<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>HI!FEI!</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-06-09T07:47:59.044Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Feidashen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>计算机网络</title>
    <link href="http://example.com/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    <id>http://example.com/2024/06/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</id>
    <published>2024-06-09T07:47:39.000Z</published>
    <updated>2024-06-09T07:47:59.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="网络基础"><a href="#网络基础" class="headerlink" title="网络基础"></a>网络基础</h1><h2 id="1-TCP-IP-网络模型有哪几层？"><a href="#1-TCP-IP-网络模型有哪几层？" class="headerlink" title="1.TCP&#x2F;IP 网络模型有哪几层？"></a>1.TCP&#x2F;IP 网络模型有哪几层？</h2><p><strong>1. 应用层</strong>：专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP等，而且应用层是工作在操作系统中的<em>用户态</em>，传输层及以下则工作在<em>内核态</em>。</p><p>通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。把应用层交互的数据单元称为<strong>报文</strong>。</p><p><strong>2.传输层</strong>：应用层的数据包会传给传输层，传输层是为应用层提供网络支持的。在传输层会有两个传输协议，分别是 TCP 和 UDP。</p><p>主要任务就是负责向两台主机进程之间的通信提供通用的<strong>数据传输服务</strong>。应用进程利用该服务传送应用层报文。“通用的”是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。<strong>一台机可同时运行多个线程，因此运输层有复用和分用的功能。</strong></p><p><strong>3.网络层</strong>：不希望传输层协议处理太多的事情，只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是网络层。网络层最常使用的是 IP 协议。</p><p>任务就是选择合适的网间路由和交换结点， 确保数据及时传送。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP &#x2F; IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 <strong>IP 数据报</strong>，简称<strong>数据报</strong>。</p><p><strong>4.网络接口层（链路层）</strong>：生成了 IP 头部之后，接下来要交给网络接口层（Link Layer）在 IP 头部的前面加上 <strong>MAC 头部</strong>，并封装成数据帧（Data frame）发送到网络上。</p><p>数据链路层（data link layer）通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如：同步信息，地址信息，差错控制等）。</p><p><strong>OSI模型（七层）</strong>：应用层、表示层、会话层（前三层统一表示为应用层）、传输层、网络层、数据链路层、物理层(后两层统一表示为网络接口层)</p><blockquote><ul><li>应用层，负责给应用程序提供统一的接口；</li><li>表示层，负责把数据转换成兼容另一个系统能识别的格式；</li><li>会话层，负责建立、管理和终止表示层实体之间的通信会话；</li><li>传输层，负责端到端的数据传输；</li><li>网络层，负责数据的路由、转发、分片；</li><li>数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；</li><li>物理层，负责在物理网络中传输数据帧；</li></ul></blockquote><h2 id="2-简单说下每一层对应的网络协议有哪些？"><a href="#2-简单说下每一层对应的网络协议有哪些？" class="headerlink" title="2.简单说下每一层对应的网络协议有哪些？"></a>2.简单说下每一层对应的网络协议有哪些？</h2><p><strong>应用层：</strong></p><ul><li>超文本传输协议：HTTP</li><li>文件传输协议：FTP</li><li>简单邮件传输协议：SMTP</li><li>域名系统：DNS</li><li>安全外壳协议：SSH</li><li>动态主机配置协议：DHCP</li><li>远程登录协议：TELNET</li></ul><p><strong>传输层：</strong></p><ul><li>传输控制协议：TCP</li><li>用户数据报文协议：UDP</li></ul><p><strong>网络层：</strong></p><ul><li>网际协议：IP</li><li>ARP：地址转换协议</li><li>RARP：反向地址转换协议</li><li>ICMP：Internet 控制报文协议</li><li>IGMP：Internet 组管理协议</li><li>RIP：路由信息协议</li><li>OSPF：分布式链路状态协议</li><li>BGP：边界网关协议</li></ul><p><strong>数据链路层：</strong></p><ul><li>自动重传请求协议：ARQ</li><li>停止等待协议：CSMA&#x2F;CD</li><li>点对点协议：PPP</li></ul><p><strong>物理层：</strong></p><ul><li>中继器</li><li>集线器</li><li>网线</li><li>HUB</li></ul><h2 id="3-键入网址到网页显示，期间发生了什么？"><a href="#3-键入网址到网页显示，期间发生了什么？" class="headerlink" title="3.键入网址到网页显示，期间发生了什么？"></a>3.键入网址到网页显示，期间发生了什么？</h2><p>1.要<strong>对 URL 进行解析</strong>（URL 实际上是请求服务器里的文件资源）；</p><blockquote><p>当没有路径名时，就代表访问根目录下事先设置的默认文件，也就是 &#x2F;index.html 或者 &#x2F;default.html 这些文件</p></blockquote><p>2.对 URL 进行解析之后，浏览器确定了 Web 服务器和文件名，根据这些信息来<strong>生成 HTTP 请求消息</strong>（GET, POST）；</p><p>3.<strong>查询服务器域名对应的 IP 地址</strong>（解析DNS域名），因为委托操作系统发送消息时，必须提供通信对象的 IP 地址；</p><blockquote><p>DNS 服务器专门保存了 Web 服务器域名与 IP 的对应关系；<br>DNS 中的域名都是用句点来分隔的，比如 <a href="http://www.server.com,这里的句点代表了不同层次之间的界限.在域名中,越靠右的位置表示其层级越高./">www.server.com，这里的句点代表了不同层次之间的界限。在域名中，越靠右的位置表示其层级越高。</a></p></blockquote><p>4.通过 DNS 获取到 IP 后，就可以<strong>把 HTTP 的传输工作交给操作系统中的协议栈</strong>(应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作)；</p><blockquote><p>协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，这两个传输协议会接受应用层的委托执行收发数据的操作。</p></blockquote><blockquote><p>协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。<br>此外 IP 中还包括 ICMP 协议和 ARP 协议。</p></blockquote><blockquote><ul><li>ICMP 用于告知网络包传送过程中产生的错误以及各种控制信息。</li><li>ARP 用于根据 IP 地址查询相应的以太网 MAC 地址。</li></ul></blockquote><p>TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成网络包发送给通信对象。</p><p>生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 MAC 头部。<br>一般在 TCP&#x2F;IP 通信里，MAC 包头的协议类型只使用：</p><blockquote><p>0800 ： IP 协议<br>0806 ： ARP 协议</p></blockquote><p>5.发送 http 请求（网卡、交换机、路由器）</p><p>6.服务器处理请求（MAC-&gt;IP-&gt;TCP头-&gt;HTTP 进程），并返回响应（HTTP 响应报文）</p><p>7.接收响应并显示网页</p><h2 id="4-Linux-系统是如何收发网络包的？"><a href="#4-Linux-系统是如何收发网络包的？" class="headerlink" title="4.Linux 系统是如何收发网络包的？"></a>4.Linux 系统是如何收发网络包的？</h2><p>当应用程序通过 Socket 接口发送数据包，数据包会被网络协议栈从上到下进行逐层处理后，才会被送到网卡队列中，随后由网卡将网络包发送出去。</p><p><strong>Linux发包</strong>：应用程序会调用 Socket 发送数据包的接口，内核会申请一个 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区，然后网络协议栈从 Socket 发送缓冲区中取出 sk_buff，先进入传输层，如果使用的是 TCP 协议发送数据，会先拷贝一个sk_buff 副本 ，然后为副本添加TCP头部，本来的sk_buff就留在传输层，接着sk_buff副本在网络层添加上IP头部，然后在网络接口层添加上帧头（帧头包括了MAC头部）和帧尾，最后将 sk_buff 放到网卡的发送队列中。随后会触发「软中断」告诉网卡驱动程序，驱动程序会从发送队列中读取 sk_buff，将这个 sk_buff 挂到 Ring Buffer 中，接着将 sk_buff 数据映射到网卡可访问的内存 DMA 区域，最后触发真实的发送。当数据发送完成以后，网卡会触发一个硬中断来释放内存，主要是释放 sk_buff 内存和清理 Ring Buffer 内存。</p><p>而在接收网络包时，同样也要先经过网络协议栈从下到上的逐层处理，最后才会被送到应用程序。</p><p><strong>Linux收包</strong>：网卡收到网络包之后会通过 DMA（直接存储器访问） 技术将网络包写入 RingBuffer 环形缓冲区，接着网卡向 CPU 发起硬件中断，当 CPU 收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数。硬件中断函数先暂时屏蔽中断(下一次就直接写入内存而不通知CPU)，再发起软中断，软中断调用 ksoftirqd 线程从 Ring Buffer 中获取一个数据帧，用 sk_buffer(socket_buffer，一种数据类型)表示，然后由网络协议栈处理，先进入网络接口层，去掉帧头和帧尾，再进入网络层，去掉IP头部，接着进入传输层去掉TCP 头或 UDP 头，根据四元组「源 IP、目的 IP、源端口、目的端口」 作为标识，找出对应的 Socket，并把数据放到 Socket 的接收缓冲区。最后，应用层程序调用 Socket 接口，将缓冲区的数据「拷贝」到应用层的缓冲区，然后唤醒用户进程。</p><h2 id="5-发送网络数据的时候，涉及几次内存拷贝操作？"><a href="#5-发送网络数据的时候，涉及几次内存拷贝操作？" class="headerlink" title="5.发送网络数据的时候，涉及几次内存拷贝操作？"></a>5.发送网络数据的时候，涉及几次内存拷贝操作？</h2><p>第一次，调用发送数据的系统调用的时候，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。</p><p>第二次，在使用 TCP 传输协议的情况下，从传输层进入网络层的时候，每一个 sk_buff 都会被克隆一个新的副本出来。副本 sk_buff 会被送往网络层，等它发送完的时候就会释放掉，然后原始的 sk_buff 还保留在传输层，目的是为了实现 TCP 的可靠传输，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。</p><p>第三次，当 IP 层发现 sk_buff 大于 MTU 时才需要进行。会再申请额外的 sk_buff，并将原来的 sk_buff 拷贝为多个小的 sk_buff。</p><h1 id="HTTP-相关"><a href="#HTTP-相关" class="headerlink" title="HTTP 相关"></a>HTTP 相关</h1><h2 id="5-HTTP-是什么？"><a href="#5-HTTP-是什么？" class="headerlink" title="5.HTTP 是什么？"></a>5.HTTP 是什么？</h2><p>HTTP 是<strong>超文本传输协议</strong>，也就是HyperText Transfer Protocol。<br>由三个部分组成：</p><ul><li>超文本：传输的内容</li><li>传输：两点之间传输数据的约定和规范</li><li>协议：计算机交流通信的规范，以及相关的各种控制和错误处理方式；</li></ul><p>HTTP 协议是一个双向协议</p><h2 id="6-HTTP-常见的状态码有哪些？"><a href="#6-HTTP-常见的状态码有哪些？" class="headerlink" title="6.HTTP 常见的状态码有哪些？"></a>6.HTTP 常见的状态码有哪些？</h2><table><thead><tr><th></th><th>具体含义</th><th>常见的状态码</th></tr></thead><tbody><tr><td>1xx</td><td>提示信息，是协议处理中的一种中间状态，还需要后续操作</td><td></td></tr><tr><td>2xx</td><td>成功，报文已经收到，并被正确处理</td><td>200，204，206</td></tr><tr><td>3xx</td><td>重定向，资源位置发生变动，需要客户端重新发送请求</td><td>301，302，304</td></tr><tr><td>4xx</td><td>客户端错误，请求报文有误，服务器无法处理</td><td>400，403，404</td></tr><tr><td>5xx</td><td>服务器错误，服务器在处理请求时内部发生了错误</td><td>500，501，502，503</td></tr></tbody></table><ul><li>「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。</li><li>「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。</li><li>「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。</li><li>「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。</li><li>「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。 301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。</li><li>「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。</li><li>「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。</li><li>「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。</li><li>「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。</li><li>「500 Internal Server Error」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。</li><li>「501 Not Implemented」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。</li><li>「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。</li><li>「503 Service Unavailable」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。</li></ul><p>#7.HTTP 常见字段有哪些？<br><strong>Host 字段</strong>：<br>客户端发送请求时，用来指定服务器的域名。</p><p><strong>Content-Length 字段</strong>：<br>服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据长度。</p><p><strong>Connection 字段</strong>：<br>最常用于客户端要求服务器使用「HTTP 长连接」机制，以便其他请求复用。</p><blockquote><p>HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。</p></blockquote><p><strong>Content-Type 字段</strong>：<br>用于服务器回应时，告诉客户端，本次数据是什么格式。</p><p><strong>Content-Encoding 字段</strong>：<br>说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式</p><p><strong>Accept 字段</strong>：<br>声明自己可以接受哪些数据格式</p><h2 id="8-GET-和-POST-有什么区别？"><a href="#8-GET-和-POST-有什么区别？" class="headerlink" title="8.GET 和 POST 有什么区别？"></a>8.GET 和 POST 有什么区别？</h2><p>GET 的语义是<strong>从服务器获取指定的资源</strong>。</p><blockquote><p>GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。</p></blockquote><p>POST 的语义是<strong>根据请求负荷（报文body）对指定的资源做出处理</strong>，具体的处理方式视资源类型而不同。</p><blockquote><p>POST 请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。</p></blockquote><h2 id="9-GET-和-POST-方法都是安全和幂等的吗？"><a href="#9-GET-和-POST-方法都是安全和幂等的吗？" class="headerlink" title="9.GET 和 POST 方法都是安全和幂等的吗？"></a>9.GET 和 POST 方法都是安全和幂等的吗？</h2><ul><li>在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。</li><li>所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。</li></ul><p><strong>GET 方法就是安全且幂等的</strong>，因为它是「只读」操作，无论操作多少次，服务器上的数据都是<strong>安全的</strong>，且每次的结果都是相同的。所以，可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签。</p><p>POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是<strong>不安全的</strong>，且多次提交数据就会创建多个资源，所以<strong>不是幂等的</strong>。所以，浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签。</p><h2 id="10-GET-请求可以带-body-吗？"><a href="#10-GET-请求可以带-body-吗？" class="headerlink" title="10.GET 请求可以带 body 吗？"></a>10.GET 请求可以带 body 吗？</h2><p>RFC 规范并没有规定 GET 请求不能带 body 的。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。</p><p>另外，URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的。</p><h2 id="11-HTTP-缓存有哪些实现方式？"><a href="#11-HTTP-缓存有哪些实现方式？" class="headerlink" title="11.HTTP 缓存有哪些实现方式？"></a>11.HTTP 缓存有哪些实现方式？</h2><p>强制缓存和协商缓存</p><p><strong>强制缓存</strong>指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。</p><p>强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：<br><code>Cache-Control</code>， 是一个相对时间；<br><code>Expires</code>，是一个绝对时间；Cache-Control 的优先级高于 Expires 。第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小。后续服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。</p><p><strong>协商缓存</strong>就是与服务端协商之后，通过协商结果来判断是否使用本地缓存。</p><p>第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。</p><p><strong>协商缓存的两种实现都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。</strong></p><h2 id="12-HTTP-1-1-的优缺点？"><a href="#12-HTTP-1-1-的优缺点？" class="headerlink" title="12.HTTP&#x2F;1.1 的优缺点？"></a>12.HTTP&#x2F;1.1 的优缺点？</h2><p>HTTP 优点：「简单、灵活和易于扩展、应用广泛和跨平台」；</p><p>HTTP 缺点：「无状态、明文传输」，「不安全」</p><h2 id="13-HTTP-1-1-的性能如何？"><a href="#13-HTTP-1-1-的性能如何？" class="headerlink" title="13.HTTP&#x2F;1.1 的性能如何？"></a>13.HTTP&#x2F;1.1 的性能如何？</h2><p>HTTP 协议是基于 TCP&#x2F;IP，并且使用了「请求 - 应答」的通信模式</p><p>1.长连接：<br>减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。</p><p>2.管道网络传输：<br>在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。</p><p>3.队头阻塞：<br>当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞。</p><p>HTTP&#x2F;1.1 的性能一般般</p><h2 id="14-HTTP-与-HTTPS-有哪些区别？"><a href="#14-HTTP-与-HTTPS-有哪些区别？" class="headerlink" title="14.HTTP 与 HTTPS 有哪些区别？"></a>14.HTTP 与 HTTPS 有哪些区别？</h2><ul><li>HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则<strong>解决 HTTP 不安全的缺陷</strong>，在 TCP 和 HTTP 网络层之间加入了 SSL&#x2F;TLS 安全协议，使得报文能够加密传输。</li><li>HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL&#x2F;TLS 的握手过程，才可进入加密报文传输。（Secure Sockets Layer，SSL；Transport Layer Security，TLS）</li><li>两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。</li><li>HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。</li></ul><h2 id="15-SSL-TLS-协议基本流程"><a href="#15-SSL-TLS-协议基本流程" class="headerlink" title="15.SSL&#x2F;TLS 协议基本流程"></a>15.SSL&#x2F;TLS 协议基本流程</h2><ul><li>客户端向服务器索要并验证服务器的公钥。</li><li>双方协商生产「会话秘钥」。</li><li>双方采用「会话秘钥」进行加密通信。</li></ul><p><strong>TLS 的「握手阶段」涉及四次通信：</strong></p><ol><li><p>由客户端向服务器发起加密通信请求，也就是 ClientHello 请求：客户端生产的随机数（Client Random），客户端支持的密码套件列表。</p></li><li><p>服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello：服务器生产的随机数（Server Random），确认的密码套件列表，服务器的数字证书。</p></li><li><p>客户端回应：客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA（证书认证机构） 公钥，确认服务器的数字证书的真实性。向服务器发送如下信息：<br>（1）一个随机数（pre-master key）。该随机数会被服务器公钥加密。<br>（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。<br>（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。</p></li><li><p>服务器的最后回应：服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」，然后，向客户端发送最后的信息：<br>（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。<br>（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。</p></li></ol><p>至此，整个 TLS 的握手阶段全部结束。</p><h2 id="16-HTTP-1-1、HTTP-2、HTTP-3-演变？"><a href="#16-HTTP-1-1、HTTP-2、HTTP-3-演变？" class="headerlink" title="16.HTTP&#x2F;1.1、HTTP&#x2F;2、HTTP&#x2F;3 演变？"></a>16.HTTP&#x2F;1.1、HTTP&#x2F;2、HTTP&#x2F;3 演变？</h2><p>HTTP&#x2F;2 相比 HTTP&#x2F;1.1 性能上的改进：</p><ul><li>头部压缩：消除头部重复的部分</li><li>二进制格式：头信息和数据体都是二进制，并且统称为帧（frame）—&gt;头信息帧（Headers Frame）和数据帧（Data Frame）</li><li>并发传输：引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接（Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号）</li><li>服务器主动推送资源：服务端不再是被动地响应，可以主动向客户端发送消息</li></ul><p>HTTP&#x2F;2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是一旦发生丢包，就会阻塞住所有的 HTTP 请求，这属于 TCP 层队头阻塞。</p><p>HTTP&#x2F;3 把 HTTP 下层的 TCP 协议改成了 UDP！</p><ul><li>无队头阻塞：当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题。</li><li>更快的连接建立</li><li>连接迁移</li></ul><h2 id="17-HTTP-1-1-如何优化？"><a href="#17-HTTP-1-1-如何优化？" class="headerlink" title="17.HTTP&#x2F;1.1 如何优化？"></a>17.HTTP&#x2F;1.1 如何优化？</h2><ul><li>尽量避免发送 HTTP 请求（缓存）；</li><li>在需要发送 HTTP 请求时，考虑如何减少请求次数（减少重定向请求次数、合并请求、延迟发送请求）；</li><li>减少服务器的 HTTP 响应的数据大小（无损压缩、有损压缩）；</li></ul><h2 id="18-RPC和HTTP的区别？"><a href="#18-RPC和HTTP的区别？" class="headerlink" title="18.RPC和HTTP的区别？"></a>18.RPC和HTTP的区别？</h2><p>RPC（Remote Procedure Call），又叫做<strong>远程过程调用</strong>。它本身并不是一个具体的协议，而是一种调用方式。</p><p>虽然大部分 RPC 协议底层使用 TCP，但实际上它们不一定非得使用 TCP，改用 UDP 或者 HTTP，其实也可以做到类似的功能。</p><p><strong>1.服务发现</strong></p><ul><li>HTTP ：知道服务的域名，就可以通过 DNS 服务去解析得到它背后的 IP 地址，默认 80 端口。</li><li>RPC ：一般会有专门的中间服务去保存服务名和IP信息，比如 Consul 或者 Etcd，甚至是 Redis。想要访问某个服务，就去这些中间服务去获得 IP 和端口信息。</li></ul><p><strong>2.底层连接形式</strong></p><ul><li>HTTP：默认在建立底层 TCP 连接之后会一直保持这个连接（Keep Alive），之后的请求和响应都会复用这条连接。</li><li>RPC：也是通过建立 TCP 长链接进行数据交互，但不同的地方在于，RPC 协议一般还会再建个连接池，在请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，用完放回去，下次再复用</li></ul><p><strong>3.传输的内容</strong></p><ul><li>HTTP：内容非常多的冗余，显得非常啰嗦</li><li>RPC：定制化程度更高，可以采用体积更小的 Protobuf 或其他序列化协议去保存结构体数据，同时也不需要像 HTTP 那样考虑各种浏览器行为。</li></ul><h2 id="19-WebSocket是什么？"><a href="#19-WebSocket是什么？" class="headerlink" title="19.WebSocket是什么？"></a>19.WebSocket是什么？</h2><p>WebSocket是HTML5下一种新的协议（websocket协议本质上是一个基于tcp的协议）</p><p>它实现了浏览器与服务器<strong>全双工通信</strong>，能更好的节省服务器资源和带宽并达到实时通讯的目的（Websocket协议通过第一个request建立了TCP连接之后，之后交换的数据都不需要发送 HTTP header就能交换数据）</p><p>Websocket是一个持久化的协议</p><p>websocket 约定了一个通信的规范，通过一个握手的机制，客户端和服务器之间能建立一个类似 tcp 的连接，从而方便它们之间的通信；在 websocket 出现之前，we b交互一般是基于 http 协议的短连接或者长连接；<br>websocket是一种全新的协议，不属于 http 无状态协议，协议名为”ws”</p><h2 id="20-websocket-与-http的关系？"><a href="#20-websocket-与-http的关系？" class="headerlink" title="20.websocket 与 http的关系？"></a>20.websocket 与 http的关系？</h2><p><strong>相同点：</strong></p><ul><li>都是基于tcp的，都是可靠性传输协议</li><li>都是应用层协议</li></ul><p><strong>不同点：</strong></p><ul><li>WebSocket 是双向通信协议，模拟Socket协议，可以双向发送或接受信息；HTTP是单向的</li><li>WebSocket 是需要浏览器和服务器握手进行建立连接的；而http是浏览器发起向服务器的连接，服务器预先并不知道这个连接。</li></ul><p><font color="#F100">WebSocket在建立握手时，数据是通过HTTP传输的。但是建立之后，在真正传输时候是不需要HTTP协议的。</font></p><p><a href="https://blog.csdn.net/weixin_47428270/article/details/126639625">什么是websocket？</a></p><hr><h1 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h1><h2 id="21-为什么需要-TCP-协议？-TCP-工作在哪一层？"><a href="#21-为什么需要-TCP-协议？-TCP-工作在哪一层？" class="headerlink" title="21.为什么需要 TCP 协议？ TCP 工作在哪一层？"></a>21.为什么需要 TCP 协议？ TCP 工作在哪一层？</h2><p>IP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。</p><p>TCP 是一个工作在<strong>传输层</strong>的可靠数据传输的服务，它能确保接收端接收的网络包是无损坏、无间隔、非冗余和按序的。</p><h2 id="22-什么是-TCP-？"><a href="#22-什么是-TCP-？" class="headerlink" title="22.什么是 TCP ？"></a>22.什么是 TCP ？</h2><p>TCP 是<strong>面向连接的、可靠的、基于字节流</strong>的传输层通信协议。</p><p><strong>面向连接</strong>：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；</p><p><strong>可靠的</strong>：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；</p><p><strong>字节流</strong>：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。</p><h2 id="23-什么是-TCP-连接？"><a href="#23-什么是-TCP-连接？" class="headerlink" title="23.什么是 TCP 连接？"></a>23.什么是 TCP 连接？</h2><p>用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 Socket、序列号和窗口大小称为<strong>连接</strong>。</p><p>建立一个 TCP 连接是需要客户端与服务端达成下述三个信息的共识：</p><ul><li>Socket：由 IP 地址和端口号组成</li><li>序列号：用来解决乱序问题等</li><li>窗口大小：用来做流量控制</li></ul><h2 id="24-如何唯一确定一个-TCP-连接？"><a href="#24-如何唯一确定一个-TCP-连接？" class="headerlink" title="24.如何唯一确定一个 TCP 连接？"></a>24.如何唯一确定一个 TCP 连接？</h2><p>TCP 四元组可以唯一的确定一个连接，四元组包括如下：</p><ul><li>源地址</li><li>源端口</li><li>目的地址</li><li>目的端口</li></ul><p>源地址和目的地址的字段（32 位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。</p><h2 id="25-有一个-IP-的服务端监听了一个端口，它的-TCP-的最大连接数是多少？"><a href="#25-有一个-IP-的服务端监听了一个端口，它的-TCP-的最大连接数是多少？" class="headerlink" title="25.有一个 IP 的服务端监听了一个端口，它的 TCP 的最大连接数是多少？"></a>25.有一个 IP 的服务端监听了一个端口，它的 TCP 的最大连接数是多少？</h2><p>客户端 IP 和端口是可变的，其理论值是：客户端的IP数 × 客户端的端口数</p><p>对 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数，约为 2 的 48 次方。</p><p>服务端最大并发 TCP 连接数远不能达到理论上限，会受以下因素影响：</p><p><strong>文件描述符限制</strong>，每个 TCP 连接都是一个文件，如果文件描述符被占满了，会发生 Too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制：</p><ul><li><strong>系统级</strong>：当前系统可打开的最大数量，通过 cat &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;file-max 查看；</li><li><strong>用户级</strong>：指定用户可打开的最大数量，通过 cat &#x2F;etc&#x2F;security&#x2F;limits.conf 查看；</li><li><strong>进程级</strong>：单个进程可打开的最大数量，通过 cat &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;nr_open 查看；</li></ul><p><strong>内存限制</strong>，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。</p><h2 id="26-UDP-和-TCP-有什么区别？"><a href="#26-UDP-和-TCP-有什么区别？" class="headerlink" title="26.UDP 和 TCP 有什么区别？"></a>26.UDP 和 TCP 有什么区别？</h2><p>TCP 的全称叫<strong>传输控制协议（Transmission Control Protocol）</strong>，大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能<strong>可靠地</strong>传输给对方。</p><p>UDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它<strong>实时性</strong>相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以。</p><p><strong>1.连接</strong><br>TCP 是面向连接的传输层协议，传输数据前先要建立连接。<br>UDP 是不需要连接，即刻传输数据。</p><p><strong>2.服务对象</strong><br>TCP 是一对一的两点服务，即一条连接只有两个端点。<br>UDP 支持一对一、一对多、多对多的交互通信。</p><p><strong>3.可靠性</strong><br>TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。<br>UDP 是尽最大努力交付，不保证可靠交付数据。但是可以基于 UDP 传输协议实现一个可靠的传输协议。</p><p><strong>4. 拥塞控制、流量控制</strong><br>TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。<br>UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。</p><p><strong>5.首部开销</strong><br>TCP首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。<br>UDP 首部只有 8 个字节，并且是固定不变的，开销较小。</p><p><strong>6.传输方式</strong><br>TCP 是流式传输，没有边界，但保证顺序和可靠。<br>UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。</p><p><strong>7.分片不同</strong><br>TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。<br>UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。</p><p> TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：</p><ul><li>FTP 文件传输；</li><li>HTTP &#x2F; HTTPS；</li></ul><p>UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：</p><ul><li>包总量较少的通信，如 DNS 、SNMP 等；</li><li>视频、音频等多媒体通信；</li><li>广播通信；</li></ul><h2 id="27-TCP-和-UDP-可以使用同一个端口吗？"><a href="#27-TCP-和-UDP-可以使用同一个端口吗？" class="headerlink" title="27.TCP 和 UDP 可以使用同一个端口吗？"></a>27.TCP 和 UDP 可以使用同一个端口吗？</h2><p>可以。</p><p>传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。<br>TCP 和 UDP，在内核中是两个完全独立的软件模块。<br>当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP&#x2F;UDP，所以可以根据这个信息确定送给哪个模块（TCP&#x2F;UDP）处理，送给 TCP&#x2F;UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。</p><p>因此， TCP&#x2F;UDP 各自的端口号也相互独立，二者并不冲突。</p><h2 id="28-TCP-三次握手过程是怎样的？"><a href="#28-TCP-三次握手过程是怎样的？" class="headerlink" title="28.TCP 三次握手过程是怎样的？"></a>28.TCP 三次握手过程是怎样的？</h2><ul><li>一开始，客户端和服务端都处于 CLOSE 状态。先是服务端主动监听某个端口，处于 LISTEN 状态；</li><li>客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。</li><li>服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。</li><li>客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，<strong>这次报文可以携带客户到服务端的数据</strong>，之后客户端处于 ESTABLISHED 状态。</li><li>服务端收到客户端的应答报文后，也进入 ESTABLISHED 状态。</li></ul><p><font color = "#F100">第三次握手是可以携带数据的，前两次握手是不可以携带数据的</font></p><h2 id="29-TCP-需要三次握手的原因？"><a href="#29-TCP-需要三次握手的原因？" class="headerlink" title="29.TCP 需要三次握手的原因？"></a>29.TCP 需要三次握手的原因？</h2><ul><li>三次握手才可以阻止重复历史连接的初始化（主要原因）</li><li>三次握手才可以同步双方的初始序列号（接收方可以去除重复的数据；<br>接收方可以根据数据包的序列号按序接收；<br>可以标识发送出去的数据包中， 哪些是已经被对方收到的&lt;通过 ACK 报文中的序列号知道&gt;；）</li><li>三次握手才可以避免资源浪费</li></ul><h2 id="30-既然-IP-层会分片，为什么-TCP-层还需要-MSS-呢？"><a href="#30-既然-IP-层会分片，为什么-TCP-层还需要-MSS-呢？" class="headerlink" title="30.既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？"></a>30.既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？</h2><p>-** MTU**：一个网络包的最大长度，以太网中一般为 1500 字节；</p><ul><li><strong>MSS</strong>：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；</li></ul><p>如果在TCP的整个报文（头部+数据）交给IP层进行分片，当某一个IP分片丢失后，接收方的 IP 层就无法组装成一个完整的TCP报文，也就无法将数据报文送给TCP层，所以接收方不会响应ACK给发送方，因为发送方迟迟收不到ACK确认报文，所以就会触发超时重传，就会重发整个TCP报文(头部+数据)。</p><p>当 TCP 层发现数据超过 MSS 时，则会先进行分片，分片后的形成的 IP 包自然不会超过 MTU，也就不用 IP 进行分片了。此时，如果一个TCP分片丢失后，进行重发也是MSS为单位的，而不用重发所有数据，大大增加了重传的效率。</p><h2 id="31-三次握手出现问题"><a href="#31-三次握手出现问题" class="headerlink" title="31.三次握手出现问题"></a>31.三次握手出现问题</h2><p><strong>当第一次握手丢失了，客户端会发生超时重传：</strong><br>重传 SYN 报文，而且<em>重传的 SYN 报文的序列号都是一样的</em></p><p><strong>当第二次握手丢失了，客户端和服务端都会超时重传：</strong></p><ul><li>客户端会重传 SYN 报文，也就是第一次握手，最大重传次数由 tcp_syn_retries内核参数决定；</li><li>服务端会重传 SYN-ACK 报文，也就是第二次握手，最大重传次数由 tcp_synack_retries 内核参数决定。</li></ul><p><strong>第三次握手丢失了，服务端超时重传：</strong><br>重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。<br><em>ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文</em>。</p><h2 id="32-TCP-四次挥手过程是怎样的？"><a href="#32-TCP-四次挥手过程是怎样的？" class="headerlink" title="32.TCP 四次挥手过程是怎样的？"></a>32.TCP 四次挥手过程是怎样的？</h2><ul><li>客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。</li><li>服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSE_WAIT 状态。</li><li>客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。</li><li>等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。</li><li>客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态</li><li>服务端收到了 ACK 应答报文后，就进入了 CLOSE 状态，至此服务端已经完成连接的关闭。</li><li>客户端在经过 2MSL 一段时间后，自动进入 CLOSE 状态，至此客户端也完成连接的关闭。</li></ul><h2 id="33-四次挥手出现问题"><a href="#33-四次挥手出现问题" class="headerlink" title="33.四次挥手出现问题"></a>33.四次挥手出现问题</h2><p><strong>第一次挥手丢失：</strong><br>客户端迟迟收不到被动方的 ACK 的话，也就会触发<strong>超时重传机制（时间为上一次超时时间的2倍），重传 FIN 报文</strong>，重发次数由 tcp_orphan_retries 参数控制。</p><p><strong>服务端的第二次挥手丢失</strong>：<br>客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。（ACK不会重传）</p><blockquote><p>当客户端收到第二次挥手，也就是收到服务端发送的 ACK 报文后，客户端就会处于 FIN_WAIT2 状态，在这个状态需要等服务端发送第三次挥手，也就是服务端的 FIN 报文。</p></blockquote><blockquote><p>对于 close 函数关闭的连接，由于无法再发送和接收数据，所以 FIN_WAIT2  状态不可以持续太久，而 tcp_fin_timeout 控制了这个状态下连接的持续时长，默认值是 60 秒。<br>这意味着对于调用 close 关闭的连接，如果在 60 秒后还没有收到 FIN 报文，客户端（主动关闭方）的连接就会直接关闭。</p></blockquote><blockquote><p>如果主动关闭方使用 shutdown 函数关闭连接，指定了只关闭发送方向，而接收方向并没有关闭，那么意味着主动关闭方还是可以接收数据的。如果主动关闭方一直没收到第三次挥手，那么主动关闭方的连接将会一直处于 FIN_WAIT2 状态（<strong>tcp_fin_timeout 无法控制 shutdown 关闭的连接</strong>）</p></blockquote><p><strong>第三次挥手丢失</strong>：<br>服务端处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭，迟迟收不到这个 ACK，服务端就会重发 FIN 报文（超时重传）。</p><p><strong>第四次挥手丢失：</strong><br>如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制。</p><p>客户端在收到第三次挥手后，就会进入 TIME_WAIT 状态，开启时长为 2MSL 的定时器，如果途中再次收到第三次挥手（FIN 报文）后，就会<strong>重置定时器</strong>。</p><p>达到重传次数上限后，如果还是没能收到客户端的第四次挥手（ACK 报文），那么服务端就会断开连接。</p><h2 id="34-为什么-TIME-WAIT-等待的时间是-2MSL？"><a href="#34-为什么-TIME-WAIT-等待的时间是-2MSL？" class="headerlink" title="34.为什么 TIME_WAIT 等待的时间是 2MSL？"></a>34.为什么 TIME_WAIT 等待的时间是 2MSL？</h2><p>MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。</p><p>因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个  TTL  （Time to Live，生存时间）字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。</p><p>MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。</p><p>TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了。</p><p>TIME_WAIT 等待 2 倍的 MSL，是因为网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。</p><h2 id="35-为什么需要-TIME-WAIT-状态？"><a href="#35-为什么需要-TIME-WAIT-状态？" class="headerlink" title="35.为什么需要 TIME_WAIT 状态？"></a>35.为什么需要 TIME_WAIT 状态？</h2><ul><li><ol><li>防止历史连接中的数据，被后面相同四元组的连接错误的接收（<strong>序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况，这意味着无法根据序列号来判断新老数据</strong>）：<br>TIME_WAIT 的 2MSL 足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的</li></ol></li><li>2.保证「被动关闭连接」的一方，能被正确的关闭：<strong>等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭</strong>。</li></ul><h2 id="36-如果已经建立了连接，但是服务端的进程崩溃会发生什么？"><a href="#36-如果已经建立了连接，但是服务端的进程崩溃会发生什么？" class="headerlink" title="36.如果已经建立了连接，但是服务端的进程崩溃会发生什么？"></a>36.如果已经建立了连接，但是服务端的进程崩溃会发生什么？</h2><p>TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以<strong>即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程</strong>。</p><h2 id="37-TCP滑动窗口大小由哪一方决定？"><a href="#37-TCP滑动窗口大小由哪一方决定？" class="headerlink" title="37.TCP滑动窗口大小由哪一方决定？"></a>37.TCP滑动窗口大小由哪一方决定？</h2><p>接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。</p><h2 id="38-接收窗口和发送窗口的大小是相等的吗？"><a href="#38-接收窗口和发送窗口的大小是相等的吗？" class="headerlink" title="38.接收窗口和发送窗口的大小是相等的吗？"></a>38.接收窗口和发送窗口的大小是相等的吗？</h2><p>并不是完全相等，接收窗口的大小是约等于发送窗口的大小的。</p><p>因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。</p><h2 id="39-什么是TCP流量控制？"><a href="#39-什么是TCP流量控制？" class="headerlink" title="39.什么是TCP流量控制？"></a>39.什么是TCP流量控制？</h2><p>两个应用程序通过 TCP 协议在网络中传输数据时，双方在硬件性能和软件性能上均可能存在差异，导致双方处理数据的速度不一致。当发送方的发送速度低于接收方接的处理速度时，不会出现问题。而当发送方的发送速度高于接收方的处理速度时，接收方会抛弃暂时无法“安置”的数据包。由于这些丢弃的数据包得不到确认，发送方会重新发送它们，直到他们被成功接收，造成资源浪费。TCP流量控制就是确保发送方的发送速度不要超出接收方的处理能力。</p><p>发送发和接收方都维护一个数据池来处理数据，称之为Buffer。发送方不断地将要发送的数据送入sender buffer，接收方不断地从receiver buffer里获取数据。</p><p>当接收方的receiver buffer已满时，发送方则暂时停止发送数据。</p><h2 id="40-流量控制和拥塞控制的不同？"><a href="#40-流量控制和拥塞控制的不同？" class="headerlink" title="40.流量控制和拥塞控制的不同？"></a>40.流量控制和拥塞控制的不同？</h2><ul><li>流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。</li><li>拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络</li></ul><p>只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是发生了超时重传，就会认为网络出现了拥塞。</p><p>拥塞控制主要是四个算法：</p><ul><li>慢启动：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1；</li><li>拥塞避免：拥塞窗口大于慢启动门限（ssthresh）时会启动拥塞避免算法（每当收到一个 ACK 时，cwnd 增加 1&#x2F;cwnd）；</li><li>拥塞发生：超时重传（ssthresh 设为 cwnd&#x2F;2，cwnd 重置为初始值），快速重传（cwnd &#x3D; cwnd&#x2F;2 ，ssthresh &#x3D; cwnd；进入快速恢复算法）</li><li>快速恢复：</li></ul><p>拥塞窗口 cwnd &#x3D; ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）；<br>重传丢失的数据包；<br>如果再收到重复的 ACK，那么 cwnd 增加 1；<br>如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；</p><h2 id="41-Nagle-算法是如何避免大量-TCP-小数据报文的传输？"><a href="#41-Nagle-算法是如何避免大量-TCP-小数据报文的传输？" class="headerlink" title="41.Nagle 算法是如何避免大量 TCP 小数据报文的传输？"></a>41.Nagle 算法是如何避免大量 TCP 小数据报文的传输？</h2><p>Nagle 算法做了一些策略来避免过多的小数据报文发送，这可提高传输效率。</p><p>MSS：最大报文段长度</p><pre><code>if 有数据要发送 &#123;    if 可用窗口大小 &gt;= MSS and 可发送的数据 &gt;= MSS &#123;    立刻发送MSS大小的数据    &#125; else &#123;        if 有未确认的数据 &#123;            将数据放入缓存等待接收ACK        &#125; else &#123;            立刻发送数据        &#125;    &#125;&#125;</code></pre><p>使用 Nagle 算法，该算法的思路是延时处理，只有满足下面两个条件中的任意一个条件，才能可以发送数据：</p><ul><li>条件一：要等到窗口大小 &gt;&#x3D; MSS 并且 数据大小 &gt;&#x3D; MSS；</li><li>条件二：收到之前发送数据的 ack 回包；</li></ul><h2 id="42-延迟确认是什么？"><a href="#42-延迟确认是什么？" class="headerlink" title="42.延迟确认是什么？"></a>42.延迟确认是什么？</h2><ul><li>当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方</li><li>当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送</li><li>如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK</li></ul><h2 id="43-什么是-TCP-半连接队列和全连接队列？"><a href="#43-什么是-TCP-半连接队列和全连接队列？" class="headerlink" title="43.什么是 TCP 半连接队列和全连接队列？"></a>43.什么是 TCP 半连接队列和全连接队列？</h2><p>在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：</p><ul><li>半连接队列，也称 SYN 队列；</li><li>全连接队列，也称 accept 队列；</li></ul><p>服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。</p><h2 id="44-如何优化-TCP"><a href="#44-如何优化-TCP" class="headerlink" title="44.如何优化 TCP?"></a>44.如何优化 TCP?</h2><p><a href="https://blog.csdn.net/m0_69305074/article/details/126302550">https://blog.csdn.net/m0_69305074&#x2F;article&#x2F;details&#x2F;126302550</a></p><p><strong>1.TCP 三次握手的性能提升</strong></p><ul><li>调整 SYN 报文的重传次数</li><li>调整 SYN 半连接队列长度</li><li>调整 SYN+ACK 报文的重传次数</li><li>调整 accpet 队列长度</li><li>绕过三次握手</li></ul><p><strong>客户端优化：</strong>可以根据网络的稳定性和目标服务器的繁忙程度修改 SYN 的重传次数，调整客户端的三次握手时间上限；</p><p><strong>服务端优化：</strong>当网络繁忙、不稳定时，报文丢失就会变严重，此时应该调大重发次数。反之则可以调小重发次数。</p><p><strong>TCP Fast Open：</strong> 当TCP连接使用完之后，客户端再次向服务器请求建立连接，报文中可以记录此前的Fast Open Cookie。服务器对Cookie进行校验之后，如果Cookie有效，就可以将数据给到程序处理，相当于<strong>绕过了三次握手</strong>，可以更快的建立连接。</p><p><strong>2.TCP 四次挥手的性能提升</strong></p><ul><li>调整 FIN 报文重传次数</li><li>调整 FIN_WAIT2 状态的时间（只适用 close 函数关闭的连接）</li><li>调整孤儿连接的上限个数（只适用 close 函数关闭的连接）</li><li>调整 time_wait 状态的上限个数</li><li>复用 time_wait 状态的连接(只适用客户端)</li></ul><p><strong>主动方：</strong> 当 TIME_WAIT 的连接数量超过该参数时，新关闭的连接就不再经历 TIME_WAIT 而直接关闭；或者在建立新连接时，复用处于 TIME_WAIT 状态的连接（打开 tcp_tw_reuse 参数）&lt;只用于客户端（建立连接的发起方），因为是在调用 connect() 时起作用的&gt;；或者某些情况跳过四次挥手（用 close 发送RST信号）</p><p><strong>被动方：</strong> 回复 ACK 后进入 CLOSE_WAIT 状态，等待进程调用 close 函数关闭连接。在未等到 ACK 时，会在 tcp_orphan_retries 参数的控制下重发 FIN 报文。</p><p><strong>3.TCP 数据传输的性能提升</strong></p><ul><li>扩大窗口大小</li><li>调整发送缓冲区范围</li><li>调整接收缓冲区范围</li><li>打开接收缓冲区动态调节</li><li>调整内存范围</li></ul><p>系统会为每个连接建立缓冲区， 接收缓冲区可以根据系统空闲内存的大小来调节接收窗口。</p><p>发送缓冲区的调节功能是自动开启的，接收缓冲区设置 tcp_moderate_rcvbuf&#x3D;1 表示开启调节功能。</p><p>高并发服务中，可以调整缓冲区的动态调整可以达到最大宽带延积。如果服务是网络IO型的话，可以调大tcp_mem的上限，让TCP连接可以使用更多的系统内存，有利于提高并发。</p><h2 id="45-调用-close-函数和-shutdown-函数有什么区别？"><a href="#45-调用-close-函数和-shutdown-函数有什么区别？" class="headerlink" title="45.调用 close 函数和 shutdown 函数有什么区别？"></a>45.调用 close 函数和 shutdown 函数有什么区别？</h2><p>调用了 close 函数意味着完全断开连接，完全断开不仅指无法传输数据，而且也不能发送数据。 此时，调用了 close 函数的一方的连接叫做「孤儿连接]。</p><p>shutdown 函数可以控制只关闭一个方向的连接。</p><h2 id="46-如果连接双方同时关闭连接，会怎么样？"><a href="#46-如果连接双方同时关闭连接，会怎么样？" class="headerlink" title="46.如果连接双方同时关闭连接，会怎么样？"></a>46.如果连接双方同时关闭连接，会怎么样？</h2><p>由于 TCP 是双全工的协议，所以是会出现两方同时关闭连接的现象，也就是同时发送了 FIN 报文。</p><p>两方发送 FIN 报文时，都认为自己是主动方，所以都进入了 FIN_WAIT1 状态；接下来，双方在等待 ACK 报文的过程中，都等来了 FIN 报文。这是一种新情况，所以连接会进入一种叫做 <code>CLOSING</code> 的新状态，它替代了 FIN_WAIT2 状态。接着，双方内核回复 ACK 确认对方发送通道的关闭后，进入 TIME_WAIT 状态，等待 2MSL 的时间后，连接自动关闭。</p><h2 id="47-为什么-TCP-是面向字节流的协议？"><a href="#47-为什么-TCP-是面向字节流的协议？" class="headerlink" title="47.为什么 TCP 是面向字节流的协议？"></a>47.为什么 TCP 是面向字节流的协议？</h2><p> TCP 是<strong>面向字节流</strong>的协议，UDP 是<strong>面向报文</strong>的协议，是因为操作系统对 TCP 和 UDP 协议的<strong>发送方的机制不同</strong></p><ul><li><p>当用户消息通过 UDP 协议传输时，操作系统不会对消息进行拆分，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是每个 UDP 报文就是一个用户消息的边界，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。</p></li><li><p>当用户消息通过 TCP 协议传输时，消息可能会被操作系统分组成多个的 TCP 报文，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。这时，接收方的程序如果不知道发送方发送的消息的长度，也就是不知道消息的边界时，是无法读出一个有效的用户消息的，因为用户消息被拆分成多个 TCP 报文后，并不能像 UDP 那样，一个 UDP 报文就能代表一个完整的用户消息。</p></li></ul><h2 id="48-如何解决粘包？"><a href="#48-如何解决粘包？" class="headerlink" title="48.如何解决粘包？"></a>48.如何解决粘包？</h2><p>粘包的问题出现是因为不知道一个用户消息的边界在哪</p><ul><li>固定长度的消息（每个用户消息都是固定长度的）；</li><li>特殊字符作为边界（两个用户消息之间插入一个特殊的字符串）；</li><li>自定义消息结构（自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大）。</li></ul><h2 id="49-为什么-TCP-每次建立连接时，初始化序列号都要不一样呢？"><a href="#49-为什么-TCP-每次建立连接时，初始化序列号都要不一样呢？" class="headerlink" title="49.为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？"></a>49.为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？</h2><ul><li>为了防止历史报文被下一个相同四元组的连接接收（主要方面）；</li><li>为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；</li></ul><h2 id="50-SYN-报文什么时候情况下会被丢弃？"><a href="#50-SYN-报文什么时候情况下会被丢弃？" class="headerlink" title="50.SYN 报文什么时候情况下会被丢弃？"></a>50.SYN 报文什么时候情况下会被丢弃？</h2><ol><li>开启 tcp_tw_recycle 参数，并且在 NAT（Network Address Translation） 环境下，造成 SYN 报文被丢弃</li></ol><p>如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收；</p><p>如果客户端网络环境是用了 NAT 网关，那么客户端环境的每一台机器通过 NAT 网关后，都会是相同的 IP 地址，在服务端看来，就好像只是在跟一个客户端打交道一样，无法区分出来。</p><ol><li>TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃</li></ol><h2 id="51-已建立连接的TCP，收到SYN会发生什么？"><a href="#51-已建立连接的TCP，收到SYN会发生什么？" class="headerlink" title="51.已建立连接的TCP，收到SYN会发生什么？"></a>51.已建立连接的TCP，收到SYN会发生什么？</h2><p><strong>1. 客户端的 SYN 报文里的端口号与历史连接不相同</strong></p><p>如果客户端恢复后发送的 SYN 报文中的源端口号跟上一次连接的源端口号不一样，此时服务端会认为是新的连接要建立，于是就会通过三次握手来建立新的连接。</p><p>如果服务端发送了数据包给客户端，由于客户端的连接已经被关闭了，此时客户的内核就会回 RST 报文，服务端收到后就会释放连接。</p><p>如果服务端一直没有发送数据包给客户端，在超过一段时间后，TCP 保活机制就会启动，检测到客户端没有存活后，接着服务端就会释放掉该连接。</p><p><strong>2. 客户端的 SYN 报文里的端口号与历史连接相同</strong></p><p>处于 Established 状态的服务端，如果收到了客户端的 SYN 报文（注意此时的 SYN 报文其实是乱序的，因为 SYN 报文的初始化序列号其实是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK。</p><p>接着，客户端收到这个 Challenge ACK，发现确认号（ack num）并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接。</p><h2 id="52-四次挥手中收到乱序的-FIN-包会如何处理？"><a href="#52-四次挥手中收到乱序的-FIN-包会如何处理？" class="headerlink" title="52.四次挥手中收到乱序的 FIN 包会如何处理？"></a>52.四次挥手中收到乱序的 FIN 包会如何处理？</h2><p>在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，那么就被会加入到「<strong>乱序队列</strong>」，并不会进入到 TIME_WAIT 状态。</p><p>等再次收到前面被网络延迟的数据包时，会判断乱序队列有没有数据，然后会检测乱序队列中是否有可用的数据，<strong>如果能在乱序队列中找到与当前报文的序列号保持的顺序的报文</strong>，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态。</p><h2 id="53-在-TCP-正常挥手过程中，处于-TIME-WAIT-状态的连接，收到相同四元组的-SYN-后会发生什么？"><a href="#53-在-TCP-正常挥手过程中，处于-TIME-WAIT-状态的连接，收到相同四元组的-SYN-后会发生什么？" class="headerlink" title="53.在 TCP 正常挥手过程中，处于 TIME_WAIT 状态的连接，收到相同四元组的 SYN 后会发生什么？"></a>53.在 TCP 正常挥手过程中，处于 TIME_WAIT 状态的连接，收到相同四元组的 SYN 后会发生什么？</h2><p>关键是要看 SYN 的「序列号和时间戳」是否合法：</p><ul><li>如果处于 TIME_WAIT 状态的连接收到「合法的 SYN 」后，就会重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程。</li><li>如果处于 TIME_WAIT 状态的连接收到「非法的 SYN 」后，就会再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号（ack num），就回 RST 报文给服务端。</li></ul><blockquote><p>合法 SYN：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要大，并且 SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要大。</p></blockquote><blockquote><p>非法 SYN：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要小，或者 SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要小。</p></blockquote><h2 id="54-TCP-连接，一端断电和进程崩溃有什么区别？"><a href="#54-TCP-连接，一端断电和进程崩溃有什么区别？" class="headerlink" title="54.TCP 连接，一端断电和进程崩溃有什么区别？"></a>54.TCP 连接，一端断电和进程崩溃有什么区别？</h2><p><strong>TCP 保活机制（keepalive）</strong>可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活。</p><p><strong>在没有使用 TCP 保活机制且双方不传输数据的情况下</strong>，一方的 TCP 连接处在 ESTABLISHED 状态，并不代表另一方的连接还一定正常。</p><p>TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是<strong>在内核完成，并不需要进程的参与</strong>，所以即使服务端的进程退出了，还是能与客户端完成 TCP四次挥手的过程。</p><p>所以，即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃，这个过程操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手。</p><p><strong>因此，</strong></p><p>如果「<strong>客户端进程崩溃</strong>」，</p><ul><li>客户端的进程在发生崩溃的时候，内核会发送 FIN 报文，与服务端进行四次挥手。</li></ul><p>如果「<strong>客户端主机宕机</strong>」，</p><ul><li>如果服务端会发送数据，由于客户端已经不存在，收不到数据报文的响应报文，服务端的数据报文会超时重传，当重传总间隔时长达到一定阈值（内核会根据 tcp_retries2 设置的值计算出一个阈值）后，会断开 TCP 连接；</li><li>如果服务端一直不会发送数据，再看服务端有没有开启 TCP keepalive 机制？<br>如果有开启，服务端在一段时间没有进行数据交互时，会触发 TCP keepalive 机制，探测对方是否存在，如果探测到对方已经消亡，则会断开自身的 TCP 连接；<br>如果没有开启，服务端的 TCP 连接会一直存在，并且一直保持在 ESTABLISHED 状态。</li></ul><h2 id="55-拔掉网线后，-原本的-TCP-连接还存在吗？"><a href="#55-拔掉网线后，-原本的-TCP-连接还存在吗？" class="headerlink" title="55.拔掉网线后， 原本的 TCP 连接还存在吗？"></a>55.拔掉网线后， 原本的 TCP 连接还存在吗？</h2><p><strong>有数据传输的情况：</strong></p><ul><li>在客户端拔掉网线后，如果服务端发送了数据报文，那么在服务端重传次数没有达到最大值之前，客户端就插回了网线，那么双方原本的 TCP 连接还是能正常存在，就好像什么事情都没有发生。</li><li>在客户端拔掉网线后，如果服务端发送了数据报文，在客户端插回网线之前，服务端重传次数达到了最大值时，服务端就会断开 TCP 连接。等到客户端插回网线后，向服务端发送了数据，因为服务端已经断开了与客户端相同四元组的 TCP 连接，所以就会回 RST 报文，客户端收到后就会断开 TCP 连接。至此， 双方的 TCP 连接都断开了。</li></ul><p><strong>没有数据传输的情况：</strong></p><ul><li>如果双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。</li><li>如果双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。</li></ul><h2 id="56-tcp-tw-reuse-是什么？"><a href="#56-tcp-tw-reuse-是什么？" class="headerlink" title="56.tcp_tw_reuse 是什么？"></a>56.tcp_tw_reuse 是什么？</h2><p>在 Linux 操作系统下，TIME_WAIT 状态的持续时间是 60 秒，这意味着这 60 秒内，客户端一直会占用着这个端口。要知道，端口资源也是有限的。<br>因此，客户端（主动关闭连接方）都是和「目的 IP+ 目的 PORT 」都一样的服务器建立连接的话，当客户端的 TIME_WAIT 状态连接过多的话，就会受端口资源限制，如果占满了所有端口资源，那么就无法再跟「目的 IP+ 目的 PORT」都一样的服务器建立连接了。</p><p>Linux 操作系统提供了两个可以系统参数来快速回收处于 TIME_WAIT 状态的连接：</p><ul><li>net.ipv4.tcp_tw_reuse，如果开启该选项的话，客户端（连接发起方） 在调用 connect() 函数时，如果内核选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态，如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了。所以该选项只适用于连接发起方。</li><li>net.ipv4.tcp_tw_recycle，如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收，该参数在 NAT 的网络下是不安全的！</li></ul><p>tcp_tw_reuse 的作用是<strong>让客户端快速复用处于 TIME_WAIT 状态的端口，相当于跳过了 TIME_WAIT 状态</strong>，这可能会出现这样的两个问题：</p><ul><li>历史 RST 报文可能会终止后面相同四元组的连接，因为 PAWS 检查到即使 RST 是过期的，也不会丢弃。</li><li>如果第四次挥手的 ACK 报文丢失了，有可能被动关闭连接的一方不能被正常的关闭；</li></ul><blockquote><p>PAWS 机制（ tcp_timestamps 选项）的作用是<strong>防止 TCP 包中的序列号发生绕回</strong>（带上发送时的时间戳）。因为TCP 这个 SEQ 号是有限的，一共 32 bit，SEQ 开始是递增，溢出之后从 0 开始再次依次递增，所以当 SEQ 号出现溢出后单纯通过 SEQ 号无法标识数据包的唯一性，某个数据包延迟或因重发而延迟时可能导致连接传递的数据被破坏。因此加上时间戳。</p></blockquote><h2 id="57-HTTPS-中-TLS-和-TCP-能同时握手吗？"><a href="#57-HTTPS-中-TLS-和-TCP-能同时握手吗？" class="headerlink" title="57.HTTPS 中 TLS 和 TCP 能同时握手吗？"></a>57.HTTPS 中 TLS 和 TCP 能同时握手吗？</h2><p>HTTPS 是先进行 TCP 三次握手，再进行 TLS  四次握手</p><p>同时握手需要下面这两个条件同时满足才可以：</p><ul><li>客户端和服务端都开启了 TCP Fast Open 功能，且 TLS 版本是 1.3；</li><li>客户端和服务端已经完成过一次通信；</li></ul><h2 id="58-TCP-Keepalive-和-HTTP-Keep-Alive-是一个东西吗？"><a href="#58-TCP-Keepalive-和-HTTP-Keep-Alive-是一个东西吗？" class="headerlink" title="58.TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗？"></a>58.TCP Keepalive 和 HTTP Keep-Alive 是一个东西吗？</h2><ul><li>HTTP 的 Keep-Alive，是由应用层（用户态） 实现的，称为 HTTP 长连接，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求&#x2F;应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销；</li><li>TCP 的 Keepalive，是由 TCP 层（内核态） 实现的，称为 TCP 保活机制，，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。</li></ul><h2 id="59-TCP-有什么缺陷？"><a href="#59-TCP-有什么缺陷？" class="headerlink" title="59.TCP 有什么缺陷？"></a>59.TCP 有什么缺陷？</h2><ul><li>升级 TCP 的工作很困难（TCP 协议是在内核中实现的，应用程序只能使用不能修改，如果要想升级 TCP 协议，那么只能升级内核）；</li><li>TCP 建立连接的延迟（基于 TCP 实现的应用协议，都是需要先建立三次握手才能进行数据传输）；</li><li>TCP 存在队头阻塞问题（TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且有序的）；</li><li>网络迁移需要重新建立 TCP 连接（网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接）；</li></ul><h2 id="60-如何基于-UDP-协议实现可靠传输？"><a href="#60-如何基于-UDP-协议实现可靠传输？" class="headerlink" title="60.如何基于 UDP 协议实现可靠传输？"></a>60.如何基于 UDP 协议实现可靠传输？</h2><p>可以在UDP的基础上实现一些机制来增加可靠性</p><ol><li><strong>应用层确认机制</strong>：在应用层上，可以实现自定义的确认机制。发送方在发送数据后等待接收方的确认消息，如果在一定时间内未收到确认，则重新发送数据。这样可以确保数据的可靠传输。</li><li><strong>数据校验和重传</strong>：在UDP数据包中添加校验和字段，接收方在接收数据时计算校验和并与发送方的校验和进行比较。如果不匹配，则要求发送方重新发送数据。</li><li><strong>序列号和确认号</strong>：类似于TCP协议的序列号和确认号机制，发送方给每个数据包分配一个唯一的序列号，接收方收到数据后发送确认消息，并在其中包含确认号。发送方根据确认号判断哪些数据包已经被成功接收，可以进行相应的重传。</li><li><strong>超时重传</strong>：发送方可以设置一个超时计时器，如果在指定时间内未收到确认消息，则认为数据丢失，触发重传操作。</li><li><strong>流量控制和拥塞控制</strong>：通过控制发送数据的速率和接收数据的处理速度，可以避免网络拥塞和数据丢失。这可以通过动态调整发送速率、使用滑动窗口等方法来实现。</li></ol><p><strong>QUIC 协议，已经应用在了 HTTP&#x2F;3</strong></p><ul><li>QUIC 也是<strong>需要三次握手来建立连接</strong>的，主要目的是为了协商连接 ID。协商出连接 ID 后，后续传输时，双方只需要固定住连接 ID，从而实现连接迁移功能。（Long Packet Header 用于首次建立连接；Short Packet Header 用于日常传输数据。）</li><li>Short Packet Header 中的 <strong>Packet Number 是每个报文独一无二的编号，它是严格递增的</strong>，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值（可以更加精确计算 RTT，没有 TCP 重传的歧义性问题）。</li><li>QUIC 使用的 Packet Number 单调递增的设计，可以让数据包不再像 TCP 那样必须有序确认，QUIC 支持乱序确认，当数据包Packet N 丢失后，只要有新的已接收数据包确认，当前窗口就会继续向右滑动；</li><li>一个 Packet 报文中可以存放多个 QUIC Frame。每一个 Frame 都有明确的类型，针对类型的不同，功能也不同，自然格式也不同。</li></ul><p>举例 Stream 类型的 Frame 格式，Stream 可以认为就是一条 HTTP 请求：</p><ul><li>Stream ID 作用：多个并发传输的 HTTP 消息，通过不同的 Stream ID 加以区别，类似于 HTTP2 的 Stream ID；</li><li>Offset 作用：类似于 TCP 协议中的 Seq 序号，保证数据的顺序性和可靠性；</li><li>Length 作用：指明了 Frame 数据的长度。</li></ul><p>Frame Header 这一层，通过 Stream ID + Offset 字段信息实现数据的有序性，通过比较两个数据包的 Stream ID 与 Stream Offset ，如果都是一致，就说明这两个数据包的内容一致。</p><h2 id="61-什么情况会出现三次挥手？"><a href="#61-什么情况会出现三次挥手？" class="headerlink" title="61.什么情况会出现三次挥手？"></a>61.什么情况会出现三次挥手？</h2><p>当被动关闭方在 TCP 挥手过程中，「没有数据要发送」并且「<strong>开启了 TCP 延迟确认机制</strong>」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。</p><p><strong>TCP 延迟确认机制</strong></p><p>当发送没有携带数据的 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报文。 为了解决 ACK 传输效率低问题，所以就衍生出了 TCP 延迟确认。 TCP 延迟确认的策略：</p><ul><li>当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方</li><li>当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送</li><li>如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK。</li></ul><p>因为延迟机制的存在，收到客户端的fin，服务端不会立马回ack，因为服务端收到了fin，这时候应用程序的read就会返回0，如果没用数据要发送，一般就是直接调用 close 了，如果在ack延迟的这段时间，刚好马上调用了close，于是就可以和 fin一起发送，也就是第二次挥手和第三次挥手合并发送了。</p><h2 id="62-TCP-序列号和确认号是如何变化的？"><a href="#62-TCP-序列号和确认号是如何变化的？" class="headerlink" title="62.TCP 序列号和确认号是如何变化的？"></a>62.TCP 序列号和确认号是如何变化的？</h2><ul><li><strong>序列号</strong>：在建立连接时由内核生成的随机数作为其初始值，通过 SYN 报文传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来解决网络包乱序问题。</li><li><strong>确认号</strong>：指下一次「期望」收到的数据的序列号，发送端收到接收方发来的 ACK 确认报文以后，就可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。</li><li><strong>控制位</strong>：用来标识 TCP 报文是什么类型的报文，比如是 SYN 报文、数据报文、ACK 报文，FIN 报文等。</li></ul><p>发送的 TCP 报文：</p><p><strong>公式一</strong>：序列号 &#x3D; 上一次发送的序列号 + len（数据长度）。特殊情况，如果上一次发送的报文是 SYN 报文或者 FIN 报文，则改为 上一次发送的序列号 + 1。<br><strong>公式二</strong>：确认号 &#x3D; 上一次收到的报文中的序列号 + len（数据长度）。特殊情况，如果收到的是 SYN 报文或者 FIN 报文，则改为上一次收到的报文中的序列号 + 1。</p><h2 id="TCP-和-UDP-分别对应的常见应用层协议有哪些？"><a href="#TCP-和-UDP-分别对应的常见应用层协议有哪些？" class="headerlink" title="TCP 和 UDP 分别对应的常见应用层协议有哪些？"></a>TCP 和 UDP 分别对应的常见应用层协议有哪些？</h2><p><strong>1.TCP 对应的应用层协议</strong></p><ul><li><strong>FTP</strong>：定义了文件传输协议，使用 21 端口。常说某某计算机开了 FTP 服务便是启动了文件传输服务。下载文件，上传主页，都要用到 FTP 服务。</li><li><strong>Telnet</strong>：它是一种用于远程登陆的端口，用户可以以自己的身份远程连接到计算机上，通过这种端口可以提供一种基于 DOS 模式下的通信服务。如以前的 BBS 是-纯字符界面的，支持 BBS 的服务器将 23 端口打开，对外提供服务。</li><li><strong>SMTP</strong>：定义了简单邮件传送协议，现在很多邮件服务器都用的是这个协议，用于发送邮件。如常见的免费邮件服务中用的就是这个邮件服务端口，所以在电子邮件设置中常看到有这么 SMTP 端口设置这个栏，服务器开放的是 25 号端口。</li><li><strong>POP3</strong>：它是和 SMTP 对应，POP3 用于接收邮件。通常情况下，POP3 协议所用的是 110 端口。也是说，只要你有相应的使用 POP3 协议的程序（例如 Fo-xmail 或 Outlook），就可以不以 Web 方式登陆进邮箱界面，直接用邮件程序就可以收到邮件（如是163 邮箱就没有必要先进入网易网站，再进入自己的邮箱来收信）。</li><li><strong>HTTP</strong>：从 Web 服务器传输超文本到本地浏览器的传送协议。</li></ul><p><strong>2.UDP 对应的应用层协议</strong></p><ul><li><strong>DNS</strong>：用于域名解析服务，将域名地址转换为 IP 地址。DNS 用的是 53 号端口。</li><li><strong>SNMP</strong>：简单网络管理协议，使用 161 号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。</li><li>**TFTP(Trival File Transfer Protocal)**：简单文件传输协议，该协议在熟知端口 69 上使用 UDP 服务。</li></ul><h2 id="谈谈你对停止等待协议的理解？"><a href="#谈谈你对停止等待协议的理解？" class="headerlink" title="谈谈你对停止等待协议的理解？"></a>谈谈你对停止等待协议的理解？</h2><p>停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组；在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。主要包括以下几种情况：无差错情况、出现差错情况（超时重传）、确认丢失和确认迟到、确认丢失和确认迟到。</p><h1 id="IP"><a href="#IP" class="headerlink" title="IP"></a>IP</h1><h2 id="63-IPv6-相比-IPv4-的首部改进"><a href="#63-IPv6-相比-IPv4-的首部改进" class="headerlink" title="63.IPv6 相比 IPv4 的首部改进"></a>63.IPv6 相比 IPv4 的首部改进</h2><ul><li>取消了首部校验和字段。 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。</li><li>取消了分片&#x2F;重新组装相关字段。 分片与重组是耗时的过程，IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提高了路由器转发的速度。</li><li>取消选项字段。 选项字段不再是标准 IP 首部的一部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下一个首部」指出的位置上。删除该选项字段使的 IPv6 的首部成为固定长度的 40 字节。</li></ul><h2 id="64-ICMP-是什么？"><a href="#64-ICMP-是什么？" class="headerlink" title="64.ICMP 是什么？"></a>64.ICMP 是什么？</h2><p>ICMP 全称是 Internet Control Message Protocol，也就是互联网控制报文协议。</p><p>ICMP 主要的功能包括：<strong>确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。</strong></p><p>在 IP 通信中如果某个 IP 包因为某种原因未能达到目标地址，那么这个具体的原因将由 ICMP 负责通知。</p><p>ICMP 报文是<strong>封装在 IP 包里面</strong>，它工作在网络层，是 IP 协议的助手。</p><p>ICMP 包头的类型字段，大致可以分为两大类：</p><ul><li>一类是用于诊断的查询消息，也就是「查询报文类型」</li><li>另一类是通知出错原因的错误消息，也就是「差错报文类型」</li></ul><h2 id="64-什么是127-0-0-1？"><a href="#64-什么是127-0-0-1？" class="headerlink" title="64.什么是127.0.0.1？"></a>64.什么是127.0.0.1？</h2><p>这是个 IPV4 地址。</p><p>IPV4 地址有 32 位，一个字节有 8 位，共 4 个字节。</p><p>其中127 开头的都属于回环地址，也是 IPV4 的特殊地址。</p><h2 id="65-什么是-ping？"><a href="#65-什么是-ping？" class="headerlink" title="65.什么是 ping？"></a>65.什么是 ping？</h2><p>尝试发送一个小小的消息到目标机器上，判断目的机器是否可达，其实也就是判断目标机器网络是否能连通。</p><p>ping应用的底层，用的是网络层的ICMP协议。</p><p>虽然ICMP协议和IP协议都属于网络层协议，但其实ICMP也是利用了IP协议进行消息的传输。</p><h2 id="66-0-0-1-和-localhost-以及-0-0-0-0-有区别吗"><a href="#66-0-0-1-和-localhost-以及-0-0-0-0-有区别吗" class="headerlink" title="66.0.0.1 和 localhost 以及 0.0.0.0 有区别吗"></a>66.0.0.1 和 localhost 以及 0.0.0.0 有区别吗</h2><p>首先 localhost 就不叫 IP，它是一个<strong>域名</strong>，就跟 “baidu.com”,是一个形式的东西，只不过默认会把它解析为 127.0.0.1 ，当然这可以在 &#x2F;etc&#x2F;hosts 文件下进行修改。</p><p>所以默认情况下，使用 localhost 跟使用 127.0.0.1 确实是没区别的。</p><p>其次就是 0.0.0.0，执行 ping 0.0.0.0 ，是会失败的，因为它在IPV4中表示的是无效的目标地址。但如果 listen 的是本机的 0.0.0.0 , 那么它表示本机上的所有IPV4地址。</p><p>##67.ARP 协议的工作原理？<br>ARP（Address Resolution Protocol）协议是一种在局域网中解析MAC地址的协议。</p><p>网络层的 ARP 协议完成了 IP 地址与物理地址的映射。首先，每台主机都会在自己的 ARP 缓冲区中建立一个 ARP 列表，以表示 IP 地址和 MAC 地址的对应关系。当源主机需要将一个数据包要发送到目的主机时，会首先检查自己 ARP 列表中是否存在该 IP 地址对应的 MAC 地址：如果有，就直接将数据包发送到这个 MAC 地址；如果没有，就向本地网段发起一个 ARP 请求的广播包，查询此目的主机对应的 MAC 地址。</p><p>此 ARP 请求数据包里包括源主机的 IP 地址、硬件地址、以及目的主机的 IP 地址。网络中所有的主机收到这个 ARP 请求后，会检查数据包中的目的 IP 是否和自己的 IP 地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的 MAC 地址和 IP 地址添加到自己的 ARP 列表中，如果 ARP 表中已经存在该 IP 的信息，则将其覆盖，然后给源主机发送一个 ARP 响应数据包，告诉对方自己是它需要查找的 MAC 地址；源主机收到这个 ARP 响应数据包后，将得到的目的主机的 IP 地址和 MAC 地址添加到自己的 ARP 列表中，并利用此信息开始数据的传输。如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。</p><h2 id="68-谈下你对-IP-地址分类的理解？"><a href="#68-谈下你对-IP-地址分类的理解？" class="headerlink" title="68.谈下你对 IP 地址分类的理解？"></a>68.谈下你对 IP 地址分类的理解？</h2><p><strong>IP 地址是指互联网协议地址，是 IP 协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异</strong>。IP 地址编址方案将 IP 地址空间划分为 A、B、C、D、E 五类，其中 A、B、C 是基本类，D、E 类作为多播和保留使用，为特殊地址。</p><p><strong>每个 IP 地址包括两个标识码（ID），即网络 ID 和主机 ID</strong>。同一个物理网络上的所有主机都使用同一个网络 ID，网络上的一个主机（包括网络上工作站，服务器和路由器等）有一个主机 ID 与其对应。A~E 类地址的特点如下：</p><ul><li>A 类地址：以 0 开头，第一个字节范围：0~127；</li><li>B 类地址：以 10 开头，第一个字节范围：128~191；</li><li>C 类地址：以 110 开头，第一个字节范围：192~223；</li><li>D 类地址：以 1110 开头，第一个字节范围为 224~239；</li><li>E 类地址：以 1111 开头，保留地址</li></ul><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><h2 id="什么是粘包？"><a href="#什么是粘包？" class="headerlink" title="什么是粘包？"></a>什么是粘包？</h2><ol><li>TCP 是基于字节流的，虽然应用层和 TCP 传输层之间的数据交互是大小不等的数据块，但是 TCP 把这些数据块仅仅看成一连串无结构的字节流，没有边界；</li><li>从 TCP 的帧结构也可以看出，在 TCP 的首部没有表示数据长度的字段。</li></ol><p>基于上面两点，在使用 TCP 传输数据时，才有粘包或者拆包现象发生的可能。一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为粘包。</p><p>接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了拆包和粘包。拆包和粘包的问题导致接收端在处理的时候会非常困难，因为无法区分一个完整的数据包。</p><h2 id="TCP-黏包是怎么产生的？"><a href="#TCP-黏包是怎么产生的？" class="headerlink" title="TCP 黏包是怎么产生的？"></a>TCP 黏包是怎么产生的？</h2><p><strong>发送方产生粘包</strong></p><p>采用 TCP 协议传输数据的客户端与服务器经常是保持一个长连接的状态（一次连接发一次数据不存在粘包），双方在连接不断开的情况下，可以一直传输数据。但当发送的数据包过于的小时，那么 TCP 协议默认的会启用 Nagle 算法，将这些较小的数据包进行合并发送（缓冲区数据发送是一个堆压的过程）；这个合并过程就是在发送缓冲区中进行的，也就是说数据发送出来它已经是粘包的状态了。</p><p><strong>接收方产生粘包</strong></p><p>接收方采用 TCP 协议接收数据时的过程是这样的：数据到接收方，从网络模型的下方传递至传输层，传输层的 TCP 协议处理是将其放置接收缓冲区，然后由应用层来主动获取（C 语言用 recv、read 等函数）；这时会出现一个问题，就是我们在程序中调用的读取数据函数不能及时的把缓冲区中的数据拿出来，而下一个数据又到来并有一部分放入的缓冲区末尾，等我们读取数据时就是一个粘包。（放数据的速度 &gt; 应用层拿数据速度）</p><h2 id="怎么解决拆包和粘包？"><a href="#怎么解决拆包和粘包？" class="headerlink" title="怎么解决拆包和粘包？"></a>怎么解决拆包和粘包？</h2><p>分包机制一般有两个通用的解决方法：</p><ol><li>特殊字符控制；</li><li>在包头首都添加数据包的长度。</li></ol><p>如果使用 netty 的话，就有专门的编码器和解码器解决拆包和粘包问题了。</p><p>tips：UDP 没有粘包问题，但是有丢包和乱序。不完整的包是不会有的，收到的都是完全正确的包。传送的数据单位协议是 UDP 报文或用户数据报，发送的时候既不合并，也不拆分。</p><h2 id="forward-和-redirect-的区别？"><a href="#forward-和-redirect-的区别？" class="headerlink" title="forward 和 redirect 的区别？"></a>forward 和 redirect 的区别？</h2><p>Forward 和 Redirect 代表了两种请求转发方式：直接转发和间接转发。</p><p><strong>直接转发方式（Forward）</strong>：客户端和浏览器只发出一次请求，Servlet、HTML、JSP 或其它信息资源，由第二个信息资源响应该请求，在请求对象 request 中，保存的对象对于每个信息资源是共享的。</p><p><strong>间接转发方式（Redirect）</strong>：实际是两次 HTTP 请求，服务器端在响应第一次请求的时候，让浏览器再向另外一个 URL 发出请求，从而达到转发的目的。</p><h2 id="谈谈你对域名缓存的了解？"><a href="#谈谈你对域名缓存的了解？" class="headerlink" title="谈谈你对域名缓存的了解？"></a>谈谈你对域名缓存的了解？</h2><p>为了提高 DNS 查询效率，并减轻服务器的负荷和减少因特网上的 DNS 查询报文数量，在域名服务器中广泛使用了高速缓存，用来存放最近查询过的域名以及从何处获得域名映射信息的记录。</p><p>由于名字到地址的绑定并不经常改变，为保持高速缓存中的内容正确，域名服务器应为每项内容设置计时器并处理超过合理时间的项（例如：每个项目两天）。<strong>当域名服务器已从缓存中删去某项信息后又被请求查询该项信息，就必须重新到授权管理该项的域名服务器绑定信息</strong>。当权限服务器回答一个查询请求时，在响应中都指明绑定有效存在的时间值。增加此时间值可减少网络开销，而减少此时间值可提高域名解析的正确性。</p><p>不仅在本地域名服务器中需要高速缓存，在主机中也需要。许多主机在启动时从本地服务器下载名字和地址的全部数据库，维护存放自己最近使用的域名的高速缓存，并且只在从缓存中找不到名字时才使用域名服务器。维护本地域名服务器数据库的主机应当定期地检查域名服务器以获取新的映射信息，而且主机必须从缓存中删除无效的项。由于域名改动并不频繁，大多数网点不需花精力就能维护数据库的一致性。</p><h2 id="HTTP-和-HTTPS-的区别？"><a href="#HTTP-和-HTTPS-的区别？" class="headerlink" title="HTTP 和 HTTPS 的区别？"></a>HTTP 和 HTTPS 的区别？</h2><ol><li><strong>开销</strong>：HTTPS 协议需要到 CA 申请证书，一般免费证书很少，需要交费；</li><li><strong>资源消耗</strong>：HTTP 是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的 ssl 加密传输协议，需要消耗更多的 CPU 和内存资源；</li><li><strong>端口不同</strong>：HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是  80，后者是 443；</li><li><strong>安全性</strong>：HTTP 的连接很简单，是无状态的；HTTPS 协议是由 TSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。</li></ol><h2 id="HTTPS-的优缺点？"><a href="#HTTPS-的优缺点？" class="headerlink" title="HTTPS 的优缺点？"></a>HTTPS 的优缺点？</h2><p><strong>优点：</strong></p><ol><li>使用 HTTPS 协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；</li><li>HTTPS 协议是由 SSL + HTTP 协议构建的可进行加密传输、身份认证的网络协议，要比 HTTP 协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性；</li><li>HTTPS 是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。</li></ol><p><strong>缺点：</strong></p><ol><li>HTTPS 协议握手阶段比较费时，会使页面的加载时间延长近 50%，增加 10% 到 20% 的耗电；</li><li>HTTPS 连接缓存不如 HTTP 高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响；</li><li>SSL 证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用；</li><li>SSL 证书通常需要绑定 IP，不能在同一 IP 上绑定多个域名，IPv4 资源不可能支撑这个消耗；</li><li>HTTPS 协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用。最关键的，SSL 证书的信用链体系并不安全，特别是在某些国家可以控制 CA 根证书的情况下，中间人攻击一样可行。</li></ol><h2 id="什么是数字签名？"><a href="#什么是数字签名？" class="headerlink" title="什么是数字签名？"></a>什么是数字签名？</h2><p>为了避免数据在传输过程中被替换，比如黑客修改了你的报文内容，但是你并不知道，所以我们让发送端做一个数字签名，把数据的摘要消息进行一个加密，比如 MD5，得到一个签名，和数据一起发送。然后接收端把数据摘要进行 MD5 加密，如果和签名一样，则说明数据确实是真的。</p><h2 id="什么是数字证书？"><a href="#什么是数字证书？" class="headerlink" title="什么是数字证书？"></a>什么是数字证书？</h2><p>对称加密中，双方使用公钥进行解密。虽然数字签名可以保证数据不被替换，但是数据是由公钥加密的，如果公钥也被替换，则仍然可以伪造数据，因为用户不知道对方提供的公钥其实是假的。所以为了保证发送方的公钥是真的，CA 证书机构会负责颁发一个证书，里面的公钥保证是真的，用户请求服务器时，服务器将证书发给用户，这个证书是经由系统内置证书的备案的。</p><h2 id="什么是对称加密和非对称加密？"><a href="#什么是对称加密和非对称加密？" class="headerlink" title="什么是对称加密和非对称加密？"></a>什么是对称加密和非对称加密？</h2><p>对称密钥加密是指加密和解密使用同一个密钥的方式，这种方式存在的最大问题就是密钥发送问题，即如何安全地将密钥发给对方。</p><p>非对称加密指使用一对非对称密钥，即：公钥和私钥，公钥可以随意发布，但私钥只有自己知道。发送密文的一方使用对方的公钥进行加密处理，对方接收到加密信息后，使用自己的私钥进行解密。</p><p>由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性。但是和对称加密比起来，它非常的慢，所以我们还是要用对称加密来传送消息，但对称加密所使用的密钥我们可以通过非对称加密的方式发送出去。</p><h2 id="Session和Cookie的区别？"><a href="#Session和Cookie的区别？" class="headerlink" title="Session和Cookie的区别？"></a>Session和Cookie的区别？</h2><p>Cookie是保存在客户端的一小块文本串的数据。客户端向服务器发起请求时，服务端会向客户端发送一个Cookie，客户端就把Cookie保存起来。在客户端下次向同一服务器再发起请求时，Cookie被携带发送到服务器。服务器就是根据这个Cookie来确认身份的。</p><p>Session 指的就是服务器和客户端一次会话的过程。Session 利用 Cookie 进行信息处理的，当用户首先进行了请求后，服务端就在用户浏览器上创建了一个Cookie，当这个 Session 结束时，其实就是意味着这个Cookie就过期了。Session对象存储着特定用户会话所需的属性及配置信息。</p><ul><li>用户第一次请求服务器时，服务器根据用户提交的信息，创建对应的 Session，请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器，浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入 Cookie 中，同时 Cookie 记录此 SessionID 是属于哪个域名。</li><li>当用户第二次访问服务器时，请求会自动判断此域名下是否存在Cookie信息，如果存在，则自动将Cookie信息也发送给服务端，服务端会从Cookie中获取SessionID，再根据 SessionID查找对应的 Session信息，如果没有找到，说明用户没有登录或者登录失效，如果找到Session证明用户已经登录可执行后面操作。</li></ul><h2 id="有了IP地址，为什么还要用MAC地址？"><a href="#有了IP地址，为什么还要用MAC地址？" class="headerlink" title="有了IP地址，为什么还要用MAC地址？"></a>有了IP地址，为什么还要用MAC地址？</h2><p>标识网络中的一台计算机，比较常用的就是IP地址和MAC地址，但<strong>计算机的IP地址可由用户自行更改，管理起来就相对困难，而MAC地址不可更改</strong>，所以一般会把IP地址和MAC地址组合起来使用。</p><ul><li>那只使用MAC地址不用IP地址行不行呢？不行的！因为最早就是MAC地址先出现的，并且当时并不用 IP 地址，<strong>只用MAC地址，后来随着网络中的设备越来越多，整个路由过程越来越复杂</strong>，便出现了子网的概念。对于目的地址在其他子网的数据包，路由只需要将数据包送到那个子网即可。</li><li>那为什么要用IP地址呢？是因为IP地址是和地域相关的，对于同一个子网上的设备，IP地址的前缀都是一样的，这样<strong>路由器通过IP地址的前缀就知道设备在在哪个子网上了，而只用MAC地址的话，路由器则需要记住每个MAC地址在哪个子网，这需要路由器有极大的存储空间</strong>，是无法实现的。</li></ul><p>IP地址可以比作为地址，MAC地址为收件人，在一次通信过程中，两者是缺一不可的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;网络基础&quot;&gt;&lt;a href=&quot;#网络基础&quot; class=&quot;headerlink&quot; title=&quot;网络基础&quot;&gt;&lt;/a&gt;网络基础&lt;/h1&gt;&lt;h2 id=&quot;1-TCP-IP-网络模型有哪几层？&quot;&gt;&lt;a href=&quot;#1-TCP-IP-网络模型有哪几层？&quot; class=&quot;</summary>
      
    
    
    
    
    <category term="Offer" scheme="http://example.com/tags/Offer/"/>
    
  </entry>
  
  <entry>
    <title>操作系统</title>
    <link href="http://example.com/2024/06/09/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    <id>http://example.com/2024/06/09/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</id>
    <published>2024-06-09T07:46:57.000Z</published>
    <updated>2024-06-09T07:47:16.399Z</updated>
    
    <content type="html"><![CDATA[<h1 id="硬件结构"><a href="#硬件结构" class="headerlink" title="硬件结构"></a>硬件结构</h1><h2 id="1-冯诺依曼模型"><a href="#1-冯诺依曼模型" class="headerlink" title="1.冯诺依曼模型"></a>1.冯诺依曼模型</h2><p>运算器、控制器、存储器、输入设备、输出设备</p><p>运算器、控制器是在中央处理器里的，存储器就我们常见的内存，输入输出设备则是计算机外接的设备，比如键盘就是输入设备，显示器就是输出设备。</p><p>存储单元和输入输出设备要与中央处理器打交道离不开总线。</p><p><strong>内存</strong>：存储的区域是线性的，存储数据的基本单位是字节（byte），1 字节等于 8 位（8 bit）。每一个字节都对应一个内存地址。内存的地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1。</p><p><strong>中央处理器</strong>：CPU，32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据（32位4字节，64位8字节）。</p><p><strong>常见的寄存器种类：</strong></p><ul><li><strong>通用寄存器</strong>，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。</li><li><strong>程序计数器</strong>，用来存储 CPU 要执行下一条指令「所在的<strong>内存地址</strong>」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令「的地址」。</li><li><strong>指令寄存器</strong>，用来存放当前正在执行的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里。</li></ul><p><strong>总线</strong>：用于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种：</p><ul><li><strong>地址总线</strong>，用于指定 CPU 将要操作的内存地址；</li><li><strong>数据总线</strong>，用于读写内存的数据；</li><li><strong>控制总线</strong>，用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线；</li></ul><h2 id="2-程序执行的基本过程"><a href="#2-程序执行的基本过程" class="headerlink" title="2.程序执行的基本过程"></a>2.程序执行的基本过程</h2><p>一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。</p><p>CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束，这个不断循环的过程被称为 CPU 的<strong>指令周期</strong>。</p><p>CPU 执行程序的过程如下：</p><ul><li>第一步，CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个指令数据存入到「指令寄存器」。</li><li>第二步，「程序计数器」的值自增，表示指向下一条指令。这个自增的大小，由 CPU 的位宽决定，比如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会自增 4；</li><li>第三步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执行；</li></ul><blockquote><p>数据和指令是分开区域存放的，存数据的是「数据段」，存放指令区域的地方称为「正文段」。</p></blockquote><blockquote><p>指令的内容是一串二进制数字的机器码，每条指令都有对应的机器码，CPU 通过解析机器码来知道指令的内容；不同的 CPU 有不同的指令集，也就是对应着不同的汇编语言和不同的机器码。</p></blockquote><h2 id="3-CPU-指令周期的四个阶段？"><a href="#3-CPU-指令周期的四个阶段？" class="headerlink" title="3.CPU 指令周期的四个阶段？"></a>3.CPU 指令周期的四个阶段？</h2><p>大多数 CPU 都使用来流水线的方式来执行指令，所谓的流水线就是把一个任务拆分成多个小任务，于是一条指令通常分为 4 个阶段：</p><ol><li>CPU 通过程序计数器读取（控制器）对应内存地址（存储器）的指令，这个部分称为 Fetch（取得指令）；</li><li>CPU 对指令进行解码（控制器），这个部分称为 Decode（指令译码）；</li><li>CPU 执行指令（运算器、控制器），这个部分称为 Execution（执行指令）；</li><li>CPU 将计算结果存回寄存器或者将寄存器的值存入内存，这个部分称为 Store（数据回写）；</li></ol><h2 id="4-指令的类型与执行速度"><a href="#4-指令的类型与执行速度" class="headerlink" title="4.指令的类型与执行速度"></a>4.指令的类型与执行速度</h2><p>指令从功能角度划分，可以分为 5 大类：</p><ol><li><strong>数据传输</strong>类型的指令，比如 store&#x2F;load 是寄存器与内存间数据传输的指令，mov 是将一个内存地址的数据移动到另一个内存地址的指令；</li><li><strong>运算</strong>类型的指令，比如加减乘除、位运算、比较大小等等，它们最多只能处理两个寄存器中的数据；</li><li><strong>跳转</strong>类型的指令，通过修改程序计数器的值来达到跳转执行指令的过程，比如编程中常见的 if-else、switch-case、函数调用等。</li><li><strong>信号</strong>类型的指令，比如发生中断的指令 trap；</li><li><strong>闲置</strong>类型的指令，比如指令 nop，执行后 CPU 会空转一个周期；</li></ol><p>对于 CPU 来说，在一个时钟周期内，CPU 仅能完成一个最基本的动作，时钟频率越高，时钟周期就越短，工作速度也就越快。</p><blockquote><p> 1 GHz 的 CPU，指的是时钟频率是 1 G，代表着 1 秒会产生 1G 次数的脉冲信号，每一次脉冲信号高低电平的转换就是一个周期，称为时钟周期。</p></blockquote><p><font color = "#F100">程序的 CPU 执行时间 &#x3D; CPU 时钟周期数（CPU Cycles）和时钟周期时间（Clock Cycle Time）的乘积 </font></p><p><font color = "#F100"> CPU 时钟周期数 &#x3D; 指令数 与 每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI）的乘积</font></p><p>因此，<font color="#F8A"><strong>程序的 CPU 执行时间 &#x3D; 指令数 * CPI *  时钟周期时间</strong> </font></p><ul><li>指令数，表示执行程序所需要多少条指令，以及哪些指令。这个层面是基本靠编译器来优化，毕竟同样的代码，在不同的编译器，编译出来的计算机指令会有各种不同的表示方式。</li><li>每条指令的平均时钟周期数 CPI，表示一条指令需要多少个时钟周期数，现代大多数 CPU 通过流水线技术（Pipeline），让一条指令需要的 CPU 时钟周期数尽可能的少;</li><li>时钟周期时间，表示计算机主频，取决于计算机硬件。有的 CPU 支持超频技术，打开了超频意味着把 CPU 内部的时钟给调快了，于是 CPU 工作速度就变快了，但是也是有代价的，CPU 跑的越快，散热的压力就会越大，CPU 会很容易奔溃。</li></ul><h2 id="5-磁盘与内存"><a href="#5-磁盘与内存" class="headerlink" title="5.磁盘与内存"></a>5.磁盘与内存</h2><ul><li><strong>寄存器</strong>：每个寄存器可以用来存储一定的字节（byte）的数据。32 位 CPU 中大多数寄存器可以存储 4 个字节，64位可以存储 8 个字节。</li><li><strong>CPU Cache</strong>：用的是一种叫 SRAM（Static Random-Access Memory，静态随机存储器） 的芯片。一旦<strong>断电，数据就会丢失</strong>了。CPU 的高速缓存，通常可以分为 L1、L2、L3 这样的三层高速缓存，也称为一级缓存、二级缓存、三级缓存。每个 CPU 核心都有一块属于自己的 L1 高速缓存，指令和数据在 L1 是分开存放的，所以 L1 高速缓存通常分成 <strong>指令缓存</strong> 和 <strong>数据缓存</strong> 。L1 Cache 和 L2 Cache 都是每个 CPU 核心独有的，而 L3 Cache 是多个 CPU 核心共享的。</li><li><strong>内存</strong>：使用的是一种叫作 DRAM （Dynamic Random Access Memory，动态随机存取存储器） 的芯片。需要「<strong>定时刷新</strong>」，才能保证数据不会被丢失。</li><li><strong>SSD&#x2F;HDD 硬盘</strong>：SSD（Solid-state disk） 固体硬盘与 HDD（Hard Disk Drive）机械硬盘。</li></ul><p><strong>每个存储器只和相邻的一层存储器设备打交道</strong>，并且存储设备为了追求更快的速度，所需的材料成本必然也是更高，也正因为成本太高，所以 CPU 内部的寄存器、L1\L2\L3 Cache 只好用较小的容量，相反内存、硬盘则可用更大的容量。</p><p>另外，当 CPU 需要访问内存中某个数据的时候，如果寄存器有这个数据，CPU 就直接从寄存器取数据即可，如果寄存器没有这个数据，CPU 就会查询 L1 高速缓存，如果 L1 没有，则查询 L2 高速缓存，L2 还是没有的话就查询 L3 高速缓存，L3 依然没有的话，才去内存中取数据。</p><h2 id="6-CPU-Cache-的数据结构和读取过程是什么样的？"><a href="#6-CPU-Cache-的数据结构和读取过程是什么样的？" class="headerlink" title="6.CPU Cache 的数据结构和读取过程是什么样的？"></a>6.CPU Cache 的数据结构和读取过程是什么样的？</h2><p>CPU Cache 是由很多个Cache Line（缓存块）组成的，Cache Line 是 CPU 从内存读取数据的基本单位，而 Cache Line 是由各种标志（Tag）+ 数据块（Data Block）组成。</p><p>CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的，而不是按照单个数组元素来读取数据的，具体这一小块数据的大小，取决于 <code>coherency_line_size</code> 的值，一般 64 字节。在内存中，这一块的数据我们称为<strong>内存块（Block）</strong>，读取的时候我们要拿到数据所在内存块的地址。</p><p>对于直接映射 Cache 采用的策略，就是<strong>把内存块的地址始终「映射」在一个 CPU Cache Line（缓存块） 的地址</strong>，至于映射关系实现方式，则是使用「取模运算」，取模运算的结果就是内存块地址对应的 CPU Cache Line（缓存块） 的地址。</p><p>为了区别不同的内存块，在对应的 CPU Cache Line 中我们还会存储一个<strong>组标记</strong>（Tag）。这个组标记会记录当前 CPU Cache Line 中存储的数据对应的内存块，我们可以用这个组标记来区分不同的内存块。</p><blockquote><p>除了<strong>组标记</strong>信息外，CPU Cache Line 还有两个信息：</p></blockquote><blockquote><ul><li>一个是，从内存加载过来的<strong>实际存放数据（Data）</strong>。</li><li>另一个是，<strong>有效位（Valid bit）</strong>，它是用来标记对应的 CPU Cache Line 中的数据是否是有效的，如果有效位是 0，无论 CPU Cache Line 中是否有数据，CPU 都会直接访问内存，重新加载数据。</li></ul></blockquote><p>CPU 在从 CPU Cache 读取数据的时候，<strong>并不是读取 CPU Cache Line 中的整个数据块</strong>，而是读取 CPU 所需要的一个数据片段，这样的数据统称为一个<strong>字（Word）</strong>。</p><p><font color="#F100">一个内存的访问地址，包括<strong>组标记</strong>、<strong>CPU Cache Line 索引</strong>、<strong>偏移量</strong>这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。而对于 CPU Cache 里的数据结构，则是由<strong>索引 + 有效位 + 组标记 + 数据块</strong>组成。</font></p><p>如果内存中的数据已经在 CPU Cache 中了，那 CPU 访问一个内存地址的时候，会经历这 4 个步骤：</p><ol><li>根据内存地址中索引信息，计算在 CPU Cache 中的索引，也就是找出对应的 CPU Cache Line 的地址；</li><li>找到对应 CPU Cache Line 后，判断 CPU Cache Line 中的有效位，确认 CPU Cache Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行；</li><li>对比内存地址中组标记和 CPU Cache Line 中的组标记，确认 CPU Cache Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行；</li><li>根据内存地址中偏移量信息，从 CPU Cache Line 的数据块中，读取对应的字。</li></ol><h2 id="7-CPU-Cache-的数据写入"><a href="#7-CPU-Cache-的数据写入" class="headerlink" title="7.CPU Cache 的数据写入"></a>7.CPU Cache 的数据写入</h2><p><strong>写直达</strong>：把数据同时写入内存和 Cache 中。</p><ul><li>如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；</li><li>如果数据没有在 Cache 里面，就直接把数据更新到内存里面。</li></ul><p><strong>写回</strong>：当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中。</p><ul><li><p>如果当发生写操作时，数据已经在 CPU Cache 里的话，则把数据更新到 CPU Cache 里，同时标记 CPU Cache 里的这个 Cache Block 为脏（Dirty）的，这个脏的标记代表<strong>这个时候CPU Cache 里面的这个 Cache Block 的数据和内存是不一致的</strong>，这种情况是不用把数据写到内存里的；</p></li><li><p>如果当发生写操作时，数据所对应的 Cache Block 里存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block 里的数据有没有被标记为脏的：</p></li><li><p>1.如果是脏的话，我们就要把这个 Cache Block 里的数据写回到内存，然后再把当前要写入的数据，先从内存读入到 Cache Block 里，然后再把当前要写入的数据写入到 Cache Block，最后也把它标记为脏的；</p></li><li><p>2.如果不是脏的话，把当前要写入的数据先从内存读入到 Cache Block 里，接着将数据写入到这个 Cache Block 里，然后再把这个 Cache Block 标记为脏的就好了。</p></li></ul><p><font color="#F100">在把数据写入到 Cache 的时候，只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，而在缓存命中的情况下，则在写入后 Cache 后，只需把该数据对应的 Cache Block 标记为脏即可，而不用写到内存里。</font></p><h2 id="8-CPU缓存的一致性"><a href="#8-CPU缓存的一致性" class="headerlink" title="8.CPU缓存的一致性"></a>8.CPU缓存的一致性</h2><p>想实现缓存一致性，关键是要满足 2 点：</p><ul><li>第一点是<strong>写传播</strong>，也就是当某个 CPU 核心发生写入操作时，需要把该事件广播通知给其他核心；</li><li>第二点是<strong>事物的串行化</strong>，这个很重要，只有保证了这个，才能保障我们的数据是真正一致的，我们的程序在各个不同的核心上运行的结果也是一致的；</li></ul><p>基于总线嗅探机制的 MESI 协议，就满足上面了这两点，因此它是保障缓存一致性的协议。</p><p>MESI 协议，是<strong>已修改、独占、共享、已失效</strong>这四个状态的英文缩写的组合。整个 MSI 状态的变更，则是根据来自本地 CPU 核心的请求，或者来自其他 CPU 核心通过总线传输过来的请求，从而构成一个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache Line，修改更新其数据不需要发送广播给其他 CPU 核心。</p><p><a href="https://www.scss.tcd.ie/Jeremy.Jones/vivio/caches/MESI.htm">MESI 协议可视化</a></p><h2 id="9-CPU-是如何执行任务的？"><a href="#9-CPU-是如何执行任务的？" class="headerlink" title="9.CPU 是如何执行任务的？"></a>9.CPU 是如何执行任务的？</h2><p>CPU 读写数据的时候，每一次都是以 64 字节大小为一块进行操作</p><p>如果我们操作的数据是数组，那么访问数组元素的时候，按内存分布的地址顺序进行访问，这样能充分利用到 Cache，程序的性能得到提升。但如果操作的数据不是数组，而是普通的变量，并在多核 CPU 的情况下，我们还需要避免 Cache Line 伪共享的问题。</p><p>因为多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象称为<strong>伪共享（False Sharing）</strong></p><p>对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同一个 Cache Line 中，避免的方式一般有 Cache Line 大小字节对齐，以及字节填充等方法。</p><p>系统中需要运行的多线程数一般都会大于 CPU 核心，这样就会导致线程排队等待 CPU，这可能会产生一定的延时，如果我们的任务对延时容忍度很低，则可以通过一些人为手段干预 Linux 的默认调度策略和优先级。（priority(new) &#x3D; priority(old) + nice）</p><h2 id="10-什么是软中断？"><a href="#10-什么是软中断？" class="headerlink" title="10.什么是软中断？"></a>10.什么是软中断？</h2><p><strong>中断</strong>是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。</p><p>中断是一种异步的事件处理机制，可以提高系统的并发处理能力。</p><p>中断请求的响应程序，也就是中断处理程序，要<strong>尽可能快的执行完</strong>，这样可以减少对正常进程运行调度地影响。</p><p>Linux 系统为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」</p><ul><li>上半部用来快速处理中断，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。</li><li>下半部用来延迟处理上半部未完成的工作，一般以「内核线程」的方式运行。<br>中断处理程序的上部分和下半部可以理解为：</li></ul><p>上半部直接处理硬件请求，也就是<strong>硬中断</strong>，主要是负责耗时短的工作，特点是快速执行；</p><p>下半部是由内核触发，也就说<strong>软中断</strong>，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行；</p><h2 id="11-计算机是怎么存小数的？"><a href="#11-计算机是怎么存小数的？" class="headerlink" title="11.计算机是怎么存小数的？"></a>11.计算机是怎么存小数的？</h2><p>计算机是以浮点数的形式存储小数的，大多数计算机都是 IEEE 754 标准定义的浮点数格式，包含三个部分：</p><ul><li><strong>符号位</strong>：表示数字是正数还是负数，为 0 表示正数，为 1 表示负数；</li><li><strong>指数位</strong>：指定了小数点在数据中的位置，指数可以是负数，也可以是正数，指数位的长度越长则数值的表达范围就越大；</li><li><strong>尾数位</strong>：小数点右侧的数字，也就是小数部分，比如二进制 1.0011 x 2^(-2)，尾数部分就是 0011，而且尾数的长度决定了这个数的精度，因此如果要表示精度更高的小数，则就要提高尾数位的长度；</li></ul><h2 id="12-Linux中按下电源到展现命令行的过程是怎样的？"><a href="#12-Linux中按下电源到展现命令行的过程是怎样的？" class="headerlink" title="12.Linux中按下电源到展现命令行的过程是怎样的？"></a>12.Linux中按下电源到展现命令行的过程是怎样的？</h2><p>步骤1 - 当我们启动电源时，BIOS（基本输入&#x2F;输出系统）或UEFI（统一可扩展固件接口）固件从非易失性存储器加载，并执行POST（上电自检）。</p><p>步骤2 - BIOS&#x2F;UEFI检测连接到系统的设备，包括CPU、RAM和存储。</p><p>步骤3 - 选择一个启动设备以从中引导操作系统。这可以是硬盘、网络服务器或光盘驱动器。</p><p>步骤4 - BIOS&#x2F;UEFI运行引导加载程序（GRUB），该加载程序提供一个菜单，用于选择操作系统或内核功能。</p><p>步骤5 - 内核准备好后，我们现在切换到用户空间。内核启动systemd作为第一个用户空间进程，它管理进程和服务，探测所有剩余的硬件，挂载文件系统，并运行桌面环境。</p><p>步骤6 - systemd默认在系统引导时激活默认的.target单元。其他分析单元也会被执行。</p><p>步骤7 - 系统运行一系列启动脚本并配置环境。</p><p>步骤8 - 用户被呈现出登录窗口。系统现在已经准备就绪。</p><p><a href="https://zhuanlan.zhihu.com/p/670742766">https://zhuanlan.zhihu.com/p/670742766</a></p><hr><h1 id="操作系统结构"><a href="#操作系统结构" class="headerlink" title="操作系统结构"></a>操作系统结构</h1><h2 id="1-Linux-内核"><a href="#1-Linux-内核" class="headerlink" title="1.Linux 内核"></a>1.Linux 内核</h2><p>内核一般会提供 4 个基本能力：</p><ol><li>管理进程、线程，决定哪个进程、线程使用 CPU，也就是<strong>进程调度</strong>的能力；</li><li>管理内存，决定内存的分配和回收，也就是<strong>内存管理</strong>的能力；</li><li>管理硬件设备，为进程与硬件设备之间提供通信能力，也就是<strong>硬件通信</strong>能力；</li><li>提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是<strong>用户程序与操作系统之间的接口</strong>。</li></ol><h2 id="2-Linux-内核设计的理念"><a href="#2-Linux-内核设计的理念" class="headerlink" title="2.Linux 内核设计的理念"></a>2.Linux 内核设计的理念</h2><ol><li>MultiTask，多任务（并发或并行）</li><li>SMP，对称多处理（ CPU 地位相等）</li><li>ELF，可执行文件链接格式（Linux 可执行文件格式叫作 ELF，Windows 可执行文件格式叫作 PE）</li><li>Monolithic Kernel，宏内核（内核是一个完整的可执行程序，且拥有最高的权限）</li></ol><p>内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。</p><h2 id="3-内核的架构种类"><a href="#3-内核的架构种类" class="headerlink" title="3.内核的架构种类"></a>3.内核的架构种类</h2><ol><li>宏内核，包含多个模块，整个内核像一个完整的程序；</li><li>微内核，有一个最小版本的内核，一些模块和服务则由用户态管理；</li><li>混合内核，是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有一个小型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序；</li></ol><p>Linux 的内核设计是采用了宏内核，Window 的内核设计则是采用了混合内核。华为的鸿蒙操作系统的内核架构是微内核。</p><hr><h1 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h1><h2 id="1-虚拟内存有什么作用？"><a href="#1-虚拟内存有什么作用？" class="headerlink" title="1.虚拟内存有什么作用？"></a>1.虚拟内存有什么作用？</h2><ul><li>第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。</li><li>第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。</li><li>第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。<blockquote><p><strong>局部性原理</strong>是指CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中。</p></blockquote></li></ul><h2 id="2-操作系统是如何管理虚拟地址与物理地址之间的关系？"><a href="#2-操作系统是如何管理虚拟地址与物理地址之间的关系？" class="headerlink" title="2.操作系统是如何管理虚拟地址与物理地址之间的关系？"></a>2.操作系统是如何管理虚拟地址与物理地址之间的关系？</h2><p>主要有两种方式，分别是内存分段和内存分页；</p><p>程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用<strong>分段</strong>（Segmentation）的形式把这些段分离出来。</p><p>分段机制下的虚拟地址由两部分组成，<strong>段选择因子</strong>和<strong>段内偏移量</strong>。</p><blockquote><p>段选择因子和段内偏移量：</p><ul><li>段选择子就保存在段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。</li><li>虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。</li></ul></blockquote><p>分段（根据实际需求分配内存）解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：</p><ul><li>第一个就是内存碎片（外部内存碎片）的问题。</li><li>第二个就是内存交换的效率低的问题。</li></ul><p><font color="#F1000">分段的好处就是能产生连续的内存空间，但是会出现「外部内存碎片和内存交换的空间太大」的问题。</font></p><p><strong>分页</strong>是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。</p><p>虚拟地址与物理地址之间通过页表来映射。页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。</p><p><font color="#F1000">当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。</font></p><p>分页机制分配内存的最小单位是一页，即使程序不足一页大小，最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制会有<strong>内部内存碎片</strong>的现象。</p><p>在分页机制下，<strong>虚拟地址分为两部分，页号和页内偏移</strong>。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址</p><p><strong>段页式内存管理</strong> 的方式：</p><ul><li>先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；</li><li>接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；</li></ul><p>地址结构就由<strong>段号</strong>、<strong>段内页号</strong>和<strong>页内位移</strong>三部分组成。</p><blockquote><p>Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。</p></blockquote><h2 id="3-Linux-的虚拟地址空间是如何分布的？"><a href="#3-Linux-的虚拟地址空间是如何分布的？" class="headerlink" title="3.Linux 的虚拟地址空间是如何分布的？"></a>3.Linux 的虚拟地址空间是如何分布的？</h2><p>虚拟地址空间的内部又被分为<strong>内核空间</strong>和<strong>用户空间</strong>两部分，不同位数的系统，地址空间的范围也不同。</p><p>虽然每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实<strong>关联的都是相同的物理内存</strong>。</p><p>用户空间内存，从低到高分别是 6 种不同的内存段：</p><ul><li>代码段，包括二进制可执行代码；</li><li>数据段，包括已初始化的静态常量和全局变量；</li><li>BSS(Block Started by Symbol) 段（Unix链接器产生的未初始化数据段），包括未初始化的静态变量和全局变量；</li><li>堆段，包括动态分配的内存，从低地址开始向上增长；</li><li>文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关 (opens new window)）；</li><li>栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；</li></ul><h2 id="4-malloc-是如何分配内存的？"><a href="#4-malloc-是如何分配内存的？" class="headerlink" title="4.malloc 是如何分配内存的？"></a>4.malloc 是如何分配内存的？</h2><p>malloc() 并不是系统调用，而是 C 库里的函数，用于动态分配内存。</p><p>malloc 申请内存的时候，会有两种方式向操作系统申请堆内存。</p><ul><li>方式一：通过 brk() 系统调用从堆分配内存（通过 brk() 函数将「堆顶」指针向高地址移动，获得新的内存空间）</li><li>方式二：通过 mmap() 系统调用在文件映射区域分配内存（私有匿名映射）；</li></ul><blockquote><p>brk() 函数是一个系统调用，用于改变进程的结束地址（end of data segment），从而控制进程使用的堆内存大小。当应用程序需要分配更多的内存时，可以通过 brk() 调整堆区边界，增加可用内存大小。</p></blockquote><p>malloc() 源码里默认定义了一个阈值：</p><ul><li>如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；</li><li>如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；</li></ul><p><font color="#F100">malloc() 分配的是虚拟内存</font>，如果分配后的虚拟内存没有被访问的话，虚拟内存是不会映射到物理内存的；只有在访问已分配的虚拟地址空间的时候，操作系统通过查找页表，发现虚拟内存对应的页没有在物理内存中，就会触发<strong>缺页中断</strong>，然后操作系统会建立虚拟内存和物理内存之间的映射关系。</p><ul><li>malloc 通过 brk() 方式申请的内存，free 释放内存的时候，并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用；</li><li>malloc 通过 mmap() 方式申请的内存，free 释放内存的时候，会把内存归还给操作系统，内存得到真正的释放。</li></ul><h2 id="5-内存分配的过程是怎样的？"><a href="#5-内存分配的过程是怎样的？" class="headerlink" title="5.内存分配的过程是怎样的？"></a>5.内存分配的过程是怎样的？</h2><p>应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。</p><p>缺页中断处理函数会看是否有空闲的物理内存，如果有，就直接分配物理内存，并建立虚拟内存与物理内存之间的映射关系。</p><p>如果没有空闲的物理内存，那么内核就会开始进行回收内存的工作，回收的方式主要是两种：直接内存回收和后台内存回收。</p><ul><li><strong>后台内存回收（kswapd）</strong> ：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。</li><li><strong>直接内存回收（direct reclaim）</strong>：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。</li></ul><p>如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么触发 OOM （Out of Memory）机制。根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，直到释放足够的内存位置</p><p>可被回收的内存类型有<strong>文件页</strong>和<strong>匿名页</strong>：</p><ul><li>文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I&#x2F;O 的，这个操作是会影响系统性能的。</li><li>匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。</li></ul><p>可以调整文件页和匿名页的回收倾向，尽量倾向于回收文件页</p><blockquote><p>文件页（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。</p></blockquote><blockquote><p>匿名页（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。</p></blockquote><blockquote><p>文件页和匿名页的回收都是基于 LRU 算法（active 和 inactive 两个双向链表），越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。</p></blockquote><h2 id="6-在-4GB-物理内存的机器上，申请-8G-内存会怎么样？"><a href="#6-在-4GB-物理内存的机器上，申请-8G-内存会怎么样？" class="headerlink" title="6.在 4GB 物理内存的机器上，申请 8G 内存会怎么样？"></a>6.在 4GB 物理内存的机器上，申请 8G 内存会怎么样？</h2><ul><li>在 32 位操作系统，因为进程理论上最大能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。</li><li>在 64位 位操作系统，因为进程理论上最大能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：<ul><li>如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；</li><li>如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；</li></ul></li></ul><h2 id="7-如何避免预读失效和缓存污染的问题？"><a href="#7-如何避免预读失效和缓存污染的问题？" class="headerlink" title="7.如何避免预读失效和缓存污染的问题？"></a>7.如何避免预读失效和缓存污染的问题？</h2><p>传统的 LRU 算法法无法避免下面这两个问题：</p><ul><li>预读失效导致缓存命中率下降；</li><li>缓存污染导致缓存命中率下降；</li></ul><blockquote><p>预读失效（Predictive Prefetching Invalidation）是指在计算机系统中，特别是涉及到磁盘I&#x2F;O操作时，系统预测未来的数据访问模式并提前加载数据到缓存中，但实际的访问模式与预测不符，导致提前加载的数据变得不再需要，从而造成缓存空间的浪费。</p></blockquote><blockquote><p>缓存污染（Cache Pollution）是指在缓存中存储了大量不常用或不再需要的数据，这些数据占据了宝贵的缓存空间，导致有用的数据无法被缓存，从而降低了缓存效率。</p></blockquote><p>为了避免「预读失效」造成的影响，Linux 和 MySQL 对传统的 LRU 链表做了改进：</p><ul><li>Linux 操作系统实现两个了 LRU 链表：活跃 LRU 链表（active list）和非活跃 LRU 链表（inactive list）。</li><li>MySQL Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：young 区域 和 old 区域。</li></ul><p>但是如果还是使用「只要数据被访问一次，就将数据加入到活跃 LRU 链表头部（或者 young 区域）」这种方式的话，那么还存在<strong>缓存污染</strong>的问题。</p><p>为了避免「缓存污染」造成的影响，Linux 操作系统和 MySQL Innodb 存储引擎分别<strong>提高了升级为热点数据的门槛</strong>：</p><ul><li>Linux 操作系统：在内存页被访问第二次的时候，才将页从 inactive list 升级到 active list 里。</li><li>MySQL Innodb：在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行停留在 old 区域的时间判断：<ul><li>如果第二次的访问时间与第一次访问的时间在 1 秒内（默认值），那么该页就不会被从 old 区域升级到 young 区域；</li><li>如果第二次的访问时间与第一次访问的时间超过 1 秒，那么该页就会从 old 区域升级到 young 区域；</li></ul></li></ul><p>通过提高了进入 active list （或者 young 区域）的门槛后，就很好了避免缓存污染带来的影响。</p><h2 id="8-南桥和北桥"><a href="#8-南桥和北桥" class="headerlink" title="8.南桥和北桥"></a>8.南桥和北桥</h2><p>北桥芯片还有个名字叫“图形与内存控制器”，南桥叫“输入&#x2F;输出控制器”。</p><p>北桥芯片组因为与CPU联系密切所以它在主板靠近CPU的位置，而南桥芯片则在远离CPU的位置</p><p>北桥芯片(North Bridge)是主板芯片组中起主导作用的最重要的组成部分，也称为**主桥(Host Bridge)**，主要负责与CPU的联系并控制内存、AGP数据在北桥内部传输，提供对CPU的类型和主频、系统的前端总线频率、ECC纠错等支持。</p><p>南桥芯片主要是偏向于集成功能，主要负责I&#x2F;O总线之间的通信，如PCI总线、USB和高级电源管理等。</p><p>现在芯片已经没有北桥了，功能被集成到了CPU中。</p><h2 id="9-什么是虚拟内存？解决了什么问题？"><a href="#9-什么是虚拟内存？解决了什么问题？" class="headerlink" title="9.什么是虚拟内存？解决了什么问题？"></a>9.什么是虚拟内存？解决了什么问题？</h2><p>虚拟内存是操作系统内存管理的一种技术，每个进程启动时，操作系统会提供一个独立的虚拟地址空间，这个地址空间是连续的，进程可以很方便的访问内存，这里的内存指的是访问虚拟内存。虚拟内存的目的，一是方便进程进行内存的访问，二是可以使有限的物理内存运行一个比它大很多的程序。</p><p>虚拟内存的基本思想：每个程序拥有自己的地址空间，这个空间被分割成很多块，每块称为一页，每一页地址都是连续的地址范围。这些页被映射到物理内存，但不要求是连续的物理内存，也不需要所有的页都映射到物理内存，而是按需分配，在程序片段需要分配内存时由硬件执行映射(通常是 MMU)，调入内存中执行。</p><h2 id="10-说说分页和分段的机制？"><a href="#10-说说分页和分段的机制？" class="headerlink" title="10.说说分页和分段的机制？"></a>10.说说分页和分段的机制？</h2><p>分页是实现虚拟内存的技术，虚拟内存按照固定的大小分为页面，物理内存也会按照固定的大小分成页框，页面和页框大小通常是一样的，一般是 4KB，页面和页框可以实现一对一的映射。分页是一维的，主要是为了获得更大的线性地址空间。但是一个地址空间可能存在很多个表，表的数据大小是动态增长的，由于多个表都在一维空间中，有可能导致一个表的数据覆盖了另一个表。</p><p>分段是把虚拟内存划分为多个独立的地址空间，每个地址空间可以动态增长，互不影响。每个段可以单独进行控制，有助于保护和共享。</p><h2 id="11-页表的作用？为什么引入多级页表？"><a href="#11-页表的作用？为什么引入多级页表？" class="headerlink" title="11. 页表的作用？为什么引入多级页表？"></a>11. 页表的作用？为什么引入多级页表？</h2><p>页表实现了虚拟内存到物理内存的映射，当访问一个虚拟内存页面时，页面的虚拟地址将作为一个索引指向页表，如果页表中存在对应物理内存的映射，则直接返回物理内存的地址，否则将引发一个缺页异常，从而陷入到内核中分配物理内存，返回对应的物理地址，然后更新页表。</p><p>为了加快虚拟地址到物理地址的转换，多数系统会引入一个转换检测缓冲区（TLB）的设备，通常又称为快表，当请求访问一个虚拟地址时，处理器检查是否缓存了该虚拟地址的映射，如果命中则直接返回物理地址，否则就通过页表搜索对应的物理地址。</p><p>由于虚拟内存通常比较大(32 位系统通常是 4G)，要实现整个地址空间的映射，需要非常大的页表。解决的办法是引入多级页表，只将那些用到的页面装载进来，因此，多级页表可以大大节约地址转换所需要的的空间。</p><h2 id="12-页面置换算法有哪几种？"><a href="#12-页面置换算法有哪几种？" class="headerlink" title="12.页面置换算法有哪几种？"></a>12.页面置换算法有哪几种？</h2><p>访问的页面不在内存中时，会发生一个缺页异常，操作系统必须将该页换出内存，如果此时内存已满，则操作系统必须将其中一个页面换出，放到 swap 交换区中，为当前访问的页面腾出空间，这个过程称为页面置换。操作系统提供了多种页面置换算法：</p><p><strong>1.最优页面置换算法</strong></p><p>选择一个将来最长时间不会被访问的页面换出。这样可以保证将来最低的缺页率。这是一种理论上的算法，因为无法知道哪个页面是将来最长时间都不会被访问的</p><p><strong>2.最近未使用页面置换算法 (NRU)</strong></p><p>为每个页面设两个状态位：被访问时设置为 R&#x3D;1 位，页面被修改时，设置为 M&#x3D;1 位。当启动一个进程时，所有页面都被初始化为 R&#x3D;0，M&#x3D;0。其中 R 位会被定时的清 0，以此区分最近被访问的页面和没有被访问的页面。</p><p>于是所有页面可以分为以下 4 类：</p><ul><li>0 类：R&#x3D;0，M&#x3D;0；</li><li>1 类：R&#x3D;0，M&#x3D;1；</li><li>2 类：R&#x3D;1，M&#x3D;0；</li><li>3 类：R&#x3D;1，M&#x3D;1；</li></ul><p>当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出（挑选优先级：1 类 &gt; 2 类 &gt; 3 类）。</p><p><strong>3.最近最少未使用（LRU）页面置换算法</strong></p><p>在内存中维护一个所有页面的单链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。</p><p>因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。</p><p><strong>4.先进先出（FIFO）页面置换算法</strong></p><p>维护一个链表，最先进入的页面放在表头，最后进入的页面放在表尾，当缺页中断发生时，直接淘汰表头的页面，并把新的页面放在表尾。</p><p>这种算法有可能置换掉经常访问的页面，导致缺页率升高。</p><p><strong>5.第二次机会页面置换算法</strong></p><p>对 FIFO 算法做一个修改：取出表头的页面时，检查该页面的 R 位，如果是 1 表示是最近有访问的，将其清 0，然后放入表尾，然后继续检查下一个表头的页面，直到遇到一个 R 位为 0 的页面，将其换出。</p><p><strong>6.时钟页面置换算法</strong></p><p>单链表改成了环形链表，形成一个时钟，移动的也不是页面，而是中间的表针。检查页面逻辑类似，如果该页面 R 为 0，则直接置换该页面，否则将该 R 位清 0，然后表针向前移动。</p><h2 id="13-内存是如何分配的？"><a href="#13-内存是如何分配的？" class="headerlink" title="13.内存是如何分配的？"></a>13.内存是如何分配的？</h2><p>Linux 分配物理内存的主要机制是页面分配机制（页分配器），使用了著名的伙伴算法，主要用来分配页大小的整数倍的内存(4n KB)。如果是小于页大小的内存分配，通常使用 slab 管理器。通过 slab 分配的内存通常会缓存起来，方便下次使用。</p><h2 id="14-内存是如何回收的？"><a href="#14-内存是如何回收的？" class="headerlink" title="14.内存是如何回收的？"></a>14.内存是如何回收的？</h2><p>应用程序用完内存后，可以调用 free() 释放内存，或调用 unmap() 取消内存映射，归还系统。</p><p>在内存紧张时，会通过一系列机制来回收内存，如以下三种方式：</p><ul><li>回收缓存。主要是页缓存。</li><li>回收不常访问的页面。使用页面置换算法，把不常用的页面放到交换区中。</li><li>通过 OOM 杀死占用大量内存的进程，释放内存。</li></ul><hr><h1 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h1><h2 id="1-进程和线程的区别"><a href="#1-进程和线程的区别" class="headerlink" title="1.进程和线程的区别?"></a>1.进程和线程的区别?</h2><p>总的来说，进程是资源的容器，用来把资源集中到一起，而线程是在 CPU 上被实际调度的实体对象。</p><p>进程是资源分配的基本单位，进程中包括可执行的代码、打开的文件描述符、挂起的信号、进程的状态、内存地址空间、存放全局变量的数据段，以及一个或多个执行线程等。</p><p>线程是进程中活动的对象，或者说独立调度的基本单位。每个线程都拥有一个独立的程序计数器、线程堆栈和寄存器。</p><p>这里引申一个问题，有了进程为什么还要有线程？</p><ul><li>在一个进程中会存在多种活动任务，如果只有一个调度来执行这些任务，那么当某个任务被阻塞时，其他任务将得不到执行，因此需要有多个独立调度的单元来使这些任务可以并行的执行，这些单元就是线程。</li><li>线程比进程更轻量，它们比进程更快的创建，也更容易撤销。线程间切换的开销也比进程小，由于进程拥有大量的资源，当切换到另一个进程的时候，需要保存当前进程的所有资源，而线程间的切换只需要保存当前堆栈和少了寄存器的内容。</li></ul><p><font color="#F100">当进程只有一个线程时，可以认为进程就等于线程</font></p><p>值得一提的是，在 Linux 中，并不太区分进程和线程，线程只是一种特殊的进程，他们都被叫做任务，用 task_struct 结构体表示。它们的创建方式也大致相同，都是调用 fork() 函数，然后底层执行 clone() 方法创建，只不过，创建线程会在执行 clone() 的时候传递一些参数来指明需要共享的资源。</p><h2 id="2-轻量级进程如何理解？"><a href="#2-轻量级进程如何理解？" class="headerlink" title="2.轻量级进程如何理解？"></a>2.轻量级进程如何理解？</h2><p>轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度。</p><p>在大多数系统中，LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。</p><p>在 LWP 之上也是可以使用用户线程的，那么 LWP 与用户线程的对应关系就有三种：</p><ul><li>1 : 1，即一个 LWP 对应 一个用户线程；</li><li>N : 1，即一个 LWP 对应多个用户线程；</li><li>M : N，即多个 LWP 对应多个用户线程；</li></ul><h2 id="3-并发和并行"><a href="#3-并发和并行" class="headerlink" title="3.并发和并行"></a>3.并发和并行</h2><p>同一个 CPU 在同一时刻只能执行一个任务指令。</p><p><strong>并发</strong>是指一段时间内可以同时运行多道程序，因为时间较短，所以看起来像多个程序在同时执行，实际上是 CPU 在多个程序间进行快速的切换。</p><p><strong>并行</strong>是同一时刻可以运行多个程序，是真正意义上的并发。并行需要多处理器的支持。</p><h2 id="4-线程的实现"><a href="#4-线程的实现" class="headerlink" title="4.线程的实现"></a>4.线程的实现</h2><p>主要有三种线程的实现方式：</p><ol><li>用户线程（User Thread）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；</li><li>内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程；</li><li>轻量级进程（LightWeight Process）：在内核中来支持用户线程；</li></ol><h2 id="5-进程间通信有哪几种方式，都有什么特点？"><a href="#5-进程间通信有哪几种方式，都有什么特点？" class="headerlink" title="5.进程间通信有哪几种方式，都有什么特点？"></a>5.进程间通信有哪几种方式，都有什么特点？</h2><p><font color="#F100">每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。</font></p><ul><li><strong>管道</strong>：通常用在父子进程间通信(管道传输数据是单向的)。管道分为「匿名管道」和「命名管道」;<strong>匿名管道</strong>只能用于存在父子关系的进程间通信；<strong>命名管道</strong>去除了父子进程间通信的机制，通常用来汇聚多个客户端进程与服务端进程的通信，先进先出。</li><li><strong>消息队列</strong>：独立于进程存在，进程间可以通过消息队列来传递数据(消息队列是保存在内核中的消息链表，每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程)，典型的模式是生产者-消费者模型。</li><li><strong>信号</strong>：一个进程可以给另一个进程发送信号来触发某些操作，比如挂起一个进程。Linux 通过 kill 命令来发送信号。(进程间通信机制中唯一的异步通信机制)；进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SIGSTOP；</li><li><strong>信号量</strong>：信号量是一个计数器，用来保护临界资源(实现进程间的互斥与同步)。进程可以读取信号量的值，并对它进行加减操作，多个进程可以通过信号量实现进程同步。</li><li><strong>共享内存</strong>：多个进程上不同的地址空间(虚拟地址)可以映射到同一块物理内存上，实现数据的共享，因为不涉及数据的拷贝，所以这是一种高效的通信方式。需要注意的是，多个进程并行时，需要通过同步机制保护共享内存的访问。</li><li><strong>Socket 通信</strong>：不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。</li></ul><h2 id="6-生产者消费者问题"><a href="#6-生产者消费者问题" class="headerlink" title="6.生产者消费者问题?"></a>6.生产者消费者问题?</h2><p>也叫做有界缓冲区问题，两个进程共享一个公共的固定大小的缓冲区，一个进程产生数据放到缓冲区中，另一个进程从缓冲区中取走信息。这里存在对计数变量的竞争条件，任何时刻，只能有一个生产者或消费者可以访问缓冲区。</p><p>缓冲区空时，消费者必须等待生产者生成数据；缓冲区满时，生产者必须等待消费者取出数据。说明生产者和消费者需要同步。</p><blockquote><p>如何使用信号量解决生产者消费者问题？</p><p>信号量是一个整型变量，用来实现计数器功能，主要提供 down 和 up 操作（即 P 和 V 操作），这两个操作都是原子性的。当执行 down 操作使信号量值变为 0 时，会导致当前进程睡眠，而执行 up 操作 +1 时，会同时唤醒一个进程。</p><p>当信号量取值 0 和 1 时，就是一个互斥信号量，当取值大于 1 时，就是一个计数信号量。</p></blockquote><h2 id="7-哲学家就餐问题？"><a href="#7-哲学家就餐问题？" class="headerlink" title="7.哲学家就餐问题？"></a>7.哲学家就餐问题？</h2><p>五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：进餐以及思考。当一个哲学家进餐时，需要先拿起自己左右两边的叉子，并且一次只能拿起一只叉子。</p><p>五个哲学家最多只能同时两个人进餐，因为只有 5 只叉子。如果五个哲学家同时拿起左边的叉子，那么都在等待邻居放下右边的叉子，导致谁都无法进餐，产生饥饿（也叫死锁）。</p><p>为了避免死锁，需要设置两个条件：</p><ul><li>必须同时拿起左右两边叉子</li><li>只有在两个邻居都没有进餐的情况下才允许进餐</li></ul><h2 id="8-读者-写者问题？"><a href="#8-读者-写者问题？" class="headerlink" title="8.读者-写者问题？"></a>8.读者-写者问题？</h2><p>读者只会读取数据，不会修改数据，而写者即可以读也可以修改数据。</p><p>允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。</p><p>一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。</p><h2 id="9-怎么避免死锁？"><a href="#9-怎么避免死锁？" class="headerlink" title="9.怎么避免死锁？"></a>9.怎么避免死锁？</h2><p>当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成两个线程都在等待对方释放锁，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了<strong>死锁</strong>。</p><p>死锁只有同时满足以下四个条件才会发生：</p><ul><li>互斥条件（多个线程不能同时使用同一个资源）；</li><li>持有并等待条件（线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1）；</li><li>不可剥夺条件（当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取）；</li><li>环路等待条件（两个线程获取资源的顺序构成了环形链）；</li></ul><p><strong>避免死锁问题就只需要破环其中一个条件就可以</strong>，最常见的并且可行的就是使用资源有序分配法，来破环环路等待条件。</p><h2 id="10-锁的种类"><a href="#10-锁的种类" class="headerlink" title="10.锁的种类"></a>10.锁的种类</h2><p>加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。</p><p>当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：</p><ul><li>互斥锁加锁失败后，线程会释放 CPU ，给其他线程（从用户态陷入到内核态）；</li><li>自旋锁加锁失败后，线程会忙等待，直到它拿到锁；</li></ul><p><strong>互斥锁</strong>：是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞。</p><ul><li><strong>对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的</strong>。当加锁失败时，内核会将线程置为「<strong>睡眠</strong>」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。</li></ul><p><strong>自旋锁</strong>：是通过 CPU 提供的 CAS 函数（Compare And Swap），在「<strong>用户态</strong>」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。一直自旋，利用 CPU 周期，直到锁可用。</p><ul><li>需要注意，<strong>在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）</strong>。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。</li></ul><p><strong>读写锁</strong>：由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。适用于能明确区分读操作和写操作的场景。写锁是独占锁，读锁是共享锁。</p><ul><li>当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。</li><li>但是，<strong>一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞</strong>，而且其他写线程的获取写锁的操作也会被阻塞。</li></ul><p><font color = "#F100">互斥锁、自旋锁、读写锁，都是属于悲观锁。</font></p><p><strong>悲观锁</strong>：认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以<strong>访问共享资源前，先要上锁</strong>。</p><p><strong>乐观锁（全程并没有加锁）</strong>：假定冲突的概率很低，它的工作方式是：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。</p><h2 id="11-进程上下文切换和线程上下文切换？"><a href="#11-进程上下文切换和线程上下文切换？" class="headerlink" title="11.进程上下文切换和线程上下文切换？"></a>11.进程上下文切换和线程上下文切换？</h2><p>上下文切换指的是当前任务的资源（寄存器和程序计数器等）、状态等内容保存起来，然后加载新任务的资源和状态，跳转到新的程序计数器指定的指令继续执行。</p><p><strong>进程上下文切换不仅需要保存虚拟内存、全局变量、文件描述符等用户空间资源，还需要保存内核堆栈、寄存器、程序计数器等内核资源。</strong></p><p>线程的上下文切换的是什么？<strong>当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据（线程栈）、寄存器等不共享的数据。</strong>比进程切换开销小很多。</p><h2 id="12-僵尸进程和孤儿进程的区别？"><a href="#12-僵尸进程和孤儿进程的区别？" class="headerlink" title="12.僵尸进程和孤儿进程的区别？"></a>12.僵尸进程和孤儿进程的区别？</h2><p><strong>僵尸进程</strong>：一个子进程退出时会处于 ZOMBIE 状态，此时它占用的进程描述符没有被释放，只有等它的父进程调用 wait() 或 waitpid() 获取到子进程的信息后，最后由父进程决定是否将子进程资源释放。如果子进程的资源由于某种原因一直得不到释放，那么就一直处于僵死状态，变成了僵尸进程。</p><p><strong>孤儿进程</strong>：当父进程退出了，但是它的子进程还没有退出，这些子进程就变成了孤儿进程。孤儿进程只是暂时的，系统会在父进程退出时启动寻父机制，为子进程找到一个新的父亲：首先在当前进程组中寻找，如果找不到就会返回 init (PID&#x3D;1) 进程作为父进程。</p><p>系统中如果驻留大量的僵死进程是危险的，因为会一直占用系统资源，解决的直接办法就是杀死父进程，让他们变成孤儿进程，最后会被新的进程领养，新的父进程会例行调用 wait() 来检查子进程状态，清除相关的僵死进程。</p><h2 id="13-进程有哪几种状态，他们是如何转换的？"><a href="#13-进程有哪几种状态，他们是如何转换的？" class="headerlink" title="13.进程有哪几种状态，他们是如何转换的？"></a>13.进程有哪几种状态，他们是如何转换的？</h2><p>进程主要有三种状态：运行态、就绪态、阻塞态。</p><p>运行态和就绪态可以相互转换，通常由系统的进程调度引起的。当一个处于运行态的进程遇到阻塞的代码，需要等待触发条件，或者没有足够的运行资源时，就会挂起当前进程，进入阻塞状态，而当满足了触发条件，或者系统资源又满足时，就是进入就绪状态，等待再次被调度。</p><h2 id="14-进程和线程的创建方式？"><a href="#14-进程和线程的创建方式？" class="headerlink" title="14.进程和线程的创建方式？"></a>14.进程和线程的创建方式？</h2><p>进程的创建发生在这么几个场景中：</p><ul><li>系统启动时，主要会初始化创建 3 个系统进程，一个 idle 空闲进程(PID&#x3D;0)、一个 init 进程(PID&#x3D;1)、一个页面守护进程(PID&#x3D;2)</li><li>正在运行的进程执行系统调用创建一个子进程(Unix&#x2F;Linux 中使用 fork)</li><li>用户请求创建一个新进程，如在 shell 中输入执行命令。</li><li>提交一个批处理请求，会创建一个新进程来运行</li></ul><p>Linux 中进程的创建主要是通过 fork 系统调用，线程被当做一种特殊的进程，也是用 fork 创建，不过通过传递不同的参数，指明共享父进程的地址空间，打开的文件等资源。</p><p>其他系统如 Windows 创建进程执行的是 CreateProcess，而线程创建实现的 POSIX 标准接口，POSIX 定义的线程包叫 Pthread，其中定义了许多的系统调用，如 Pthread_create、Pthread_join、Pthread_exit 等</p><h2 id="15-子进程创建时会拷贝父进程哪些资源？"><a href="#15-子进程创建时会拷贝父进程哪些资源？" class="headerlink" title="15.子进程创建时会拷贝父进程哪些资源？"></a>15.子进程创建时会拷贝父进程哪些资源？</h2><p>Linux系统中，子进程的创建不会马上拷贝父进程的所有资源，而是以只读的方式共享大部分父进程的资源，当需要修改地址空间资源时，触发只读保护，这时才会拷贝一份地址空间。这种机制叫做 **写时拷贝(copy-on-write)**。这种优化可以避免拷贝大量根本不会使用到的数据。</p><p>fork 系统调用实际上只是为子进程创建一个唯一的进程描述符，分配了一个有效的 PID，有的 Linux 系统 fork 调用也会复制一份父进程的页面。</p><h2 id="16-什么是系统调用？为什么要有系统调用？"><a href="#16-什么是系统调用？为什么要有系统调用？" class="headerlink" title="16.什么是系统调用？为什么要有系统调用？"></a>16.什么是系统调用？为什么要有系统调用？</h2><p>系统调用是在一个进程中，由用户态切换到内核态，在内核中执行任务，或者申请操作系统的资源。系统调用是一种<strong>保护操作系统的机制</strong>，它提供一系列定义良好的 API 接口来和操作系统交互，避免用户程序直接对内核进行操作，保证了系统的稳定、安全、可靠。</p><h2 id="17-内核态和用户态是什么？"><a href="#17-内核态和用户态是什么？" class="headerlink" title="17.内核态和用户态是什么？"></a>17.内核态和用户态是什么？</h2><p>多数 CPU 都有两种模式，即用户态和内核态，通常由<strong>程序状态字(PSW) 寄存器</strong>中的一个位来控制这两种模式的切换（通过 TRAP 指令实现切换）。这两种状态其实对应着应用程序访问资源的权限：在用户态只能访问受限的资源，如虚拟内存，全局变量等，而要访问内核等资源需要通过系统调用等方式陷入到内核中；内核态可以访问操作系统的所有资源，包括内存、I&#x2F;O 等资源。</p><h2 id="18-如何实现进程同步？"><a href="#18-如何实现进程同步？" class="headerlink" title="18.如何实现进程同步？"></a>18.如何实现进程同步？</h2><p>进程同步是指控制进程按照一定顺序执行。只有处于临界区（指访问共享内存的代码片段）的进程才需要同步。</p><p>进程同步通常有两种方式：</p><ul><li>忙等待互斥：当某个变量不满足条件时，会一直轮询直到变量值发送改变。用于忙等待的锁称为自旋锁。自旋锁一般用于中断处理程序中（需要禁止本地中断），因为中断程序需要安全、快速的执行，不能被打断、也不能被睡眠。</li><li>信号量：是一个整型变量，用来实现计数器功能，主要提供 down 和 up 操作（即 P 和 V 操作），这两个操作都是原子性的。当执行 down 操作使信号量值变为 0 时，会导致当前进程睡眠，而执行 up 操作 +1 时，会同时唤醒一个进程。</li><li><strong>管程</strong>：管程是由一个过程、变量和数据结构组成的一个集合，把需要控制的那部分代码独立出来执行，它有一个重要的特性，同一时刻在管程中只能有一个活跃的进程。为了避免一个进程一直占用管程，引入了条件变量和 wait 和 signal 操作。当发生当前进程无法运行时，执行 wait 操作，将当前进程阻塞，同时调入在管程外等待的另一进程执行，而另一个进程满足条件变量时，会执行 signal 操作将正在睡眠的进程唤醒，然后马上退出管程。</li></ul><p><a href="https://www.cnblogs.com/turbobin/p/14287553.html">面试-操作系统篇：进程与线程</a></p><h2 id="19-一个进程最多可以创建多少个线程？"><a href="#19-一个进程最多可以创建多少个线程？" class="headerlink" title="19.一个进程最多可以创建多少个线程？"></a>19.一个进程最多可以创建多少个线程？</h2><p>进程最多可以创建多少个线程有关的因素：</p><ul><li><strong>进程的虚拟内存空间上限</strong>，因为创建一个线程，操作系统需要为其分配一个栈空间，如果线程数量越多，所需的栈空间就要越大，那么虚拟内存就会占用的越多。</li><li><strong>系统参数限制</strong>（系统支持的最大线程数、 PID 号数值的限制），虽然 Linux 并没有内核参数来控制单个进程创建的最大线程个数，但是有系统级别的参数来控制整个系统的最大线程个数。</li></ul><p> 32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 10M，那么一个进程最多只能创建 300 个左右的线程。</p><p>64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制，而会受系统的参数或性能限制。</p><h2 id="20-线程奔溃了，进程也会奔溃吗？"><a href="#20-线程奔溃了，进程也会奔溃吗？" class="headerlink" title="20.线程奔溃了，进程也会奔溃吗？"></a>20.线程奔溃了，进程也会奔溃吗？</h2><p>正常情况下，操作系统为了保证系统安全，所以针对非法内存访问会发送一个 SIGSEGV 信号，而操作系统一般会调用默认的信号处理函数（一般会让相关的进程崩溃）。</p><p>1、如果线程是非法访问内存引起的崩溃，其<strong>对应进程一定会崩溃</strong>。</p><p>2、进程崩溃的本质是：操作系统对进程发出了信号，例如非法访问内存的信号是 SIGSEGV（序号 11）</p><p>3、想要防止进程奔溃，需要<strong>自定义信号处理函数去拦截 SIGSEGV 信号</strong>。参考 JVM 中线程崩溃但 JVM 进程不会崩溃</p><hr><h1 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h1><p>进程调度算法也称 CPU 调度算法，毕竟进程是由 CPU 调度的。<br>当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。</p><h2 id="1-什么时候会发生-CPU-调度？"><a href="#1-什么时候会发生-CPU-调度？" class="headerlink" title="1.什么时候会发生 CPU 调度？"></a>1.什么时候会发生 CPU 调度？</h2><ol><li>当进程从运行状态转到等待状态；</li><li>当进程从运行状态转到就绪状态；</li><li>当进程从等待状态转到就绪状态；</li><li>当进程从运行状态转到终止状态；</li></ol><p>其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。</p><p><strong>非抢占式</strong>的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。</p><p><strong>抢占式调度</strong>，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。</p><p><font color = "#F100">调度算法影响的是等待时间（进程在就绪队列中等待调度的时间总和），而不能影响进程真在使用 CPU 的时间和 I&#x2F;O 时间。</font></p><h2 id="2-进程间常见的调度算法"><a href="#2-进程间常见的调度算法" class="headerlink" title="2.进程间常见的调度算法"></a>2.进程间常见的调度算法</h2><ul><li><p><strong>先来先服务调度算法</strong>：每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行；</p></li><li><p><strong>最短作业优先调度算法</strong>：优先选择运行时间最短的进程来运行；</p></li><li><p><strong>高响应比优先调度算法</strong>：权衡了短作业和长作业。每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：[（等待时间 + 要求服务时间）&#x2F; 要求服务时间 ]；</p></li><li><p><strong>时间片轮转调度算法</strong>：让所有的进程同等重要，每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行，通常时间片设为 20ms~50ms折中值；</p></li><li><p><strong>最高优先级调度算法</strong>：从就绪队列中选择最高优先级的进程进行运行；</p><ul><li><strong>静态优先级</strong>：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；</li><li><strong>动态优先级</strong>：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。</li></ul></li><li><p><strong>多级反馈队列调度算法</strong>：「时间片轮转算法」和「最高优先级算法」的综合和发展；</p><ul><li>「多级」表示有多个队列，每个队列优先级从高到低，同时<em>优先级越高时间片越短</em>。</li><li>「反馈」表示如果有<em>新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列</em>； </li><li>新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；</li><li>当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；</li></ul></li></ul><h2 id="3-内存页面置换算法"><a href="#3-内存页面置换算法" class="headerlink" title="3.内存页面置换算法"></a>3.内存页面置换算法</h2><p>功能：当出现缺页异常，需调入新页面而内存已满时，置换算法选择被置换的物理页面；</p><p><strong>设计目标：</strong></p><ol><li>尽可能减少页面的调入调出次数；</li><li>把未来不再访问或短期内不访问的页面调出。</li></ol><p><strong>页表项通常有如下字段：</strong><br>【页号】【物理页号】【状态位】【访问字段】【修改位】【硬盘地址】</p><ul><li>状态位：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。</li><li>访问字段：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。</li><li>修改位：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。</li><li>硬盘地址：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。</li></ul><p>常见的页面置换算法有如下几种：</p><ul><li><strong>最佳页面置换算法（OPT）</strong>：置换在「未来」最长时间不访问的页面；</li><li><strong>先进先出置换算法（FIFO）</strong>：选择在内存驻留时间很长的页面进行中置换；</li><li><strong>最近最久未使用的置换算法（LRU）</strong>：选择最长时间没有被访问的页面进行置换；</li><li><strong>时钟页面置换算法（Lock）</strong>：把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面；当发生缺页中断时，算法首先检查表针指向的页面：<ul><li>如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；</li><li>如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；</li></ul></li><li><strong>最不常用置换算法（LFU）</strong>：当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。</li></ul><h2 id="4-磁盘调度算法"><a href="#4-磁盘调度算法" class="headerlink" title="4.磁盘调度算法"></a>4.磁盘调度算法</h2><p><strong>目的</strong>：为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。<strong>寻道</strong>的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间，从而提高磁盘的访问性能。</p><ul><li>先来先服务算法：先来的请求先被服务，即按照序列顺序移动；</li><li>最短寻道时间算法：优先选择从当前磁头位置所需寻道时间最短的请求；</li><li>扫描算法（电梯算法）：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向重复上面过程；</li><li>循环扫描算法：在扫描算法的基础上，磁头只响应一个方向的请求，返回时直接快速复位磁头（这个过程不处理任何请求），再重新往那个方向移动；</li><li>LOOK：对扫描算法的优化，磁头移动到最远的请求位置就开始反向移动（原本是到达最后的磁道位置）；</li><li>C-LOOK：对循环扫描算法的优化，磁头移动到最远的请求位置就开始反向移动（原本是到达最后的磁道位置）；</li></ul><hr><h1 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h1><h2 id="1-文件系统和磁盘有什么关系？"><a href="#1-文件系统和磁盘有什么关系？" class="headerlink" title="1. 文件系统和磁盘有什么关系？"></a>1. 文件系统和磁盘有什么关系？</h2><p>磁盘属于硬件，是一种为系统提供了基本的持久化存储的设备。</p><p>文件系统属于操作系统的功能，以磁盘为载体，提供了一个用来管理文件的树状结构。<br>##2. 文件系统有哪些结构？<br>文件系统主要由索引节点、目录项、超级块、逻辑块组成。</p><ul><li><strong>索引节点</strong>：记录了文件的元信息，包括文件权限、文件大小、创建时间、数据的索引位置等等。索引节点是文件的唯一标识，和文件一一对应，它和文件内容一样会持久化到磁盘中保存。</li><li><strong>目录项</strong>：用来记录文件的名字、索引节点的指针以及与其他目录项的关联关系。多个关联的目录项组成了文件系统的目录结构。目录项对象不会存储到磁盘中，而是被缓存起来，便于快速的解析目录。</li><li><strong>超级块</strong>：存储了整个文件系统的状态，如索引节点、逻辑块的使用情况。</li><li><strong>逻辑块</strong>：文件系统用来存储数据的最小单位，大小为 4 KB，一般由 8 个连续的扇区组成（磁盘读写的最小单位是扇区，大小为 512B），多个逻辑块组成了文件系统的数据块区。</li></ul><p>##3. 什么是虚拟文件系统，有什么作用？<br>虚拟文件系统（VFS）是操作系统在用户层与文件系统之间引入的一个抽象层，屏蔽了不同文件系统之间的差异，定义了一组标准的系统调用接口，为用户提供了统一访问文件的方式。</p><p><strong>VFS 定义了一组所有文件都支持的数据结构和标准接口</strong>，这样，用户和其他内核子系统只需要跟 VFS 提供的统一接口交互就可以了，而不需要关心底层各种文件系统的实现细节。</p><p>##4. 同步IO和异步IO，阻塞和非阻塞IO有什么区别？<br>两种是不同角度的 I&#x2F;O 划分方式。</p><p>根据是否等待系统的 I&#x2F;O 请求响应，可以分为<strong>同步 I&#x2F;O</strong> 和<strong>异步 I&#x2F;O</strong>，关注对象是I&#x2F;O 的执行者(系统)，比如系统调用 read 是同步读，在没有得到磁盘数据前不会响应应用程序，而 aio_read 是异步读，系统收到 I&#x2F;O 请求后不等待处理就立即返回了，而读取的结果通过回调的方式异步通知给应用程序。</p><p>根据应用程序是否阻塞自身运行，可以分为<strong>阻塞 I&#x2F;O</strong> 和 <strong>非阻塞 I&#x2F;O</strong>，针对的 I&#x2F;O 的调用者(应用程序)。比如在套接字接口中，使用 send 向套接字接口发送数据时，如果套接字没有设置 O_NOBLOCK 标识，那么 send 操作会一直阻塞，而如果使用了 epoll，系统会告诉套接字的状态，就可以使用非阻塞的方式读写套接字。</p><p>##5. 什么是DMA技术？<br>一种内存访问技术。DMA（Direct Memory Access，直接存储器访问）<strong>可以在不需要 CPU 参与的情况下实现内存的读取或写入</strong>，因为不依赖 CPU 的大量中断负载，因而可以实现数据的快速传送，提高系统的并发性能。</p><p>DMA 的传输过程必须经过 DMA 请求，DMA 响应，DMA 传输，DMA 结束 4 个步骤：</p><ol><li><strong>DMA 请求</strong>：CPU 对 DMA 芯片进行设置，说明需要传送的字节数，有关的设备和内存地址，然后启动 DMA；</li><li><strong>DMA 响应</strong>：DMA 向 CPU 请求总线控制权，CPU 处理完当前总线数据后就让出总线；</li><li><strong>DMA 传输</strong>：DMA 控制器直接控制内存与 I&#x2F;O 接口进行数据传输；</li><li><strong>DMA 结束</strong>：DMA 传输结束后，把总线控制权交还给 CPU，并向 I&#x2F;O 接口发送结束信号。</li></ol><p>##6. 什么是零拷贝技术？<br>零拷贝指计算机不需要先将数据从一个内存区域复制到另外一个内存区域，从而减少系统调用切换、减少拷贝次数，从而减少 CPU 的执行时间和负载。</p><p>实现零拷贝主要用到的是 DMA 数据传输技术和内存映射技术。</p><p> 传统的 I&#x2F;O 方式需要经过四次拷贝才能把磁盘上的数据输出到网络端口：</p><ol><li>执行 read 系统调用，从用户态切换到内核态，CPU 向 DMA 控制器芯片下发指令，将磁盘数据通过直接内存访问的方式拷贝到内核缓冲区中；</li><li>CPU 接收到 DMA 结束拷贝的信号，将内核缓冲区的数据拷贝到用户缓冲区中，read 调用结束，返回到用户态；</li><li>用户程序执行 write 系统调用，从用户态切换到内核态，CPU 将数据从用户缓冲区中拷贝到Socket 发送缓冲区中；</li><li>CPU 下发指令，让 DMA 控制器来处理数据，将 Socket 发送缓冲区的数据拷贝到网卡进行网络传输，write 调用结束。</li></ol><p><strong>零拷贝有几种实现方式</strong>，如下：</p><ol><li><p><code>mmap + write</code>：mmap 是一个系统调用，主要作用就是将用户缓冲区与内核中的读缓冲区进行映射，映射后这一步就不需要进行数据拷贝了，而 write 操作实际上是从内核读缓冲区中把数据拷贝到 Socket 发送缓冲区，整个过程减少了一次拷贝操作，但是系统调用切换没有减少(4 次)。</p><blockquote><ul><li>应用进程调用了 mmap() 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；</li><li>应用进程再调用 write()，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；</li><li>最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。</li></ul></blockquote></li><li><p><code>sendfile</code>：sendfile 同样省去了将数据在内核和用户空间中拷贝，与 mmap 不同的是，sendfile 不需要借助 write 调用，而是一次完整的内核拷贝过程，减少了两次 CPU 上下文切换(2 次上下文切换，和 3 次数据拷贝)。</p><blockquote><ul><li>可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销</li></ul></blockquote></li><li><p><code>sendfile + DMA gather copy</code>：对 sendfile 系统调用做了修改，引入了 gather 操作，不需要将内核缓冲区的数据拷贝到 Socket 中，而是将它对于的数据描述信息（内存地址、文件描述符，文件长度等）记录到 Socket 缓冲区中，最后由 DMA 根据这些文件描述信息从内核读缓冲区中找到数据，直接拷贝到网卡设备中。</p></li><li><p><code>splice</code>：splice 系统调用可以在内核空间的读缓冲区和网络缓冲区之间建立管道（pipeline），从而避免了两者之间的 CPU 拷贝操作。</p></li></ol><blockquote><ul><li>mmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间;</li><li>read() 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里</li></ul></blockquote><p>##7. 磁盘的分类，都有什么特点？</p><ul><li><strong>机械磁盘</strong>：也叫磁盘驱动器（HDD），带有旋转臂和磁头，由电机驱动带动盘片旋转，顺序读取的速度较快，随机读取较慢，因为要经常旋转磁头进行磁道寻址。最小读写单位是扇区，一般是 512 字节大小</li><li><strong>固态硬盘</strong>：SSD，控制闪存颗粒进行数据的读写，属于完全的电子操作。最小操作单位是页，通常是 4KB。</li></ul><p>##8. IO调度算法有哪几种？</p><ul><li>NOOP：电梯调度，最简单一种调度算法，维护一个先进先出的队列，只做一些基本的请求合并，常用于 SSD。</li><li>CFS：完全公平的调度器，一般是默认的调度算法，类似于进程调度，为每个 I&#x2F;O 进程维护一个队列，并按照时间片均匀分布每个进程的 I&#x2F;O 请求。适合运行大量进程的场景。</li><li>DeadLine：截止时间请求调度，分别为每个读写请求都维护一个调度队列，以提高磁盘的吞吐量，并确保达到最终极限的请求得到优先处理。适用于 I&#x2F;O 比较重的场景，如数据库。</li></ul><h2 id="9-在文件系统中，什么是硬链接和软链接？它们之间有什么区别？"><a href="#9-在文件系统中，什么是硬链接和软链接？它们之间有什么区别？" class="headerlink" title="9.在文件系统中，什么是硬链接和软链接？它们之间有什么区别？"></a>9.在文件系统中，什么是硬链接和软链接？它们之间有什么区别？</h2><p>在文件系统中，硬链接（Hard Link）和软链接（Symbolic Link，也称为符号链接或软连接）是两种链接文件的方式。</p><p><strong>硬链接</strong> 是文件系统中一个文件对应多个目录项的链接关系。它们具有相同的 inode（索引节点）和数据块，它们在文件系统中的位置是完全相同的。因此，对于系统来说，硬链接文件与原始文件没有区别，可以独立地访问和操作。</p><p> <strong>软链接</strong>是一个特殊的文件，它包含了指向目标文件的路径。软链接文件与原始文件有不同的 inode 和数据块，它只是一个指向目标文件的快捷方式。当访问软链接时，操作系统会根据软链接中的路径找到目标文件。</p><p>主要区别如下：</p><ol><li>硬链接不可跨越文件系统，而软链接可以跨越文件系统。</li><li>硬链接不能链接目录，而软链接可以链接目录。</li><li>硬链接不受目标文件删除的影响，只有所有的硬链接都被删除后，文件的空间才会被释放。软链接则只是指向目标文件的路径，如果目标文件被删除，软链接将成为一个无效的链接。</li><li>修改硬链接文件会影响所有链接到该文件的硬链接，而修改软链接文件不会影响目标文件或其他软链接文件。</li></ol><p><font color="#F100">硬链接是多个文件共享相同的数据和 inode，而软链接是指向目标文件的路径。硬链接是一个文件的多个入口，而软链接是一个文件的快捷方式。</font></p><h2 id="10-请解释文件系统的目录结构和文件控制块"><a href="#10-请解释文件系统的目录结构和文件控制块" class="headerlink" title="10.请解释文件系统的目录结构和文件控制块?"></a>10.请解释文件系统的目录结构和文件控制块?</h2><p><strong>目录结构</strong>是文件系统中用于组织和管理文件和目录的一种层次化结构。它提供了一种逻辑视图，使用户可以方便地查找、访问和管理文件。</p><ul><li>目录结构通常采用树形结构，其中包含了文件和子目录。常见的目录结构类型有单级目录、层次目录、索引节点和哈希表等。</li></ul><p> <strong>文件控制块（File Control Block，FCB）</strong>是文件系统中用于存储文件相关信息的数据结构。每个文件都对应一个文件控制块，它存储了文件的元数据，包括文件名、大小、创建时间、修改时间、访问权限等。</p><p>通过目录结构和文件控制块，文件系统可以组织和管理大量的文件和目录，提供了用户友好的文件访问和管理接口，方便用户进行文件的读取、写入、删除和查找等操作。同时，文件控制块中的元数据信息也能够提供文件的属性和状态，以便进行权限控制、时间管理和数据完整性保护等功能。</p><h2 id="11-请解释文件系统的索引结构和如何实现文件块分配？"><a href="#11-请解释文件系统的索引结构和如何实现文件块分配？" class="headerlink" title="11.请解释文件系统的索引结构和如何实现文件块分配？"></a>11.请解释文件系统的索引结构和如何实现文件块分配？</h2><p><strong>文件系统的索引结构</strong>是一种用于快速定位和访问文件数据的数据结构。它通过维护一个索引表或索引节点（inode）来映射文件名与文件数据的关系。索引结构的设计旨在提高文件系统的性能和效率。</p><p> 常见的索引结构有以下几种：</p><ul><li><strong>单级目录结构</strong>：文件系统维护一个全局的目录表，其中每个条目包含文件名和对应的数据块号。这种结构简单，但对于文件数量较大的情况效率较低。</li><li><strong>多级目录结构</strong>：文件系统将目录分为多级，通过嵌套的目录层次结构来组织文件。这样可以提高查找效率，但也增加了目录的管理复杂性。</li><li><strong>哈希表结构</strong>：使用哈希函数将文件名映射为数据块号，以快速查找文件数据。哈希表结构适用于大规模文件系统，可以在O(1)时间内找到文件数据。</li><li><strong>B树和B+树结构</strong>：这些树状结构适用于大型文件系统，能够高效地管理大量的文件和目录。B树和B+树结构具有平衡性和高度优化的查找性能。</li></ul><p><strong>文件块分配是指在文件系统中为文件分配存储空间的过程</strong>。常见的文件块分配方式有以下几种：</p><ol><li><strong>连续分配</strong>：将文件存储空间作为一块连续的物理空间分配给文件。这种方式简单高效，但容易产生外部碎片。</li><li><strong>链接分配</strong>：使用链表将文件的数据块链接起来。每个数据块包含指向下一个数据块的指针。这种方式灵活，但需要额外的指针开销。</li><li><strong>索引分配</strong>：为每个文件维护一个索引表，索引表中的条目指向实际存储数据的块。这种方式适用于大文件和随机访问，但需要更多的空间来存储索引表。</li><li><strong>混合分配</strong>：将连续分配和链接分配结合使用，根据文件大小和访问模式选择合适的分配方式。例如，对于小文件使用链接分配，对于大文件使用索引分配。</li></ol><p>实现文件块分配需要考虑空闲空间的管理、分配策略、碎片整理等因素。文件系统会维护一个空闲块列表或位图来跟踪可用的存储空间，并根据不同的分配策略选择合适的块进行分配。为了避免碎片问题，文件系统可能会进行碎片整理操作，将零散的空闲块整理成连续的空间，以提高存储利用率和访问效率。</p><h2 id="12-如何保护文件系统的安全性和防止文件丢失？"><a href="#12-如何保护文件系统的安全性和防止文件丢失？" class="headerlink" title="12.如何保护文件系统的安全性和防止文件丢失？"></a>12.如何保护文件系统的安全性和防止文件丢失？</h2><p>保护文件系统的安全性和防止文件丢失是文件系统设计中非常重要的考虑因素。以下是几个关键的方面：</p><ol><li><strong>访问控制和权限管理</strong>：文件系统应提供访问控制机制，确保只有经过授权的用户能够访问文件和目录。这包括使用权限位（如读、写、执行权限）、用户身份验证和访问控制列表（ACL）等方式来管理和限制对文件的访问。</li><li><strong>加密和身份验证</strong>：对于敏感数据和文件，可以使用加密算法来保护数据的机密性。此外，身份验证机制如用户名和密码、公钥加密等可以防止未经授权的用户访问文件系统。</li><li><strong>备份和恢复策略</strong>：定期备份文件系统中的重要数据是防止文件丢失的关键措施。备份可以包括完整备份和增量备份，以确保文件系统的数据可以在故障或灾难发生时恢复。</li><li><strong>冗余和容错机制</strong>：通过实现冗余存储和容错机制，如RAID（磁盘冗余阵列）等技术，可以增加文件系统的可靠性和容错能力。这样可以防止由于硬件故障而导致的数据丢失。</li><li><strong>定期维护和监控</strong>：定期进行文件系统的维护工作，包括磁盘清理、碎片整理、错误修复等，以保持文件系统的健康状态。同时，监控文件系统的运行状态，及时发现和处理异常情况，可以防止进一步的数据损失。</li></ol><h1 id="设备管理"><a href="#设备管理" class="headerlink" title="设备管理"></a>设备管理</h1><h2 id="1-键盘敲入字母时，期间发生了什么？"><a href="#1-键盘敲入字母时，期间发生了什么？" class="headerlink" title="1.键盘敲入字母时，期间发生了什么？"></a>1.键盘敲入字母时，期间发生了什么？</h2><p>CPU 里面的<strong>内存接口，直接和系统总线通信</strong>，然后系统总线再接入一个 I&#x2F;O 桥接器，这个 I&#x2F;O 桥接器，另一边接入了内存总线，使得 CPU 和内存通信。再另一边，又接入了一个 I&#x2F;O 总线，用来连接 I&#x2F;O 设备，比如键盘、显示器等。</p><ol><li>当用户输入了键盘字符，键盘控制器就会产生扫描码数据，并<strong>将其缓冲在键盘控制器的寄存器</strong>中，紧接着键盘控制器<strong>通过总线给 CPU 发送中断请求</strong>。</li><li>CPU 收到中断请求后，操作系统会<strong>保存被中断进程的 CPU 上下文，然后调用键盘的中断处理程序</strong>。</li><li>键盘的中断处理程序是在键盘驱动程序<strong>初始化时注册的</strong>，那键盘中断处理函数的功能就是从键盘控制器的寄存器的缓冲区读取扫描码，再根据扫描码找到用户在键盘输入的字符，如果输入的字符是显示字符，那就会把扫描码翻译成对应显示字符的 ASCII 码，比如用户在键盘输入的是字母 A，是显示字符，于是就会把扫描码翻译成 A 字符的 ASCII 码。</li><li>得到了显示字符的 ASCII 码后，就会<strong>把 ASCII 码放到「读缓冲区队列」</strong>，接下来就是要把显示字符显示屏幕了，显示设备的驱动程序会<strong>定时从「读缓冲区队列」读取数据放到「写缓冲区队列」，最后把「写缓冲区队列」的数据一个一个写入到显示设备的控制器的寄存器中的数据缓冲区</strong>，最后将这些数据显示在屏幕里。</li></ol><h2 id="2-设备控制器（Device-Control）"><a href="#2-设备控制器（Device-Control）" class="headerlink" title="2.设备控制器（Device Control）"></a>2.设备控制器（Device Control）</h2><p>为了屏蔽设备之间的差异</p><p>设备控制器里有芯片，它可执行自己的逻辑，也有自己的寄存器，用来与 CPU 进行通信。</p><p>控制器是有三类寄存器，它们分别是状态寄存器（Status Register）、 命令寄存器（Command Register）以及数据寄存器（Data Register）：</p><ol><li><strong>数据寄存器</strong>，CPU 向 I&#x2F;O 设备写入需要传输的数据，比如要打印的内容是「Hello」，CPU 就要先发送一个 H 字符给到对应的 I&#x2F;O 设备。</li><li><strong>命令寄存器</strong>，CPU 发送一个命令，告诉 I&#x2F;O 设备，要进行输入&#x2F;输出操作，于是就会交给 I&#x2F;O 设备去工作，任务完成后，会把状态寄存器里面的状态标记为完成。</li><li><strong>状态寄存器</strong>，目的是告诉 CPU ，现在已经在工作或工作已经完成，如果已经在工作状态，CPU 再发送数据或者命令过来，都是没有用的，直到前面的工作已经完成，状态寄存标记成已完成，CPU 才能发送下一个字符和命令。</li></ol><h2 id="3-通用块层"><a href="#3-通用块层" class="headerlink" title="3.通用块层"></a>3.通用块层</h2><p>通用块层是处于文件系统和磁盘驱动中间的一个块设备抽象层，它主要有两个功能：</p><ul><li>第一个功能，向上为文件系统和应用程序，提供访问块设备的标准接口，向下把各种不同的磁盘设备抽象为统一的块设备，并在内核层面，提供一个框架来管理这些设备的驱动程序；</li><li>第二功能，通用层还会给文件系统和应用程序发来的 I&#x2F;O 请求排队，接着会对队列重新排序、请求合并等方式，也就是 I&#x2F;O 调度，主要目的是为了提高磁盘读写的效率。</li></ul><h2 id="4-存储系统-I-O-软件分层"><a href="#4-存储系统-I-O-软件分层" class="headerlink" title="4.存储系统 I&#x2F;O 软件分层"></a>4.存储系统 I&#x2F;O 软件分层</h2><p>可以把 Linux 存储系统的 I&#x2F;O 由上到下可以分为三个层次，分别是文件系统层、通用块层、设备层。</p><ul><li><strong>文件系统层</strong>，包括虚拟文件系统和其他文件系统的具体实现，它向上为应用程序统一提供了标准的文件访问接口，向下会通过通用块层来存储和管理磁盘数据。</li><li><strong>通用块层</strong>，包括块设备的 I&#x2F;O 队列和 I&#x2F;O 调度器，它会对文件系统的 I&#x2F;O 请求进行排队，再通过 I&#x2F;O 调度器，选择一个 I&#x2F;O 发给下一层的设备层。</li><li><strong>设备层</strong>，包括硬件设备、设备控制器和驱动程序，负责最终物理设备的 I&#x2F;O 操作。</li></ul><h1 id="网络系统"><a href="#网络系统" class="headerlink" title="网络系统"></a>网络系统</h1><h2 id="1-PageCache-有什么作用？"><a href="#1-PageCache-有什么作用？" class="headerlink" title="1.PageCache 有什么作用？"></a>1.PageCache 有什么作用？</h2><p>文件传输过程，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是<strong>磁盘高速缓存（PageCache）</strong>。</p><p>PageCache 的优点主要是两个：</p><ol><li>缓存最近被访问的数据；</li><li>预读功能；</li></ol><p><font color="#F100">但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能。</font></p><ol><li>PageCache 由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 PageCache，于是这样磁盘读写的性能就会下降了；</li><li>PageCache 中的大文件数据，由于没有享受到缓存带来的好处，但却耗费 DMA 多拷贝到 PageCache 一次；</li></ol><h2 id="2-大文件传输用什么方式实现？"><a href="#2-大文件传输用什么方式实现？" class="headerlink" title="2.大文件传输用什么方式实现？"></a>2.大文件传输用什么方式实现？</h2><p>绕开 PageCache 的 I&#x2F;O 叫直接 I&#x2F;O，使用 PageCache 的 I&#x2F;O 则叫缓存 I&#x2F;O。通常，对于磁盘，异步 I&#x2F;O 只支持直接 I&#x2F;O。</p><p>在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I&#x2F;O + 直接 I&#x2F;O」来替代零拷贝技术。</p><blockquote><ul><li>传输大文件的时候，使用「异步 I&#x2F;O + 直接 I&#x2F;O」；</li><li>传输小文件的时候，则使用「零拷贝技术」；</li><li>Kafka 和 Nginx 都有实现零拷贝技术，这将大大提高文件传输的性能</li></ul></blockquote><h2 id="3-服务端给-Socket-绑定一个-IP-地址和端口，绑定这两个的目的是什么？"><a href="#3-服务端给-Socket-绑定一个-IP-地址和端口，绑定这两个的目的是什么？" class="headerlink" title="3.服务端给 Socket 绑定一个 IP 地址和端口，绑定这两个的目的是什么？"></a>3.服务端给 Socket 绑定一个 IP 地址和端口，绑定这两个的目的是什么？</h2><ul><li><strong>绑定端口的目的</strong>：当内核收到 TCP 报文，通过 TCP 头里面的端口号，来找到我们的应用程序，然后把数据传递给我们。</li><li>绑定 <strong>IP</strong> 地址的目的：一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址，当绑定一个网卡时，内核在收到该网卡上的包，才会发给我们；</li></ul><h2 id="4-文件描述符的作用是什么？"><a href="#4-文件描述符的作用是什么？" class="headerlink" title="4.文件描述符的作用是什么？"></a>4.文件描述符的作用是什么？</h2><p>每一个进程都有一个数据结构 task_struct，该结构体里有一个指向「文件描述符数组」的成员指针。该数组里列出这个进程打开的所有文件的文件描述符。</p><p>数组的下标是文件描述符，是一个整数，而数组的内容是一个指针，指向内核中所有打开的文件的列表，也就是说<strong>内核可以通过文件描述符找到对应打开的文件</strong>。</p><h2 id="5-服务器接数，主要会受两个方面的限制"><a href="#5-服务器接数，主要会受两个方面的限制" class="headerlink" title="5.服务器接数，主要会受两个方面的限制"></a>5.服务器接数，主要会受两个方面的限制</h2><ol><li><strong>文件描述符</strong>，Socket 实际上是一个文件，也就会对应一个文件描述符。在 Linux 下，单个进程打开的文件描述符数是有限制的，没有经过修改的值一般都是 1024，不过我们可以通过 ulimit 增大文件描述符的数目；</li><li><strong>系统内存</strong>，每个 TCP 连接在内核中都有对应的数据结构，意味着每个连接都是会占用一定内存的；</li></ol><h2 id="6-多进程模型与多线程模型"><a href="#6-多进程模型与多线程模型" class="headerlink" title="6.多进程模型与多线程模型"></a>6.多进程模型与多线程模型</h2><p>多进程模型：</p><ul><li>服务器的主进程负责监听客户的连接，一旦与客户端连接完成，accept() 函数就会返回一个「已连接 Socket」，这时就通过 fork() 函数创建一个子进程，实际上就把父进程所有相关的东西都复制一份，包括文件描述符、内存地址空间、程序计数器、执行的代码等。</li><li>这两个进程刚复制完的时候，几乎一模一样。不过，会根据返回值来区分是父进程还是子进程，如果返回值是 0，则是子进程；如果返回值是其他的整数，就是父进程。</li><li>子进程会复制父进程的文件描述符，于是就可以直接使用「已连接 Socket 」和客户端通信了，</li></ul><p><font color = "#F100">子进程不需要关心「监听 Socket」，只需要关心「已连接 Socket」；父进程则相反，将客户服务交给子进程来处理，因此父进程不需要关心「已连接 Socket」，只需要关心「监听 Socket」。</font></p><p>多线程模型：</p><p>当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的。</p><h2 id="7-I-O-复用"><a href="#7-I-O-复用" class="headerlink" title="7.I&#x2F;O 复用"></a>7.I&#x2F;O 复用</h2><p><strong>Select</strong></p><p>select 实现多路复用的方式是，<strong>将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生</strong>，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket <strong>标记为可读或可写</strong>， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。</p><blockquote><p> 对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。</p></blockquote><p><strong>poll</strong></p><p>select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。</p><p>poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用<strong>动态数组</strong>，以链表形式来组织，突破了 select 的文件描述符个数限制，当然<strong>还会受到系统文件描述符限制</strong>。</p><p><font color="#F100">都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合</font></p><p><strong>Epoll</strong></p><p> epoll 在内核里使用<strong>红黑树</strong>来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)</p><p> epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数。</p><p>epoll 支持两种事件触发模式，分别是<strong>边缘触发（edge-triggered，ET）</strong>和<strong>水平触发（level-triggered，LT）</strong>。</p><ol><li>用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，<strong>服务器端只会从 epoll_wait 中苏醒一次</strong>，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；</li><li>使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，<strong>服务器端不断地从 epoll_wait 中苏醒</strong>，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；</li></ol><h2 id="8-高性能网络模式：Reactor-和-Proactor"><a href="#8-高性能网络模式：Reactor-和-Proactor" class="headerlink" title="8.高性能网络模式：Reactor 和 Proactor"></a>8.高性能网络模式：Reactor 和 Proactor</h2><p>第一种方案<strong>单 Reactor 单进程 &#x2F; 线程</strong>，不用考虑进程间通信以及数据同步的问题，因此实现起来比较简单，这种方案的缺陷在于无<em>法充分利用多核 CPU，而且处理业务逻辑的时间不能太长，否则会延迟响应，所以不适用于计算机密集型的场景</em>，适用于业务处理快速的场景，比如 Redis（6.0之前 ） 采用的是单 Reactor 单进程的方案。</p><p>第二种方案<strong>单 Reactor 多线程</strong>，通过多线程的方式解决了方案一的缺陷，但它离高并发还差一点距离，差在<em>只有一个 Reactor 对象来承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方</em>。</p><p>第三种方案<strong>多 Reactor 多进程 &#x2F; 线程</strong>，通过多个 Reactor 来解决了方案二的缺陷，主 Reactor 只负责监听事件，响应事件的工作交给了从 Reactor，Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案，Nginx 则采用了类似于 「多 Reactor 多进程」的方案。</p><h2 id="9-什么是一致性哈希？"><a href="#9-什么是一致性哈希？" class="headerlink" title="9.什么是一致性哈希？"></a>9.什么是一致性哈希？</h2><p>一致性哈希是一种哈希算法，就是在移除或者增加一个结点时，能够尽可能小的改变已存在 key 的映射关系。</p><p>一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。</p><ul><li>当删除一台节点机器时，这台机器上保存的所有对象都要移动到下一台机器。</li><li>添加一台机器到圆环边上某个点时，这个点的下一台机器需要将这个节点前对应的对象移动到新机器上。</li><li>更改对象在节点机器上的分布可以通过调整节点机器的位置来实现。</li></ul><p>为了<strong>解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本</strong>。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。</p><h1 id="Linux-命令"><a href="#Linux-命令" class="headerlink" title="Linux 命令"></a>Linux 命令</h1><h2 id="1-性能指标有哪些？"><a href="#1-性能指标有哪些？" class="headerlink" title="1.性能指标有哪些？"></a>1.性能指标有哪些？</h2><p>衡量网络的性能，分别是带宽、延时、吞吐率、PPS（Packet Per Second），它们表示的意义如下：</p><ul><li><strong>带宽</strong>，表示链路的最大传输速率，单位是 b&#x2F;s （比特 &#x2F; 秒），带宽越大，其传输能力就越强。</li><li><strong>延时</strong>，表示请求数据包发送后，收到对端响应，所需要的时间延迟。不同的场景有着不同的含义，比如可以表示建立 TCP 连接所需的时间延迟，或一个数据包往返所需的时间延迟。</li><li><strong>吞吐率</strong>，表示单位时间内成功传输的数据量，单位是 b&#x2F;s（比特 &#x2F; 秒）或者 B&#x2F;s（字节 &#x2F; 秒），吞吐受带宽限制，带宽越大，吞吐率的上限才可能越高。</li><li><strong>PPS</strong>，全称是 Packet Per Second（包 &#x2F; 秒），表示以网络包为单位的传输速率，一般用来评估系统对于网络的转发能力。</li></ul><p>除了以上这四种基本的指标，还有一些其他常用的性能指标，比如：</p><ul><li><strong>网络的可用性</strong>，表示网络能否正常通信；</li><li><strong>并发连接数</strong>，表示 TCP 连接数量；</li><li><strong>丢包率</strong>，表示所丢失数据包数量占所发送数据组的比率；</li><li><strong>重传率</strong>，表示重传网络包的比例；</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;硬件结构&quot;&gt;&lt;a href=&quot;#硬件结构&quot; class=&quot;headerlink&quot; title=&quot;硬件结构&quot;&gt;&lt;/a&gt;硬件结构&lt;/h1&gt;&lt;h2 id=&quot;1-冯诺依曼模型&quot;&gt;&lt;a href=&quot;#1-冯诺依曼模型&quot; class=&quot;headerlink&quot; title=&quot;1</summary>
      
    
    
    
    
    <category term="Offer" scheme="http://example.com/tags/Offer/"/>
    
  </entry>
  
  <entry>
    <title>C++</title>
    <link href="http://example.com/2024/06/09/C++/"/>
    <id>http://example.com/2024/06/09/C++/</id>
    <published>2024-06-09T07:43:59.000Z</published>
    <updated>2024-06-09T07:44:58.159Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-C和C-的区别"><a href="#1-C和C-的区别" class="headerlink" title="1.C和C++的区别"></a>1.C和C++的区别</h2><p><strong>设计思想上：</strong> C++是面向对象的语言，而C是面向过程的结构化编程语言。</p><p><strong>语法上：</strong></p><p>C++具有封装、继承和多态三大特性。</p><p>C++相比较C，增加了许多类型安全的功能，比如强制类型转换、智能指针。</p><p>C++支持泛型编程，比如模板类，函数模板等。</p><h2 id="2-构造函数后面的冒号有什么用？"><a href="#2-构造函数后面的冒号有什么用？" class="headerlink" title="2.构造函数后面的冒号有什么用？"></a>2.构造函数后面的冒号有什么用？</h2><p>在构造函数后面加冒号，表示冒号后面接构造函数初始化列表（constructor initialize list），主要有三种应用场景：</p><ol><li>对基类进行初始化;</li><li>对类成员进行初始化;</li><li>对类的const成员变量进行初始化;</li></ol><p>由于const成员变量的值无法在构造函数内部初始化，因此只能在变量定义时赋值或者使用初始化列表赋值。</p><h2 id="3-函数后面-default-和-delete-有什么用？"><a href="#3-函数后面-default-和-delete-有什么用？" class="headerlink" title="3. 函数后面 &#x3D; default 和 &#x3D; delete 有什么用？"></a>3. 函数后面 &#x3D; default 和 &#x3D; delete 有什么用？</h2><p><a href="http://t.csdnimg.cn/hUk79" title="http://t.csdnimg.cn/hUk79">http://t.csdnimg.cn/hUk79</a></p><p><code>=defalut</code>使得被修饰的函数为编译器默认的形式。只能用于（类的）特殊的成员函数（默认构造函数，复制构造函数，析构函数等）。</p><p><code>=delete</code>使得编译器禁止该类型的成员函数生成。例如：1.禁用拷贝构造函数；2.禁用不需要用的参数转换。</p><p>对特殊成员函数使用以上修饰符使得代码更容易阅读。</p><h2 id="4-类的大小和什么有关系？"><a href="#4-类的大小和什么有关系？" class="headerlink" title="4.类的大小和什么有关系？"></a>4.类的大小和什么有关系？</h2><p>平时所声明的类只是一种类型定义，它本身是没有大小可言的。</p><p>这里所说的大小，其实指的是类的对象所占的大小。因此，如果用sizeof运算符对一个类型名操作，得到的是具有该类型实体的大小。</p><p>类的大小与普通数据成员有关，与成员函数和静态成员无关。即普通成员函数、静态成员函数、静态数据成员、静态常量数据成员均对类的大小无影响。</p><p><font color="#F100">静态数据成员之所以不计算在类的对象大小内，是因为类的静态数据成员被该类的所有对象共享，并不属于哪个对象。</font></p><p>虚函数对类的大小有影响，是因为虚函数表指针带来的影响；<br>虚继承对类的大小有影响，是因为虚基表指针带来的影响。</p><p><a href="http://t.csdnimg.cn/FR01C" title="http://t.csdnimg.cn/FR01C">http://t.csdnimg.cn/FR01C</a><br><strong>c++空类（这个类不带任何数据）的大小不为0，为1。</strong></p><p>因为：new需要分配不同的内存地址，不能分配内存大小为0的空间，避免除以 sizeof(T)时得到除以0错误，故使用一个字节来区分空类。</p><h2 id="5-struct-和-typedef-struct-什么区别？"><a href="#5-struct-和-typedef-struct-什么区别？" class="headerlink" title="5.struct 和 typedef struct 什么区别？"></a>5.struct 和 typedef struct 什么区别？</h2><p>C ：</p><pre><code>typedef struct student &#123;    int a;&#125;Stu;</code></pre><p>这时声明变量就可以：<code>Stu stu1;</code><br>如果上面没有加 <code>typedef</code> 就必须用 <code>struct student stu1</code> 来声明。这里的 <code>Stu</code> 实际上就是 <code>struct Student</code> 的别名。<br>另外这里也可以不写 <code>Student typedef struct &#123;&#125;Stu</code>; 那声明变量的时候就不能<code>struct Student stu1;</code>了只能<code>Stu stu1;</code>）</p><p>C++:</p><ol><li><code>struct name &#123;int a;&#125;stu;</code> 这里 <code>stu</code> 是一个变量。</li><li><code>typedef struct name&#123;int a;&#125;stu;</code>这里的 <code>stu</code> 是一个结构体类型。</li></ol><h2 id="6-函数后面加const"><a href="#6-函数后面加const" class="headerlink" title="6.函数后面加const"></a>6.函数后面加const</h2><p><code>const</code> 只能加在类的成员函数后面（普通函数不可以），也就是说这些成员函数是只读函数。</p><p>1、非静态成员函数后面加const（加到非成员函数或静态成员后面会产生编译错误）</p><p>2、加了cosnt的成员函数，表示成员函数隐含传入的this指针为const指针，决定了在该成员函数中，任意修改它所在的类的成员的操作都是不允许的（因为隐含了对this指针的const引用）<br>非静态成员函数后面加 <code>const</code> 和 <code>mutable</code> 是反义词</p><p>加了 <code>const</code> 的成员函数可以被 非const对象 和 const对象调用。<strong>注意是对象</strong>。</p><p>但不加 <code>const</code> 的成员函数只能被 非const对象 调用。</p><p><font color="#A100">函数前面加 cosnt 表示返回值是 const，函数后面加 const 表示不可以修改 class 的成员。</font></p><h2 id="7-共享数据的保护"><a href="#7-共享数据的保护" class="headerlink" title="7.共享数据的保护"></a>7.共享数据的保护</h2><p>1.常引用：所引用的形参不能被更新</p><pre><code>void display(const double&amp; a);</code></pre><p>2.常对象：在生存期内不能被更新，但必须被初始化</p><pre><code>A const a(3, 4);</code></pre><p>3.常成员函数：不能修改对象中数据成员，也不能调用类中没有被const修饰的成员函数（常对象唯一的对外接口）。如果声明了一个常对象，则该对象只能调用它的常函数！另外，可以用于对重载函数的区分。</p><pre><code>void print();void print() const;</code></pre><p>4.extern int a;使得其他文件也能访问该变量</p><p>声明一个函数或定义函数时，冠以 <code>static</code> 的话，函数的作用域就被限制在了当前编译单元，当前编译单元内也必须包含函数的定义，也只在其编译单元可见，其他单元不能调用这个函数（每一个cpp文件就是一个编译单元）</p><h2 id="8-运算符重载注意"><a href="#8-运算符重载注意" class="headerlink" title="8.运算符重载注意"></a>8.运算符重载注意</h2><p>单目运算符最好重载为成员函数，双目最好为友元函数。</p><p><code>=、[]</code>只能重载为成员函数，<code>&lt;&lt;</code>和<code>&gt;&gt;</code>只能重载为友元函数。</p><h2 id="9-程序内存分配方式以及它们的区别"><a href="#9-程序内存分配方式以及它们的区别" class="headerlink" title="9.程序内存分配方式以及它们的区别"></a>9.程序内存分配方式以及它们的区别</h2><p>内存分配大致上可以分成5块：</p><ol><li><strong>栈区（stack）</strong>：栈，就是那些由编译器在需要时分配，在不需要的时候自动清除的变量的存储区。里面的变量通常是局部变量、函数参数等。（由编译器管理）</li><li><strong>堆区（heap）</strong>：一般由程序员分配、释放，若程序员不释放，程序结束时可能由系统回收。注意，它与数据结构中的堆时两回事，分配方式类似于链表。</li><li><strong>全局区（静态区）（static）</strong>：全局变量和静态变量被分配到同一块内存中。程序结束后由系统释放。</li><li><strong>常量存储区</strong>：常量字符串就是放在这里的，不允许修改，程序结束后由系统释放。</li><li><strong>程序代码区</strong>：存放函数体的二进制代码。</li></ol><h2 id="10-全局变量、全局静态变量、静态变量、静态函数"><a href="#10-全局变量、全局静态变量、静态变量、静态函数" class="headerlink" title="10.全局变量、全局静态变量、静态变量、静态函数"></a>10.全局变量、全局静态变量、静态变量、静态函数</h2><h3 id="全局静态变量和全局变量的区别"><a href="#全局静态变量和全局变量的区别" class="headerlink" title="全局静态变量和全局变量的区别"></a>全局静态变量和全局变量的区别</h3><p>1.若程序由一个源文件构成时，全局变量与全局静态变量没有区别；</p><p>2.若程序由多个源文件构成时，全局变量与全局静态变量不同：全局静态变量使得该变量成为定义该变量的源文件所独享，即全局静态变量对组成该程序的其他源文件时无效的；</p><p>3.具有外部链接的静态，可以在所有源文件里调用，除了本文件，其他文件可以通过extern的方式引用。</p><p>静态变量只被所属源文件使用。</p><h3 id="static的作用"><a href="#static的作用" class="headerlink" title="static的作用"></a>static的作用</h3><p><strong>1、全局静态变量</strong></p><p>在全局变量前加上关键字 <code>static</code>，全局变量就被定义成一个全局静态变量。</p><p><strong>存放区</strong>：存放在静态存储区，在整个程序运行期间一直存在。</p><p><strong>初始化</strong>：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非它被显式初始化）</p><p><strong>作用域</strong>：全局静态变量在声明它的文件之外是不可见的，准确来说作用域是从定义之处开始，到文件结尾。</p><p><strong>2、局部静态变量</strong></p><p>在局部变量前加上关键字 <code>static</code>，局部变量就被定义成一个局部静态变量。</p><p><strong>存放区</strong>：静态存储区。</p><p><strong>初始化</strong>：未经初始化的局部静态变量会被自动初始化为0（自动对象的值是任意的，除非它被显示初始化）</p><p><strong>作用域</strong>：作用域仍然是局部作用域，当定义它的语句块结束时，作用域结束。但是当局部静态变量离开作用域后，并没有被销毁，而是仍然驻留在内存当中，只不过我们不能对其进行访问，除非该函数再次被调用，并且该局部静态变量值不变。</p><p><strong>3、静态函数</strong></p><p>在函数返回类型前加 <code>static</code>，函数就被定义为静态函数。函数的定义和声明在默认情况下都是 <code>extern</code> 的，但静态函数只在声明它的文件当中可见，不能被其他文件所用。<br>这个函数只可以被本cpp内使用，不会和其他cpp中的同名函数引起冲突。</p><p><strong>warning</strong>：（没懂）不要在头文件中声明 <code>static</code> 的全局函数，不要在cpp内声明 非static 的全局函数，如果你要在多个cpp中复用该函数，就把它的声明提到头文件中去，否则cpp内部声明需加上static修饰。</p><p><strong>4、类的静态成员</strong></p><p>在类中，静态成员可以实现多个对象之间的数据共享，并且使用静态数据成员还不会被破坏隐藏的原则，也就是保证了安全性。因此，静态成员是类的所有对象中共享的成员，而不是某个对象的成员。对多个对象来说，静态数据成员只存储一处，供所有对象共用。</p><p><strong>5、类的静态函数</strong><br>静态成员函数和静态成员一样，它们都属于类的静态成员，它们都不是对象成员。因此，对静态成员的引用不需要用对象名，可以直接使用 <code>class_name::static_func()</code> 就可以访问。</p><h3 id="静态成员函数与普通成员函数的区别"><a href="#静态成员函数与普通成员函数的区别" class="headerlink" title="静态成员函数与普通成员函数的区别"></a>静态成员函数与普通成员函数的区别</h3><p>静态成员函数没有this指针，只能访问静态成员（包括静态成员变量和静态成员函数）</p><p>普通成员函数有this指针，可以访问类中的任意成员（普通成员变量和静态成员变量，好像静态成员函数没有this指针不能通过this访问，但是可以通过类名::访问）；而静态成员函数没有this指针。</p><h2 id="11-new-delete-与-malloc-free的联系与区别"><a href="#11-new-delete-与-malloc-free的联系与区别" class="headerlink" title="11.new delete 与 malloc free的联系与区别"></a>11.new delete 与 malloc free的联系与区别</h2><p><code>new delete </code>和 <code>malloc free</code>都是释放申请的堆上的空间，都是成对存在的，否则将会造成内存泄漏或者二次释放。</p><p>不同的是，<code>new delete</code>是C++<code>中定义的操作符</code>，<code>new</code> 除了分配空间外，还会调用类的构造函数来完成初始化工作，delete 除了释放空间外还会调用类的析构函数。而malloc和free是C语言中定义的函数。</p><h2 id="12-explicit"><a href="#12-explicit" class="headerlink" title="12.explicit"></a>12.explicit</h2><p><code>explicit</code> 关键字只能用于类的构造函数的声明上。它的作用是防止构造函数进行的隐式转换。</p><p>在C++中，一个参数的构造函数（或者除了第一个参数外其余参数都有默认值的多参构造函数），承担了两个角色：</p><p>第一是构造；</p><p>第二是默认且隐含的类型转换操作符。即如果构造函数接收到的参数会默认进行隐式转换。</p><p>隐式转换看起来很方便，但是某些情况下违背了程序员的本意。这个时候就要加上explicit修饰，指定这个构造器只能被明确的调用&#x2F;使用，不能进行隐式转换。</p><pre><code>class A&#123;public:    explicit A(int a, int b) : m_a(a), m_b(b) &#123;&#125;;private:    int m_a;    int m_b;&#125;int main()&#123;    A test(1, 2); //正确    A test1(2.2, 2); // 错误，存在double-&gt;int的隐式转换。&#125;</code></pre><h2 id="13-c-的四种-cast-转换"><a href="#13-c-的四种-cast-转换" class="headerlink" title="13.c++的四种 cast 转换"></a>13.c++的四种 cast 转换</h2><p>cast转换是C++的强制转换：<code>cast-name&lt;target_type&gt;(expression);</code></p><p>1、<code>const_cast</code><br>唯一一个可以改变const性质的转换</p><p>2、<code>static_cast</code><br>任何具有明确定义的类型转换，只要不包含底层const，都可以使用static_cast</p><p>3、<code>dynamic_cast</code><br>用于动态类型转换。只能用于含有虚函数的类，用于类层次间的向上和向下转化。只能转指针或引用。向下转化时，如果时非法的对于指针返回 <code>null</code>，对于引用抛出异常。要深入理解内部转换的原理。</p><p>向上转换：指的是子类向基类的转换。<br>向下转换：指的是基类向子类的转换。</p><p>它通过判断在执行到该语句的时候变量的运行时类型和要转换的类型是否相同来判断是否能够进行向下转换。</p><p>4、<code>reinterpret_cast</code><br>几乎什么都可以转，可能会出问题，尽量少用。</p><h2 id="14-为什么不用C的强制转换？"><a href="#14-为什么不用C的强制转换？" class="headerlink" title="14.为什么不用C的强制转换？"></a>14.为什么不用C的强制转换？</h2><p>C的强制转换表面上看起来功能强大什么都能转，但是转化不够明确，不能进行错误检查，容易出错。</p><p>C的强制转换 <code>(type_name)expression</code></p><h2 id="15-mutable关键字"><a href="#15-mutable关键字" class="headerlink" title="15.mutable关键字"></a>15.mutable关键字</h2><p><code>mutable</code> 的中文意思时可变的、易变的，跟 constant（即C++里的const）是反义词。在C++中，mutable 也是为了突破 const 的限制而设置的。被 mutable 修饰的变量（**<code>mutable</code>只能用于修饰类的非静态数据成员**），将永远处于可变的状态（可以修改成员数据之类的），即使在一个const函数中。</p><h2 id="16-用const修饰函数的返回值"><a href="#16-用const修饰函数的返回值" class="headerlink" title="16.用const修饰函数的返回值"></a>16.用const修饰函数的返回值</h2><p>如果给以“指针传递”方式的函数返回值加 <code>const</code> 修饰，那么函数返回值（即指针）的内容不能修改，且该返回值只能被赋给加 <code>const</code> 的同类型指针。一般只在返回值为引用或指针时使用，返回其他值时没有必要。</p><pre><code>const char* get_string(void);char *str = get_string();//编译报错const char *str = get_string();//正确</code></pre><h2 id="17-宏、const、enum"><a href="#17-宏、const、enum" class="headerlink" title="17.宏、const、enum"></a>17.宏、const、enum</h2><p><code>#define</code>不被视为语言的一部分（#define属于预处理器）。</p><p>对于单纯常量，最好用 <code>const</code> 对象或者 <code>enum</code> 替换<code>#define</code>。</p><p>对于类似函数的宏，尽量使用内联函数替换掉 <code>#define</code></p><p><strong>编译器处理方式不同</strong>: <code>define</code> 宏是在预处理阶段展开; <code>const</code> 常量是在编译运行阶段使用。</p><p><strong>类型</strong>：<br><code>define</code> 宏没有类型，不做任何类型检查，仅仅是展开；<br><code>const</code> 常量没有具体的类型，在编译阶段会执行类型检查。</p><p><strong>起作用的方式</strong>：<code>#define</code> 只是简单的字符串替换，没有类型检查。而 <code>const</code> 有对应的数据类型，是要进行判断的，可以避免一些低级的错误。正因为 <code>define</code> 只是简单的字符串替换，会导致边界效应，很容易犯错。</p><pre><code>#define N 2+3const double a = N/2; //结果是2+3/2 = 2+1 = 3const double b = (double)N / (double)2;//我们预想的答案是2.5，可实际输出的值是2 + 3 / 2 = 3.5</code></pre><p><strong>占用空间</strong>：<br><code>define</code> 宏仅仅是展开，有多少地方使用，就展开多少次，不会分配内存，占用代码段空间；<br><code>const</code> 常量会在内存中分配（可以是在堆中也可以是在栈中） 占用数据段空间</p><p><strong>调试角度</strong>：<br><code>const</code> 常量是可以进行调试的，<code>#define</code> 不能进行调试，因为在预编译阶段就已经替换掉了。</p><p><strong>作用域</strong>：<code>const</code> 变量是由作用域的，<code>#define</code> 在没有遇到 <code>#undefine</code> 之前是没有作用域限制的。</p><h2 id="18-程序编译"><a href="#18-程序编译" class="headerlink" title="18.程序编译"></a>18.程序编译</h2><p>程序编译是指将源文件翻译成二进制目标代码的过程。主要是检查语法错误，正确的源程序文件经过编译后在磁盘上生成目标文件。便已产生的目标文件是可重定位的程序模块，不能直接运行。链接则是把目标文件和其他分别进行编译生成的目标程序模块以及系统提供的标准库函数链接在一起，生成可运行的可执行文件。</p><h2 id="19-class-和-struct-的区别"><a href="#19-class-和-struct-的区别" class="headerlink" title="19.class 和 struct 的区别"></a>19.class 和 struct 的区别</h2><p>c++中，class 和 struct 都可以定义一个类。<br>它们有以下两点区别：</p><p>1、默认继承权限，如果不指定，来自 class 的继承按照 private 继承处理，来自struct 的继承按照 public 继承处理。</p><p>2、成员的默认访问权限。class 的成员默认是 private 权限，struct 默认是public权限。</p><p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</p><h2 id="20-C-默认编写并调用了哪些函数"><a href="#20-C-默认编写并调用了哪些函数" class="headerlink" title="20.C++ 默认编写并调用了哪些函数"></a>20.C++ 默认编写并调用了哪些函数</h2><p>编译器会主动为用户编写的任何类声明一个拷贝构造函数、拷贝复制操作符和一个析构函数，同时如果声明生命任何构造函数，编译器也会为你声明一个 <code>default</code> 版本的拷贝构造函数，这些函数都是 <code>public</code> 且 <code>inline</code> 的。</p><p>注意，上边说的是声明，只有当这些函数有调用需求的时候，编译器才会帮你去实现它们。但是编译器替你实现的函数可能在类内引用、类内指针、有const成员以及类型有虚属性的情形下会出问题：</p><ol><li>对于拷贝构造函数，要考虑到类内成员有没有深拷贝的需求，如果有的话就需要自己编写拷贝构造函数&#x2F;操作符，而不是把这件事情交给编译器来做。</li><li>对于拷贝构造函数，如果类内有引用成员或 <code>const</code> 成员，需要自己定义拷贝行为，因为编译器替你实现的拷贝行为在上述两个场景很有可能是有问题的。</li><li>对于析构函数，如果该类有多态需求，请主动将析构函数声明为 <code>virtual</code></li></ol><h2 id="21-为多态基类声明-virtual"><a href="#21-为多态基类声明-virtual" class="headerlink" title="21.为多态基类声明 virtual"></a>21.为多态基类声明 virtual</h2><p>带有多态性质的基类必须将析构函数声明为虚函数，防止指向子类的基类指针在被释放时只局部销毁了该对象。</p><p>如果一个类有多态的内涵，那么几乎不可避免的会有基类的指针（或引用）指向子类对象，因为非虚函数没有动态类型，所以如果基类的析构函数不是虚函数，那么在基类指针析构时会直接调用基类的析构函数，造成子类对象仅仅析构了基类的那一部分，有内存泄漏的风险。</p><p>除此之外，还需注意：</p><ol><li>需要注意的是，普通的基类无需也不应该有虚析构函数，因为虚函数无论在时间还是空间上都会有代价。</li><li>如果一个类型没有被设计成基类，又有被误继承的风险，请在类中声明为 <code>final</code> （C++ 11），这样禁止派生可以防止误继承造成上述问题。</li><li>编译器自动生成的析构函数时非虚的，所以多态基类必须将析构函数显示声明为virtual。</li></ol><h2 id="22-禁止使用编译器自动生成的函数"><a href="#22-禁止使用编译器自动生成的函数" class="headerlink" title="22.禁止使用编译器自动生成的函数"></a>22.禁止使用编译器自动生成的函数</h2><p>如果类型在语义或功能上需要明确禁止某些函数的调用行为，比如禁止拷贝行为，那么就应该禁止编译器去自动生成它：</p><ol><li>将被禁止生成的函数声明为 <code>private</code> 并省略实现，这样可以禁止来自类外的调用。但是如果类内不小心调用了（成员函数、友元），那么会得到一个链接错误。</li><li>将上述的可能的链接错误转移到编译期间。设计一不可拷贝的工具基类，将真正不可拷贝的基类私有继承该基类型即可，但是这样的做法过于复杂，对于已经有继承关系的类型会引入多继承，同时让代码晦涩难懂。</li><li>C++11可以直接使用 <code>= delete</code> 来声明拷贝构造函数，显示禁止编译器生成该函数。</li></ol><h2 id="23-别让异常逃离析构函数"><a href="#23-别让异常逃离析构函数" class="headerlink" title="23.别让异常逃离析构函数"></a>23.别让异常逃离析构函数</h2><p>析构函数一般情况下不应抛出异常，因为很大可能发生各种未定义的问题，包括但不限于内存泄露、程序异常崩溃、所有权被锁死等。</p><p>析构函数是一个对象生存期的最后一刻，负责许多重要的工作，如线程，连接和内存等各种资源所有权的归还。如果析构函数执行期间某个时刻抛出了异常，就说明抛出异常后的代码无法再继续执行，这是一个非常危险的举动——因为析构函数往往是为类对象兜底的，甚至是在该对象其他地方出现任何异常的时候，析构函数也有可能会被调用来给程序擦屁股。在上述场景中，如果在一个异常环境中执行的析构函数又抛出了异常，很有可能会让程序直接崩溃。</p><p>在析构函数中只负责记录，需要时刻保证析构函数能够执行到底</p><h2 id="24-不要在构造和析构过程中调用-virtual-函数"><a href="#24-不要在构造和析构过程中调用-virtual-函数" class="headerlink" title="24.不要在构造和析构过程中调用 virtual 函数"></a>24.不要在构造和析构过程中调用 virtual 函数</h2><p>在多态环境中，需要重新理解构造函数和析构函数的意义，这两个函数在执行过程中，涉及到了对象类型从基类到子类，再从子类到基类的转变。</p><p>一个子类对象开始创建时，首先调用的是基类的构造函数，在调用子类构造函数之前，<strong>该对象将一直保持着“基类对象”的身份而存在</strong>，自然在基类的构造函数中调用的虚函数——将会是基类的虚函数版本，在子类的构造函数中，<strong>原先的基类对象变成了子类对象</strong>，这时子类构造函数里调用的是子类的虚函数版本。</p><p>这是一件有意思的事情，这说明<strong>在构造函数中虚函数并不是虚函数</strong>，在不同的构造函数中，调用的虚函数版本并不同，因为随着不同层级的构造函数调用时，对象的类型在实时变化。那么相似的，析构函数在调用的过程中，子类对象的类型从子类退化到基类。</p><p>因此，如果无法在基类的构造函数中调用子类的虚函数。</p><h2 id="25-在-operator-中处理“自我赋值”"><a href="#25-在-operator-中处理“自我赋值”" class="headerlink" title="25.在 operator&#x3D; 中处理“自我赋值”"></a>25.在 operator&#x3D; 中处理“自我赋值”</h2><p>自我赋值指的是将自己赋给自己。这是一种看似愚蠢无用但却在代码中出现次数比任何人想象的多得多的操作，这种操作常常需要假借指针来实现：</p><pre><code>*pa = *pb; //pa和pb指向同一对象，便是自我赋值。arr[i] = arr[j];//i和j相等，便是自我赋值</code></pre><p>那么对于管理一定资源的对象重载的 <code>operator =</code>  中，一定要对是不是自我赋值格外小心并且增加预判，因为无论是深拷贝还是资源所有权的转移，原先的内存或所有权一定会被清空才能被赋值，如果不加处理，这套逻辑被用在自我赋值上会发生——先把自己的资源给释放掉了，然后又把以释放掉的资源赋给了自己——出错了</p><p>第一种做法是在赋值前增加预判，但是这种做法没有异常安全性，试想如果在删除掉原指针指向的内存后，在赋值之前任何一处抛出了异常，那么原指针就指向了一块已经被删除的内存。</p><pre><code>SomeClass&amp; SomeClass::operator=(const SomeClass&amp; rhs) &#123;  if (this == &amp;rhs) return *this;    delete ptr;  ptr = new DataBlock(*rhs.ptr);//如果此处抛出异常，ptr将指向一块已经被删除的内存。  return *this;&#125;</code></pre><p>如果我们把异常安全性也考虑在内，那么我们就会得到如下方法，令人欣慰的是这个方法也解决了自我赋值的问题。</p><pre><code>SomeClass&amp; SomeClass::operator=(const SomeClass&amp; rhs) &#123;  DataBlock* pOrg = ptr;  ptr = new DataBlock(*rhs.ptr);//如果此处抛出异常，ptr仍然指向之前的内存。  delete pOrg;  return *this;&#125;</code></pre><p>另一个使用copy and swap技术的替代方案。</p><h2 id="26-复制对象时勿忘其每一个成分"><a href="#26-复制对象时勿忘其每一个成分" class="headerlink" title="26.复制对象时勿忘其每一个成分"></a>26.复制对象时勿忘其每一个成分</h2><p>当你给类多加了成员变量时，不要忘记在拷贝构造函数和赋值操作符中对新加的成员变量进行处理。如果忘记处理，编译器也不会报错。</p><p>如果类有继承，那么在为子类编写拷贝构造函数时一定要格外小心复制基类的每一个成分，这些成分往往是 <code>private</code> 的，所以无法访问它们，应该让子类使用子类的拷贝构造函数去调用相应基类的拷贝构造函数：</p><pre><code>//在成员初始化列表显示调用基类的拷贝构造函数ChildClass::ChildClass(const ChildClass&amp; rhs) : BaseClass(rhs) &#123;      // ...&#125;</code></pre><p>除此之外，拷贝构造函数和拷贝赋值操作符，他们两个中任意一个不要去调用另一个。</p><p>其根本原因在于拷贝构造函数在构造一个对象——这个对象在调用之前并不存在；而赋值操作符在改变一个对象——这个对象是已经构造好了的。因此<strong>前者调用后者是在给一个还未构造好的对象赋值；而后者调用前者就像是在构造一个已经存在了的对象。</strong></p><h2 id="27-设计-class-犹如设计-type"><a href="#27-设计-class-犹如设计-type" class="headerlink" title="27.设计 class 犹如设计 type"></a>27.设计 class 犹如设计 type</h2><p>每次设计class时最好在脑中过一遍以下问题：</p><ol><li>对象该如何创建销毁：包括构造函数、析构函数以及 new 和 delete 操作符的重构需求。</li><li>对象的构造函数与赋值行为应有何区别：构造函数和赋值操作符的区别，重点在资源管理上。</li><li>对象被拷贝时应考虑的行为：拷贝构造函数。</li><li>对象的合法值是什么？最好在语法层面、至少在编译前应对用户做出监督。</li><li>新的类型是否应该复合某个继承体系，这就包含虚函数的覆盖问题。</li><li>新类型和已有类型之间的隐式转换问题，这意味着类型转换函数和非explicit函数之间的取舍。</li><li>新类型是否需要重载操作符。</li><li>什么样的接口应当暴露在外，而什么样的技术应当封装在内（public和private）</li><li>新类型的效率、资源获取归还、线程安全性和异常安全性如何保证。</li><li>这个类是否具备template的潜质，如果有的话，就应改为模板类。</li></ol><h2 id="28-函数接口应该以const引用的形式传参，而不应该是按值传参"><a href="#28-函数接口应该以const引用的形式传参，而不应该是按值传参" class="headerlink" title="28.函数接口应该以const引用的形式传参，而不应该是按值传参"></a>28.函数接口应该以const引用的形式传参，而不应该是按值传参</h2><ol><li>按值传参涉及大量参数的复制，这些副本大多是没有必要的。</li><li>如果拷贝构造函数设计的是深拷贝而非浅拷贝，那么拷贝的成本将远远大于拷贝某几个指针。</li><li>对于多态而言，将父类设计成按值传参，如果传入的是子类对象，仅会对子类对象的父类部分进行拷贝，即部分拷贝，而所有属于子类的特性将被丢弃，造成不可预知的错误，同时虚函数也不会被调用。</li><li>小的类型并不意味着按值传参的成本就会小。首先，类型的大小与编译器的类型和版本有很大关系，某些类型在特定编译器上编译结果会比其他编译器大得多。小的类型也无法保证在日后代码复用和重构之后，其类型始终很小。</li></ol><h2 id="29-对class内所有成员变量声明为private，private意味着对变量的封装"><a href="#29-对class内所有成员变量声明为private，private意味着对变量的封装" class="headerlink" title="29.对class内所有成员变量声明为private，private意味着对变量的封装"></a>29.对class内所有成员变量声明为private，private意味着对变量的封装</h2><p>简单的来说，把所有成员变量声明为 private 的好处有两点。首先，所有的变量都是private了，那么所有的 public 和 protected 成员都是函数了，用户在使用的时候也就无需区分，这就是语法一致性；其次，对变量的封装意味着，<strong>可以尽量减小因类型内部改变造成的类外外代码的必要改动</strong>。</p><p><strong>public 和 protected属性在一定程度上是等价的</strong>。一个自定义类型被设计出来就是供客户使用的，那么客户的使用方法无非是两种——用这个类创建对象或者继承这个类以设计新的类——以下简称为第一类客户和第二类客户。</p><p>从封装的角度来说，一个 public 的成员说明了类的作者决定对类的第一种客户不封装此成员，而一个 protected 的成员说明了类的作者对类的第二种客户不封装此成员。</p><h2 id="30-若所有参数皆需类型转换，请为此采用non-member函数"><a href="#30-若所有参数皆需类型转换，请为此采用non-member函数" class="headerlink" title="30.若所有参数皆需类型转换，请为此采用non-member函数"></a>30.若所有参数皆需类型转换，请为此采用non-member函数</h2><p>如果我们在使用操作符时希望操作符的任意操作数都可能发生隐式类型转换，那么应该把该操作符重载成非成员函数。</p><p>首先说明：<strong>如果一个操作符是成员函数，那么它的第一个操作数（即调用对象）不会发生隐式类型转换。</strong></p><p>操作符一旦被设计为成员函数，它在被使用时的特殊性就显现出来了——单从表达式无法直接看出是类的哪个对象在调用这个操作符函数</p><p>做为成员函数的操作符默认操作符的第一个操作数应当是正确的类对象——<strong>编译器根据第一个操作数的类型来确定被调用的操作符到底属于哪一个类的</strong>。</p><p>举例说明：当 <code>Ratinoal</code> 类的构造函数允许 <code>int</code> 类型隐式转换为 <code>Rational</code> 类型时，<code>Rational z = x + 2;</code>是可以通过编译的，因为操作符是被 <code>Rational</code> 类型的 <code>x</code> 调用，同时将 <code>2</code> 隐式转换为 <code>Ratinoal</code> 类型，完成加法。但是 <code>Rational z = 2 + x;</code>却会引发编译器报错，因为由于操作符的第一个操作数不会发生隐式类型转换，所以加号“+”实际上调用的是<code>2</code>——一个 <code>int</code> 类型的操作符，因此编译器会试图将 <code>Rational</code> 类型的 <code>x</code> 转为 <code>int</code>，这样是行不通的。</p><h2 id="31-子类必须涵盖父类的所有特点，必须无条件继承父类的所有特性和接口"><a href="#31-子类必须涵盖父类的所有特点，必须无条件继承父类的所有特性和接口" class="headerlink" title="31.子类必须涵盖父类的所有特点，必须无条件继承父类的所有特性和接口"></a>31.子类必须涵盖父类的所有特点，必须无条件继承父类的所有特性和接口</h2><p>在确定是否需要public继承的时候，我们首先要搞清楚子类是否必须拥有父类每一个特性，如果不是，则无论生活经验是什么，都不能视作”is-a”的关系。<strong>public 继承关系不会使父类的特性或接口在子类中退化，只会使其扩充。</strong></p><h2 id="32-避免遮掩继承而来的名称"><a href="#32-避免遮掩继承而来的名称" class="headerlink" title="32.避免遮掩继承而来的名称"></a>32.避免遮掩继承而来的名称</h2><p>在父类中，虚函数<code>foo()</code>被重载了两次，可能是由于参数类型重载（<code>foo(int)</code>），也可能是由于<code>const</code>属性重载(<code>foo() const</code>)。如果子类仅对父类中的<code>foo()</code>进行了覆写，那么在子类中父类的另外两个实现(<code>foo(int) ,foo() const</code>)也无法被调用，这就是名称遮盖问题——名<strong>称在作用域级别的遮盖是和参数类型以及是否虚函数无关的</strong>，即使子类重载了父类的一个同名，父类的所有同名函数在子类中都被遮盖。</p><p>如果想要重启父类中的函数名称，需要在子类有此需求的作用域中（可能是某成员函数中，可能是 <code>public</code> 或 <code>private</code> 内）加上 <code>using Base::foo;</code>，即可把父类作用域汇总的同名函数拉到目标作用域中，需要注意的是，此时父类中的<code>foo(int)</code>和<code>foo() const</code>都会被置为可用。</p><p>如果只想把父类某个在子类中某一个已经不可见的同名函数复用，可使用<code>inline forwarding function</code>。</p><h2 id="33-区分接口继承和实现继承"><a href="#33-区分接口继承和实现继承" class="headerlink" title="33.区分接口继承和实现继承"></a>33.区分接口继承和实现继承</h2><p>成员函数的接口总是会被继承，而public继承保证了，如果某个函数可施加在父类上，那么他一定能够被施加在子类上。不同类型的函数代表了父类对子类实现过程中不同的期望。</p><ul><li>在父类中声明纯虚函数，是为了<strong>强制子类拥有一个接口，并强制子类提供一份实现。</strong></li><li>在父类中声明虚函数，是为了<strong>强制子类拥有一个接口，并为其提供一份缺省实现。</strong></li><li>在父类中声明非虚函数，是为了<strong>强制子类拥有一个接口以及规定好的实现，并不允许子类对其做任何更改</strong>。</li></ul><p>在这其中，有可能出现问题的是普通虚函数，这是因为<em>父类的缺省实现并不能保证对所有子类都适用，因而当子类忘记实现某个本应有定制版本的虚函数时，父类应从代码层面提醒子类的设计者做相应的检查_，很可惜，普通虚函数无法实现这个功能</em>。<em><strong>一种解决方案是，在父类中为纯虚函数提供一份实现，作为需要主动获取的缺省实现</strong></em>，当子类在实现纯虚函数时，检查后明确缺省实现可以复用，则只需调用该缺省实现即可，这个主动调用过程就是在代码层面提醒子类设计者去检查缺省实现的适用性。</p><p>将纯虚函数、虚函数区分开的并不是在父类有没有实现——纯虚函数也可以有实现，其二者本质区别在于父类对子类的要求不同，前者<strong>在于从编译层面提醒子类主动实现接口</strong>，后者则侧重于<strong>给予子类自由度对接口做个性化适配</strong>。非虚函数则没有给予子类任何自由度，而是要求子类坚定的遵循父类的意志，<br><strong>保证所有继承体系内能有其一份实现</strong>。</p><h2 id="34-不重新定义继承而来的non-virtual函数"><a href="#34-不重新定义继承而来的non-virtual函数" class="headerlink" title="34.不重新定义继承而来的non-virtual函数"></a>34.不重新定义继承而来的non-virtual函数</h2><p>如果函数有多态调用的需求，一定记得把它设为虚函数，否则在动态调用（基类指针指向子类对象）的时候是不会调用到子类重载过的函数的，很可能会出错。</p><p>反之同理，如果一个函数父类没有设置为虚函数，你千万千万不要在子类重载它，也会犯上边类似的错误。</p><p>理由就是，多态的动态调用中，只有虚函数是动态绑定，非虚函数是静态绑定的——指针（或引用）的静态类型是什么，就调用那个类型的函数，和动态类型无关。</p><p>话说回来，<strong>虚函数的意思是“接口一定被继承，但实现可以在子类更改”，而非虚函数的意思是“接口和实现都必须被继承”。</strong></p><h2 id="35-绝不重新定义继承而来的缺省参数值"><a href="#35-绝不重新定义继承而来的缺省参数值" class="headerlink" title="35.绝不重新定义继承而来的缺省参数值"></a>35.绝不重新定义继承而来的缺省参数值</h2><p>在继承中：</p><ol><li>不要更改父类非虚函数的缺省参数值，其实不要重载父类非虚函数的任何东西，不要做任何改变！</li><li>虚函数不要写缺省参数值，子类自然也不要改，虚函数要从始至终保持没有缺省参数值。<blockquote><p>缺省参数是 声明或定义函数 时为函数的 形参指定一个缺省值（默认参数）。</p></blockquote></li></ol><p>虚函数在大多数情况是供动态调用，而在动态调用中，子类做出的缺省参数改变其实并没有生效，反而会引起误会，让调用者误以为生效了。</p><p>缺省参数值属于静态绑定的原因是为了提高运行时效率。</p><h2 id="36-类的复合：一个类的对象可以作为另一个类的成员"><a href="#36-类的复合：一个类的对象可以作为另一个类的成员" class="headerlink" title="36.类的复合：一个类的对象可以作为另一个类的成员"></a>36.类的复合：一个类的对象可以作为另一个类的成员</h2><p>什么情况下我们应该用类的复合:</p><p>第一种情况，非常简单，说明某一个类“拥有”另一个类对象作为一个属性，比如学生拥有铅笔、市民拥有身份证等，不会出错。</p><p>第二种情况被讨论的更多，即“一个类根据另一个类实现”。比如“用stack实现一个queue”，更复杂一点的情况可能是“用一个老版本的Google Chrome内核去实现一个红芯浏览器”。</p><h2 id="37-审慎地使用private继承"><a href="#37-审慎地使用private继承" class="headerlink" title="37.审慎地使用private继承"></a>37.审慎地使用private继承</h2><p>private继承正是表达“通过某工具类实现另一个类”。那么相似的，工具类在目标类中自然应该被隐藏——所有接口和变量都不应对外暴露出来。这也解释了private继承的内涵，它本质是一种__技术封装__，和public继承不同的是，private继承表达的是“<strong>只有实现部分被继承，而接口部分应略去”的思想。</strong></p><p>与private继承的内涵相对应，<strong>在private继承下，父类的所有成员都转为子类私有变量——不提供对外访问的权限</strong>，外界也无需关心子类内有关父类的任何细节。</p><p>当我们拥有“用一个类去实现另一个类”的需求的时候，如何在类的复合与private继承中做选择呢？</p><p>尽可能用复合，除非必要，不要采用private继承。<br>当我们需要对工具类的某些方法（虚函数）做重载时，我们应选择private继承，这些方法一般都是工具类内专门为继承而设计的调用或回调接口，需要用户自行定制实现。</p><h2 id="38-少使用多继承"><a href="#38-少使用多继承" class="headerlink" title="38.少使用多继承"></a>38.少使用多继承</h2><p>原则上不提倡使用多继承，因为多继承可能会引起多父类共用父类，导致在底层子类中出现多余一份的共同祖先类的拷贝。为了避免这个问题C++引入了虚继承，但是虚继承会使子类对象变大，同时使成员数据访问速度变慢，这些都是虚继承应该付出的代价。</p><h2 id="39-讲一讲封装、继承、多态是什么？"><a href="#39-讲一讲封装、继承、多态是什么？" class="headerlink" title="39.讲一讲封装、继承、多态是什么？"></a>39.讲一讲封装、继承、多态是什么？</h2><p><strong>封装</strong>：将具体实现过程和数据封装成一个函数，只能通过接口进行访问，降低耦合性，使类成为一个具有内部数据的自我隐藏能力、功能独立的软件模块。</p><p><strong>意义</strong>：保护或防止代码在无意之中被破坏，保护类中的成员，不让类中以外的程序直接访问或者修改，只能通过提供的公共接口访问。</p><hr><p><strong>继承</strong>：子类继承父类的特征和行为，复用了基类的全体数据和成员函数，具有从基类复制而来的数据成员和成员函数（基类私有成员可被继承，但是无法被访问），其中构造函数、析构函数、友元函数、静态数据成员、静态成员函数都不能被继承。基类中成员的访问方式只能决定派生类能否访问它们。增强了代码耦合性，当父类中的成员变量或者类本身被final关键字修饰时，修饰的类不能被继承，修饰的成员变量不能重写或修改。</p><blockquote><p>如果对一个类或者虚函数使用 final 关键字，则代表不允许再对其内容进行修改:<br> 对类使用final关键字，代表它不可以作为基类被继承；<br> 对虚函数使用final关键字，代表它不可以在子类中被重写。</p></blockquote><p><strong>意义</strong>：基类的程序代码可以被派生类服用，提高了软件复用的效率，缩短了软件开发的周期</p><hr><p><strong>多态</strong>：不同继承类的对象对同一消息做出不同的响应，基类的指针指向或绑定到派生类的对象，使得基类指针呈现不同的表现形式。</p><p><strong>意义</strong>：对已存在的代码具有可替代性，对代码具有可扩充性，新增子类不会影响已存在类的各种性质，在程序中体现了灵活多样的操作，提高了使用效率，简化了对应用代码的编写和修改过程。</p><h2 id="40-多态的实现原理（实现方式）是什么？以及多态的优点（特点）？"><a href="#40-多态的实现原理（实现方式）是什么？以及多态的优点（特点）？" class="headerlink" title="40.多态的实现原理（实现方式）是什么？以及多态的优点（特点）？"></a>40.多态的实现原理（实现方式）是什么？以及多态的优点（特点）？</h2><p><strong>实现方式</strong>：多态分为<strong>动态多态</strong>（动态多态是利用虚函数实现运行时的多态，即在系统编译的时候并不知道程序将要调用哪一个函数，只有在运行到这里的时候才能确定接下来会跳转到哪一个函数。）和<strong>静态多态</strong>（又称编译期多态，即在系统编译期间就可以确定程序将要执行哪个函数）。</p><p>其中动态多态是通过虚函数实现的，虚函数是类的成员函数，存在存储虚函数指针的表叫做<strong>虚函数表</strong>，虚函数表是一个存储类成员虚函数的指针，每个指针都指向调用它的地方，当子类调用虚函数时，就会去虚表里面找自己对应的函数指针，从而实现“谁调用、实现谁”从而实现多态。</p><blockquote><p>虚表是一个指针数组，其元素是虚函数的指针，每个元素对应一个虚函数的函数指针。需要指出的是，普通的函数即非虚函数，其调用并不需要经过虚表，所以虚表的元素并不包括普通函数的函数指针。<br>虚表内的条目，即虚函数指针的赋值发生在编译器的编译阶段，也就是说<strong>在代码的编译阶段，虚表就可以构造出来了。</strong></p></blockquote><blockquote><p><strong>虚表是属于类的，而不是属于某个具体的对象</strong>，一个类只需要一个虚表即可。同一个类的所有对象都使用同一个虚表。<br><font color="#A100">对象的虚表指针用来指向自己所属类的虚表，虚表中的指针会指向其继承的最近的一个类的虚函数。</font></p></blockquote><blockquote><p><a href="http://t.csdnimg.cn/sJZb5" title="虚函数表详解">虚函数表详解</a></p></blockquote><p>而静态多态则是通过函数重载（函数名相同，参数不同，两个函数在同一作用域），运算符重载，和重定义（又叫隐藏，指的是在继承关系中，子类实现了一个和父类名字一样的函数，（只关注函数名，和参数与返回值无关）这样的话子类的函数就把父类的同名函数隐藏了。<strong>隐藏只与函数名有关，与参数没有关系</strong>）来实现的。</p><p><strong>优点</strong>：加强代码的可扩展性，可替换性，增强程序的灵活性，提高使用效率，简化对应用代码的编写和修改过程。</p><h2 id="41-什么时候会执行函数的动态绑定？"><a href="#41-什么时候会执行函数的动态绑定？" class="headerlink" title="41.什么时候会执行函数的动态绑定？"></a>41.什么时候会执行函数的动态绑定？</h2><p>符合以下三个条件：</p><ol><li>通过指针来调用函数</li><li>指针upcast向上转型（继承类向基类的转换称为upcast）</li><li>调用的是虚函数</li></ol><p>如果一个函数调用符合以上三个条件，编译器就会把该函数调用编译成动态绑定，其函数的调用过程走的通过虚表的机制。</p><blockquote><p>“Upcasting”是面向对象编程中的一个概念，它指的是将一个子类对象的引用或指针转换为基类（也就是父类）类型的引用或指针。这种转换是安全的，因为子类对象是其基类对象的一个超集，这意味着子类对象包含其基类的所有成员。</p></blockquote><h2 id="42-动态绑定的流程"><a href="#42-动态绑定的流程" class="headerlink" title="42.动态绑定的流程"></a>42.动态绑定的流程</h2><ol><li>取出类的虚函数表的地址</li><li>根据虚函数表的地址找到虚函数表</li><li>根据找到的虚函数的地址调用虚函数。</li></ol><p><a href="https://blog.csdn.net/qq_21438461/article/details/126362661https://blog.csdn.net/qq_21438461/article/details/126362661">C++虚函数表：让多态成为可能的关键</a></p><h2 id="43-虚函数是怎么实现的？它存放在哪里在内存的哪个区？什么时候生成的？"><a href="#43-虚函数是怎么实现的？它存放在哪里在内存的哪个区？什么时候生成的？" class="headerlink" title="43.虚函数是怎么实现的？它存放在哪里在内存的哪个区？什么时候生成的？"></a>43.虚函数是怎么实现的？它存放在哪里在内存的哪个区？什么时候生成的？</h2><p>在C++中，虚函数的实现原理基于两个关键概念：虚函数表和虚函数指针</p><p><strong>虚函数表</strong>：每个包含虚函数的类都会生成一个虚函数表，其中存储着该类中所有虚函数的地址。虚函数表是一个由指针构成的数组，每个指针指向一个虚函数的实现代码。</p><p><strong>虚函数指针</strong>：在对象的内存布局中，编译器会添加一个额外的指针，称为虚函数指针或虚表指针。这个指针指向该对象对应的虚函数表，从而让程序能够动态的调用虚函数。</p><p>当一个基类指针或引用调用虚函数时，编译器会使用虚表指针来查找该对象对应的虚函数表，并根据函数在虚函数表中的位置来调用正确的虚函数。</p><p>在编译阶段生成，虚函数和普通函数一样存放在代码段，只是它的指针又存放在了虚表之中。</p><h2 id="44-智能指针的本质是什么，它们的实现原理是什么？"><a href="#44-智能指针的本质是什么，它们的实现原理是什么？" class="headerlink" title="44.智能指针的本质是什么，它们的实现原理是什么？"></a>44.智能指针的本质是什么，它们的实现原理是什么？</h2><p>智能指针就是帮C++程序员管理动态分配的内存的，它会帮助我们自动释放new出来的内存，从而避免内存泄漏。</p><p>智能指针本质是一个封装了一个原始C++指针的类模板，为了确保动态内存的安全性而产生的。</p><p>实现原理是通过一个对象存储需要被自动释放的资源，然后依靠对象的析构函数来释放资源。</p><p><a href="https://blog.csdn.net/cpp_learner/article/details/118912592?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522171379580616800197099831%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=171379580616800197099831&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-118912592-null-null.142%5Ev100%5Epc_search_result_base3&utm_term=%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88&spm=1018.2226.3001.4187">C++ 智能指针 - 全部用法详解</a></p><p><code>auto_ptr</code>：c++ 98定义的智能指针模板，定义了管理指针的对象，可以将 new 获得（直接或间接）的地址赋给这种对象。当对象过期时，其析构函数将使用delete 来释放内存。</p><p>头文件: <code>#include &lt;memory&gt;</code>；用法：<code>auto_ptr&lt;类型&gt; 变量名(new 类型)</code></p><p>C++11 后auto_ptr 已经被“抛弃”，已使用 <code>unique_ptr</code> 替代！C++11后不建议使用auto_ptr(原因)：<br>1). 复制或者赋值都会改变资源的所有权；<br>2). 在STL容器中使用auto_ptr存在着重大风险，因为容器内的元素必须支持可复制和可赋值；<br>3). 不支持对象数组的内存管理</p><hr><p>智能指针的三个常用函数：</p><ol><li>get() 获取智能指针托管的指针地址</li><li>release() 取消智能指针对动态内存的托管</li><li>reset() 重置智能指针托管的内存地址，如果地址不一致，原来的会被析构掉</li></ol><hr><p><code>unique_ptr</code>：unique_ptr 和 auto_ptr 用法几乎一样，除了一些特殊</p><p>特性：</p><ol><li>基于排他所有权模式：两个指针不能指向同一个资源</li><li>无法进行左值unique_ptr复制构造，也无法进行左值复制赋值操作，但允许临时右值赋值构造和赋值</li><li>保存指向某个对象的指针，当它本身离开作用域时会自动释放它指向的对象。</li><li>在容器中保存指针是安全的</li></ol><hr><p><code>shared_ptr</code>：可以记录引用特定内存对象的智能指针数量，当复制或拷贝时，引用计数加1，当智能指针析构时，引用计数减1，如果计数为零，代表已经没有指针指向这块内存，那么就释放它。</p><p>1.引用计数的使用：</p><p>调用 <code>use_count</code> 函数可以获得当前托管指针的引用计数。</p><p>2.构造</p><p>1). <code>shared_ptr&lt;T&gt; sp1;</code> 空的shared_ptr，可以指向类型为T的对象</p><p>2). <code>shared_ptr&lt; T &gt; sp2(new T());</code> 定义shared_ptr,同时指向类型为T的对象</p><p>3). <code>shared_ptr&lt;T[]&gt; sp4;</code> 空的shared_ptr，可以指向类型为T[]的数组对象 C++17后支持</p><p>4). <code>shared_ptr&lt;T[]&gt; sp5(new T[] &#123; … &#125;);</code> 指向类型为T的数组对象 C++17后支持</p><p>5). <code>shared_ptr&lt; T &gt; sp6(NULL, D());</code> 空的shared_ptr，接受一个D类型的删除器，使用D释放内存</p><p>6).<code>shared_ptr&lt; T &gt; sp7(new T(), D());</code>定义shared_ptr,指向类型为T的对象，接受一个D类型的删除器，使用D删除器来释放内存</p><p>3.初始化</p><p>1). 方式一：构造函数</p><pre><code>shared_ptr&lt;int&gt; up1(new int(10));  // int(10) 的引用计数为1shared_ptr&lt;int&gt; up2(up1);  // 使用智能指针up1构造up2, 此时int(10) 引用计数为2</code></pre><p>2). 方式二：使用make_shared 初始化对象，分配内存效率更高(推荐使用)<br>make_shared函数的主要功能是在动态内存中分配一个对象并初始化它，返回指向此对象的shared_ptr; 用法：</p><pre><code>make_shared&lt;类型&gt;(构造类型对象需要的参数列表);shared_ptr&lt;int&gt; up3 = make_shared&lt;int&gt;(2); // 多个参数以逗号&#39;,&#39;隔开，最多接受十个</code></pre><p>4.赋值</p><pre><code>shared_ptrr&lt;int&gt; up1(new int(10));  // int(10) 的引用计数为1shared_ptr&lt;int&gt; up2(new int(11));   // int(11) 的引用计数为1up1 = up2;// int(10) 的引用计数减1,计数归零内存释放，up2共享int(11)给up1, int(11)的引用计数为2</code></pre><p>5.主动释放对象</p><pre><code>shared_ptrr&lt;int&gt; up1(new int(10));up1 = nullptr ;// int(10) 的引用计数减1,计数归零内存释放 // 或up1 = NULL; // 作用同上 </code></pre><p>6.重置</p><p><code>p.reset();</code> 将p重置为空指针，所管理对象引用计数减1</p><p><code>p.reset(p1);</code> 将p重置为p1（的值）,p 管控的对象计数减1，p接管对p1指针的管控</p><p><code>p.reset(p1,d); </code>将p重置为p1（的值），p 管控的对象计数减1并使用d作为删除器;p1是一个指针！</p><p>7.交换</p><p>p1 和 p2 是智能指针</p><pre><code>std::swap(p1,p2); // 交换p1 和p2 管理的对象，原对象的引用计数不变p1.swap(p2);    // 交换p1 和p2 管理的对象，原对象的引用计数不变</code></pre><p>在使用shared_ptr智能指针时，要注意避免对象交叉使用智能指针的情况！ 否则会导致内存泄露！</p><hr><p><code>weak_ptr</code> :设计的目的是为配合 shared_ptr 而引入的一种智能指针来协助 shared_ptr 工作, 它只可以从一个 shared_ptr 或另一个 weak_ptr 对象构造, 它的<strong>构造和析构不会引起引用记数的增加或减少</strong>。 同时 weak_ptr 没有重载<code>*</code>和<code>-&gt;</code>但可以使用 lock 获得一个可用的 shared_ptr 对象。</p><pre><code>shared_ptr&lt;Girl&gt; sp_girl;sp_girl = wpGirl_1.lock();// 使用完之后，再将共享指针置NULL即可sp_girl = NULL;</code></pre><p><strong>expired</strong>：判断当前weak_ptr智能指针是否还有托管的对象，有则返回false，无则返回true</p><p><font color="A100">禁止delete 智能指针get 函数返回的指针：<br>如果我们主动释放掉get 函数获得的指针，那么智能 指针内部的指针就变成野指针了，析构时造成重复释放</font></p><h2 id="45-匿名函数的本质是什么？他的优点是什么？"><a href="#45-匿名函数的本质是什么？他的优点是什么？" class="headerlink" title="45.匿名函数的本质是什么？他的优点是什么？"></a>45.匿名函数的本质是什么？他的优点是什么？</h2><p>匿名函数了，也叫做lambda表达式。</p><pre><code>[capture](parameters) specifiers exception attr -&gt; return type &#123; /*code; */ &#125;[capture]代表捕获列表，括号内为外部变量的传递方式，包括值传递、引用传递等(parameters)代表参数列表，其中括号内为形参，和普通函数的形参一样specifiers exception attr代表附加说明符，一般为mutable、noexcept等-&gt;return type代表lambda函数的返回类型如 -&gt; int、-&gt; string等。在大多数情况下不需要，因为编译器可以推导类型&#123;&#125;内为函数主体，和普通函数一样</code></pre><p>匿名函数本质上是一个<strong>对象</strong>，在其定义的过程中会创建出一个<strong>栈对象</strong>，内部通过重载()符号实现函数调用的外表。</p><p><strong>优点</strong>：使用匿名函数，可以免去函数的声明和定义。这样匿名函数仅在调用函数的时候才会创建函数对象，而调用结束后立即释放，所以匿名函数比非匿名函数更节省空间。</p><h2 id="46-右值引用是什么，为什么要引入右值引用？"><a href="#46-右值引用是什么，为什么要引入右值引用？" class="headerlink" title="46.右值引用是什么，为什么要引入右值引用？"></a>46.右值引用是什么，为什么要引入右值引用？</h2><p>右值引用是为一个临时变量取别名，它只能绑定到一个临时变量或表达式（将亡值）上。实际开发中我们可能需要对右值进行修改（实现移动语义时就需要）而右值引用可以对右值进行修改。</p><p>为什么：</p><p>1.为了支持移动语义，右值引用可以绑定到临时对象、表达式等右值上，这些右值在生命周期结束后就会被销毁，因此可以在右值引用中窃取其资源，从而避免昂贵的复制操作，实现高效的移动语义。</p><p>2.完美转发：右值引用可以绑定到任何类型的右值上，可以将其作为参数传递给函数，并在函数内部将其“转发”到其他函数中，从而实现完美转发。</p><p>3.拓展可变参数模板，实现更加灵活的模板编程。</p><blockquote><p>左值准确来说是：一个表示数据的表达式(如变量名或解引用的指针），且可以获取他的地址（取地址），可以对它进行赋值；它可以在赋值符号的左边或者右边。</p></blockquote><blockquote><p>右值准确来说是：一个表示数据的表达式（如字面常量、函数的返回值、表达式的返回值），且不可以获取他的地址（取地址）；它只能在赋值符号的右边。</p></blockquote><blockquote><blockquote><blockquote><p>左值引用：给左值取别名；右值引用：给右值取别名</p></blockquote></blockquote></blockquote><blockquote><p>左值引用只能引用左值；const左值引用可以左值，也可以引用右值（因为右值通常是不可以改变的值，所以用const左值引用是可以的）；右值只能引用右值；左值可以通过</p><p>（左值）来转化为右值，继而使用右值引用。</p></blockquote><pre><code>int main()&#123;    // 左值引用只能引用左值，不能引用右值。    int a = 10;    int&amp; ra1 = a;   // ra1为a的别名    //int&amp; ra2 = 10;   // 编译失败，因为10是右值     // const左值引用既可引用左值，也可引用右值。    const int&amp; ra3 = 10;    const int&amp; ra4 = a;      //右值引用只能右值，不能引用左值。    int&amp;&amp; r1 = 10;      int a = 10;    //message : 无法将左值绑定到右值引用    int&amp;&amp; r2 = a;       //右值引用可以引用move以后的左值    int&amp;&amp; r3 = std::move(a);     return 0;&#125;</code></pre><p>左值引用的意义在于:</p><p>1.函数传参：实参传给形参时，可以减少拷贝。</p><p>2.函数传返回值时，只要是出了作用域还存在的对象，那么就可以减少拷贝。</p><p><font color="#A100">右值引用和左值引用减少拷贝的原理不一样：<br>左值引用是取别名，直接起作用；<br>右值引用是间接起作用，实现移动构造和移动赋值,在拷贝的场景中，如果是右值(将亡值)，转移资源</p></font><p><strong>右值是不能取地址的，但是给右值取别名后，会导致右值被存储到特定位置，且可以取到该位置的地址。（右值被右值引用以后就成为了左值）</strong></p><p><a href="https://blog.csdn.net/ChaoFreeandeasy_/article/details/130229252?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522171386931016800185849419%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=171386931016800185849419&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-130229252-null-null.142%5Ev100%5Epc_search_result_base9&utm_term=%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8&spm=1018.2226.3001.4187">【C++】右值引用（极详细版）</a></p><h2 id="47-左值引用和指针的区别？"><a href="#47-左值引用和指针的区别？" class="headerlink" title="47.左值引用和指针的区别？"></a>47.左值引用和指针的区别？</h2><p><strong>是否初始化</strong>：指针可以不用初始化，引用必须初始化</p><p><strong>性质不同</strong>：指针是一个变量，引用是对被引用的对象取一个别名</p><p><strong>占用内存单元不同</strong>：指针有自己的空间地址，引用和被引用对象占同一个空间。</p><h2 id="48-指针是什么？"><a href="#48-指针是什么？" class="headerlink" title="48.指针是什么？"></a>48.指针是什么？</h2><p>指针全名为指针变量，计算机在存储数据是有序存放的，为了能够使用存放的地址，就需要一个地址来区别每个数据的位置，指针变量就是用来存放这些地址的变量。</p><h2 id="49-weak-ptr真的不计数？是否有计数方式，在哪分配的空间？"><a href="#49-weak-ptr真的不计数？是否有计数方式，在哪分配的空间？" class="headerlink" title="49.weak_ptr真的不计数？是否有计数方式，在哪分配的空间？"></a>49.weak_ptr真的不计数？是否有计数方式，在哪分配的空间？</h2><p>计数，控制块中有强弱引用计数</p><p>如果是使用 <code>make_shared</code> 初始化的函数则它所在的控制块空间是在所引用的 <code>shared_ptr</code> 中同一块的空间；</p><p>若是 <code>new</code> 则控制器所分配的内存与 <code>shared_ptr</code> 本身所在的空间不在同一块内存。</p><h2 id="50-malloc-的内存分配的方式，有什么缺点？"><a href="#50-malloc-的内存分配的方式，有什么缺点？" class="headerlink" title="50.malloc 的内存分配的方式，有什么缺点？"></a>50.malloc 的内存分配的方式，有什么缺点？</h2><p>malloc 并不是系统调用，而是C库中的函数，用于动态内存分配，在使用 malloc 分配内存的时候会有两种方式向操作系统申请堆内存:</p><p><strong>方式1</strong>：当用户分配的内存小于128KB时通过 <code>brk()</code> 系统调用从堆分配内存；</p><p><strong>实现方式</strong>：将堆顶指针向高地址移动，获取内存空间，如果使用 <code>free</code> 释放空间，并不会将内存归还给操作系统，而是会缓存在 <code>malloc</code> 的内存池中，待下次使用。</p><p><strong>方式2</strong>：当用户分配的内存大于128KB时通过 <code>mmap()</code> 系统调用在文件映射区域分配内存；</p><p><strong>实现方式</strong>为：使用私有匿名映射的方式，在文件映射区分配一块内存，也就是从文件映射区拿了一块内存，<code>free</code> 释放内存的时候，会把内存归还给操作系统，内存得到真正释放。</p><hr><p><strong>缺点</strong>：容易造成内存泄漏和过多的内存碎片，影响系统正常运行，还得注意判断内存是否分配成功，而且内存释放后（使用free函数之后指针变量p本身保存的地址并没有改变），需要将 p 的赋值为 <code>NULL</code> 拴住野指针。</p><h2 id="51-为什么不全部使用mmap来分配内存？"><a href="#51-为什么不全部使用mmap来分配内存？" class="headerlink" title="51.为什么不全部使用mmap来分配内存？"></a>51.为什么不全部使用mmap来分配内存？</h2><p>因为向操作系统申请内存的时候，是要通过系统调用的，执行系统调用要进入内核态，然后再回到用户态，状态的切换会耗费不少时间，所以申请内存的操作应该避免频繁的系统调用，如果都使用mmap来分配内存，等于每次都要执行系统调用。另外，因为mmap分配的内存每次释放的时候都会归还给操作系统，于是每次mmap分配的虚拟地址都是缺页状态，然后在第一次访问该虚拟地址的时候就会触发缺页中断。</p><blockquote><p><strong>缺页中断</strong>：在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。</p></blockquote><blockquote><p><strong>缺页异常被触发通常有两种情况</strong>：<br>1.程序设计的不当导致访问了非法的地址；<br>2.访问的地址是合法的，但是该地址还未分配物理页框（malloc()等内存分配函数，在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存）。</p></blockquote><blockquote><p>缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：<br>1、保护CPU现场<br>2、分析中断原因<br>3、转入缺页中断处理程序进行处理<br>4、恢复CPU现场，继续执行</p></blockquote><blockquote><p>但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：<br>1、在指令执行期间产生和处理缺页中断信号<br>2、一条指令在执行期间，可能产生多次缺页中断<br>3、缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。</p></blockquote><p><a href="https://blog.csdn.net/weixin_52669146/article/details/130589203">简述缺页中断</a></p><h2 id="52-为什么不全部都用brk？"><a href="#52-为什么不全部都用brk？" class="headerlink" title="52.为什么不全部都用brk？"></a>52.为什么不全部都用brk？</h2><p>如果全部使用brk申请内存那么随着程序频繁的调用malloc和free，尤其是小块内存，堆内将产生越来越多的不可用的内存碎片。</p><blockquote><p>通过调用brk系统调用，程序可以请求操作系统增加或减少它的堆空间，以动态地管理内存。</p></blockquote><blockquote><p>brk() 函数是用来修改分配给调用者进程的内存量的。这种修改是通过改变进程的中断值到addr并提供必要的空间数量来实现的。</p><p>brk()函数用于修改分配给调用方进程的内存量。随着中断值的上升，分配的空间数量也在上升。新分配的空间有一个0的值分配给它。如果程序先减去然后再增加断点值，重新分配的空间的值就不会被清空。</p></blockquote><h2 id="53-传入一个指针，它如何确定具体要清理多少空间呢？"><a href="#53-传入一个指针，它如何确定具体要清理多少空间呢？" class="headerlink" title="53.传入一个指针，它如何确定具体要清理多少空间呢？"></a>53.传入一个指针，它如何确定具体要清理多少空间呢？</h2><p>在申请内存的时候，会多分配<strong>16字节</strong>的内存，里面保存了内存块的详细信息，<code>free</code> 会对传入的内存地址向<strong>左偏移16字节</strong>，然后分析出当前内存块的大小，就知道要释放多大的内存空间了。</p><h2 id="54-define和const的区别是什么？"><a href="#54-define和const的区别是什么？" class="headerlink" title="54.define和const的区别是什么？"></a>54.define和const的区别是什么？</h2><p><strong>编译阶段</strong>：define是在编译预处理阶段进行简单的文本替换，const是在编译阶段确定其值。</p><p><strong>安全性</strong>：define定义的宏常量没有数据类型，只是进行简单的替换，不会进行类型安全检查；const定义的常量是有类型的，是要进行类型判断的。</p><p><strong>内存占用</strong>：define定义的宏常量，在程序中使用多少次就会进行多少次替换，内存中有多个备份，占用的是代码段的内存；const定义常量占用静态存储区域的空间，程序运行过程中只有一份。</p><p><strong>调试</strong>：define定义的宏常量不能调试，因为在预编译阶段就已经进行替换了；const定义的常量是可以进行调试的。</p><h2 id="55-程序运行的步骤是什么"><a href="#55-程序运行的步骤是什么" class="headerlink" title="55.程序运行的步骤是什么"></a>55.程序运行的步骤是什么</h2><p><strong>预编译</strong>：将头文件编译，进行宏替换，输出.i文件</p><p><strong>编译</strong>：将其转化为汇编语言文件，主要做词法分析，语义分析以及检查错误，检查无误后将代码翻译成汇编语言，生成.s文件</p><p><strong>汇编</strong>：汇编器将汇编语言文件翻译成机器语言，生成.o文件</p><p><strong>链接</strong>：将目标文件和库链接到一起，生成可执行文件.exe</p><h2 id="56-（☆）锁的底层原理是什么？"><a href="#56-（☆）锁的底层原理是什么？" class="headerlink" title="56.（☆）锁的底层原理是什么？"></a>56.（☆）锁的底层原理是什么？</h2><p>锁的底层是通过CAS，atomic 机制实现。</p><p><strong>CAS机制</strong>：全称为Compare And Swap（比较相同再交换）可以将比较和交换操作转换为原子操作，CAS操作依赖于三个值：内存中的值V，旧的预估值X，要修改的新值B，如果旧的预估值X等于内存中的值V，就将新的值B保存在内存之中。（就是每一个线程从主内存复制一个变量副本后，进行操作，然后对其进行修改，修改完后，再刷新回主内存前。再取一次主内存的值，看拿到的主内存的新值与当初保存的快照值，是否一样，如果不一样，说明有其他线程修改，本次修改放弃，重试。）</p><p><strong>atomic机制</strong>：原子操作是指不会被线程调度机制打断的操作，这种操作一旦开始，就一直运行到结束，中间不会有任何切换到另一个线程。</p><h2 id="57-内存对齐是什么？为什么要进行内存对齐？内存对齐有什么好处？"><a href="#57-内存对齐是什么？为什么要进行内存对齐？内存对齐有什么好处？" class="headerlink" title="57.内存对齐是什么？为什么要进行内存对齐？内存对齐有什么好处？"></a>57.内存对齐是什么？为什么要进行内存对齐？内存对齐有什么好处？</h2><p>内存对齐是处理器为了提高处理性能而对存取数据的起始地址所提出的一种要求。</p><p>有些CPU可以访问任意地址上的任意数据，而有些CPU只能在特定的地址访问数据，因此不同硬件平台具有差异性，这样的代码就不具有移植性，如果在编译时将进行对齐，这就具有平台的移植性。</p><p>CPU每次寻址有时需要消耗时间的，并且CPU访问内存的时候并不是逐个字节访问，而是以字长为单位访问，所以数据结构应该尽可能地在自然边界上对齐，如果访问未对齐内存，处理器需要做多次内存访问，而对齐的内存访问可以减少访问次数，提升性能。</p><p>优：提高程序的运行效率，增强程序的可移植性。</p><h2 id="58-（☆）进程之间的通信方式有哪些？"><a href="#58-（☆）进程之间的通信方式有哪些？" class="headerlink" title="58.（☆）进程之间的通信方式有哪些？"></a>58.（☆）进程之间的通信方式有哪些？</h2><p><strong>管道</strong>：管道分为匿名管道和命名管道，管道本质上是一个内核中的一个缓存，当进程创建管道后会返回两个文件描述符，一个写入端一个输出端。缺点：半双工通信，一个管道只能一个进程写，一个进程读。不适合进程间频繁的交换数据</p><p><strong>消息队列</strong>：可以边发边收，但是每个消息体都有最大长度限制，队列所包含的消息体的总数量也有上限并且在通信过程中存在用户态和内核态之间的数据拷贝问题</p><p><strong>共享内存</strong>：解决了消息队列存在的内核态和用户态之间的数据拷贝问题。</p><p><strong>信号量</strong>：本质上是一个计数器，当使用共享内存的通信方式时，如果有多个进程同时往共享内存中写入数据，有可能先写的进程的内容被其他进程覆盖了，信号量就用于实现进程间的互斥和同步PV操作不限于信号量+-1，而且可以任意加减正整数</p><p>信号</p><p>套接字</p><h2 id="59-（☆）线程之间的通信方式有哪些？"><a href="#59-（☆）线程之间的通信方式有哪些？" class="headerlink" title="59.（☆）线程之间的通信方式有哪些？"></a>59.（☆）线程之间的通信方式有哪些？</h2><h2 id="60-（☆）介绍一下socket中的多路复用，及其他们的优缺点，epoll的水平和边缘触发模式"><a href="#60-（☆）介绍一下socket中的多路复用，及其他们的优缺点，epoll的水平和边缘触发模式" class="headerlink" title="60.（☆）介绍一下socket中的多路复用，及其他们的优缺点，epoll的水平和边缘触发模式"></a>60.（☆）介绍一下socket中的多路复用，及其他们的优缺点，epoll的水平和边缘触发模式</h2><p>select、poll、epoll都是IO多路复用的一种机制，可以监视多个文件描述符，一旦某个文件描述符进入读或写就绪状态，就能够通知系统进行相应的读写操作。</p><hr><p><strong>Select优点</strong>：可移植性好，因为在某些Unix系统中并不支持poll和epoll</p><p>对于超时时间提供了更好的精度：微妙，而poll和epoll都是毫秒级</p><p><strong>Select缺点</strong>：支持监听的文件描述符 fd 的数量有限制，最大数量默认是1024个</p><p>Select 需要维护一个用来存放文件描述符的数据结构，每次调用 select 都需要把 fd 集合从用户区拷贝到内核区，而 select 系统调用后有需要把 fd 集合从内核区拷贝到用户区，这个系统开销在 fd 数量很多的时候会很大。</p><hr><p><strong>Poll优点（相对于select而言）</strong>：没有最大文件描述符数量的限制，poll 基于链表存储主要解决了这个最大文件描述符数量的限制（当然，他还是有限制的，上限为操作系统能支持的能开启的最大文件描述符数量），优化了编程接口，减少了函数调用参数，并且，每次调用 select 函数时，都必须重置该函数的三个 fd_set 类型的参数值，而 poll 不需要重置。</p><p><strong>Poll缺点</strong>：poll 和 select 一样同样都需要维护一个用来存放文件描述符的数据结构，当注册的文件描述符无限多时，会使得用户态和内核区之间传递该数据结构的复制开销很大。每次 poll 系统调用时，需要把文件描述符 fd 从用户态拷贝到内核区，然后 poll 系统调用返回前，又需要把文件描述符 fd 集合从内核区拷贝到用户区，这个内存拷贝的系统开销在fd数量很多的时候会很大。</p><hr><p><strong>Epoll优点</strong>：和poll一样没有最大文件描述符数量的限制，epoll 虽然也需要维护用来存放文件描述符的数据结构（epoll_event），但是它只需要将该数据结构拷贝一次，不需要重复拷贝，并且它只在调用 epoll_ctl 系统调用时拷贝一次要监听的文件描述符数据结构到内核区，在调用 epoll_wait 的时候不需要再把所有的要监听的文件描述符重复拷贝进内核区，这就解决了 select 和 poll 种内存复制开销的问题。</p><p><strong>Epoll缺点</strong>：目前只有Linux操作系统支持epoll，不支持跨平台使用，而Unix操作系统上是使用kqueue。</p><p><strong>Epoll水平触发（LT）</strong>：对于读操作，只要缓冲区内容不为空，LT模式返回读就绪；</p><p>对于写操作，只要缓冲区还不满，LT模式会返回写就绪。</p><p><strong>Epoll边缘触发（ET）</strong>：对于读操作，当缓冲区由不可读变为可读的时候，有新数据到达时，进程修改了 EPOLL_CTL_MOD 修改 EPOLLIN 事件时</p><p>在ET模式下，缓冲区从不可读变成可读，会唤醒应用进程，缓冲区数据变少的情况，则不会再唤醒应用进程。</p><p>当被监控的文件描述符上有可读写事件发生时，epoll_wait() 会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait() 时，它不会通知你，也就是它<strong>只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你</strong>。通常配合将文件描述符设置为非阻塞状态一起使用，这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符。</p><h2 id="61-类的生命周期"><a href="#61-类的生命周期" class="headerlink" title="61.类的生命周期"></a>61.类的生命周期</h2><p>类从被加载到内存中开始，到卸载出内存为止，它的整个生命周期包括：<strong>加载、验证、准备、解析、初始化、使用和卸载七个阶段</strong>。其中验证，准备，解析三个部分统称为<strong>连接</strong></p><ul><li>全局对象在main开始前被创建，main退出后被销毁。</li><li>静态对象在第一次进行作用域时被创建，在main退出后被销毁。</li><li>局部对象在进入作用域时被创建，在退出作用域时被销毁。</li><li>New 创建的对象直到内存被释放的时候都存在。</li></ul><h2 id="62-父类的构造函数和析构函数是否能为虚函数？这样操作导致的结果？"><a href="#62-父类的构造函数和析构函数是否能为虚函数？这样操作导致的结果？" class="headerlink" title="62.父类的构造函数和析构函数是否能为虚函数？这样操作导致的结果？"></a>62.父类的构造函数和析构函数是否能为虚函数？这样操作导致的结果？</h2><p>构造函数不能为虚函数，虚函数的调用是通过虚函数表来查找的，而虚函数表由类的实例化对象的vptr指针指向，该指针存放在对象的内部空间之中，需要调用构造函数完成初始化，如果构造函数为虚函数，那么调用构造函数就需要去寻找vptr，但此时vptr还没有完成初始化，导致无法构造对象。</p><p>析构函数可以是虚函数：vptr已经完成初始化，析构函数可以声明为虚函数，且类有继承时，析构函数常常必须为虚函数。</p><p>要注意，使用父类指针指向子类时，只会调用父类的析构函数，子类的析构函数不会被调用，容易造成内存泄漏。</p><h2 id="63-多线程为什么会发生死锁，死锁是什么？死锁产生的条件，如何解决死锁？"><a href="#63-多线程为什么会发生死锁，死锁是什么？死锁产生的条件，如何解决死锁？" class="headerlink" title="63.多线程为什么会发生死锁，死锁是什么？死锁产生的条件，如何解决死锁？"></a>63.多线程为什么会发生死锁，死锁是什么？死锁产生的条件，如何解决死锁？</h2><p>因为在多进程中易发生多进程对资源进行竞争，如果一个进程集合里面的每一个进程都在等待这个集合中的其他一个进程才能继续往下执行，若无外力他们将无法推进，这种情况就是死锁。产生死锁的四个条件：互斥条件、请求和保持条件、不可剥夺条件、环路等待条件。解决死锁的方法就是破坏上述任意一种条件。</p><h2 id="64-描述一下面向过程和面向对象"><a href="#64-描述一下面向过程和面向对象" class="headerlink" title="64.描述一下面向过程和面向对象"></a>64.描述一下面向过程和面向对象</h2><p><strong>面向对象</strong>：就是将问题分解为各个对象，建立对象的目的不是为了完成一个步骤，而是为了描述某个事物在整个解决问题的步骤中的行为，相比面向过程，代码更易维护和复用。但是代码效率相对较低。</p><p><strong>面向过程</strong>：就是将问题分析出解决问题的步骤，然后将这些步骤一步一步的实现，使用的时候一个一个调用就好。代码效率更高但是代码复用率低，不易维护。</p><h2 id="65-i是左值还是右值，-i和i-哪个效率更高？"><a href="#65-i是左值还是右值，-i和i-哪个效率更高？" class="headerlink" title="65.++i是左值还是右值，++i和i++哪个效率更高？"></a>65.++i是左值还是右值，++i和i++哪个效率更高？</h2><p>++i是左值，因为++i返回的是一个左值没有发生拷贝，所以效率更高。</p><h2 id="66-介绍一下vector、list的底层实现原理和优缺点"><a href="#66-介绍一下vector、list的底层实现原理和优缺点" class="headerlink" title="66.介绍一下vector、list的底层实现原理和优缺点"></a>66.介绍一下vector、list的底层实现原理和优缺点</h2><p><strong>Vector优点</strong>：可使用下标随机访问，尾插尾删效率高</p><p><strong>缺点</strong>：前面部分的插入删除效率低，扩容有消耗，可能存在一定的空间浪费。</p><p><strong>原理</strong>：底层是由一块连续的内存空间组成，由三个指针实现的分别是<strong>头指针（</strong>表示目前使用空间的头），<strong>尾指针</strong>（表示目前使用空间的尾）和<strong>可用空间尾指针</strong>实现</p><hr><p><strong>List优点</strong>：按需申请内存，不需要扩容，不会造成内存空间浪费。在任意位置的插入删除下效率高。</p><p><strong>缺点</strong>：不支持下标随机访问</p><p><strong>原理</strong>：底层是由双向链表实现的</p><h2 id="67-静态变量在哪里初始化？在哪一个阶段初始化？（都存放在全局区域）"><a href="#67-静态变量在哪里初始化？在哪一个阶段初始化？（都存放在全局区域）" class="headerlink" title="67.静态变量在哪里初始化？在哪一个阶段初始化？（都存放在全局区域）"></a>67.静态变量在哪里初始化？在哪一个阶段初始化？（都存放在全局区域）</h2><p>静态变量，全局变量，常量都在编译阶段完成初始化和内存分配。其他变量都是在编译阶段进行初始化，运行阶段内存分配.。</p><h2 id="68-如何实现多进程？"><a href="#68-如何实现多进程？" class="headerlink" title="68.如何实现多进程？"></a>68.如何实现多进程？</h2><p>在Linux中C++使用fork函数来创建进程</p><p>而windows中C++使用createprocess来创建进程</p><h2 id="69-空对象指针为什么能调用函数？"><a href="#69-空对象指针为什么能调用函数？" class="headerlink" title="69.空对象指针为什么能调用函数？"></a>69.空对象指针为什么能调用函数？</h2><p>在类的初始化的时候，编译器会将它的函数分配到类的外部，这也包括静态成员函数，这样做主要是为了节省内存，如果我们在调用类中的的成员函数时没有使用类中的任何成员变量，它不会使用到this指针所以可以正常调用这个函数。</p><h2 id="70-shared-ptr线程安全吗？"><a href="#70-shared-ptr线程安全吗？" class="headerlink" title="70.shared_ptr线程安全吗？"></a>70.shared_ptr线程安全吗？</h2><p>智能指针中的引用计数是线程安全的，但是智能指针所指向的对象的线程安全问题，智能指针没有做任何保障线程不安全。也就是说它所管理的资源可以线程安全的释放，<strong>只保证线程安全的管理资源的生命期</strong>，不保证其资源可以线程安全地被访问。</p><h2 id="71-push-back-左值和右值的区别是什么？"><a href="#71-push-back-左值和右值的区别是什么？" class="headerlink" title="71.push_back()左值和右值的区别是什么？"></a>71.push_back()左值和右值的区别是什么？</h2><p>如果 push_back（）的参数是左值，则使用它拷贝构造新对象，如果是右值，则使用它移动构造新对象。</p><h2 id="72-move底层是怎么实现的？"><a href="#72-move底层是怎么实现的？" class="headerlink" title="72.move底层是怎么实现的？"></a>72.move底层是怎么实现的？</h2><p>move的功能是将一个左值引用强制转化为右值引用，继而可以通过右值引用使用该值，以用于移动语义，从实现原理上讲基本等同一个强制类型转换。</p><p>优点：可以将左值变成右值而避免拷贝构造，将对象的状态所有权从一个对象转移到另一个对象，只是转移，没有内存搬迁或者内存拷贝。</p><blockquote><p>std::move是C++11新增加的一个函数模板，其主要功能是将一个左值强制转换为一个右值引用。</p></blockquote><blockquote><p>其原型定义如下：</p></blockquote><blockquote><p>template<typename T><br>typename remove_reference<T>::type&amp;&amp; move(T&amp;&amp; arg) noexcept;</p></blockquote><blockquote><p>其中remove_reference是一个类型转换模板，其主要功能是去除模板类型T的引用类型，返回一个非引用类型。</p></blockquote><blockquote><p>函数move接收一个泛型参数，该参数被声明为一个右值引用，也就是T&amp;&amp;。当函数move接收到一个左值参数时，其会将该参数强制转换为一个右值引用，并返回一个右值引用类型的转换结果。</p></blockquote><blockquote><p>在C++11中，移动语义的引入解决了传递复制构造函数和复制赋值运算符中的性能问题。当使用std::move函数将一个左值转换为右值引用时，可以避免不必要的对象复制和内存分配，从而提高程序的性能和效率。</p></blockquote><h2 id="73-完美转发的原理是什么？"><a href="#73-完美转发的原理是什么？" class="headerlink" title="73.完美转发的原理是什么？"></a>73.完美转发的原理是什么？</h2><p>完美转发是指函数模板可以将自己的参数完美的转发给内部调用的其他函数，完美是指不仅能够准确的转发参数的值，还能保证被转发参数的左、右值属性不变，使用引用折叠的规则，将传递进来的左值以左值传递出来，将传递进来的右值以右值的方式传出。</p><h2 id="74-空类中有什么函数？"><a href="#74-空类中有什么函数？" class="headerlink" title="74.空类中有什么函数？"></a>74.空类中有什么函数？</h2><p>默认构造函数、默认拷贝构造函数、默认析构函数、默认赋值运算符</p><p>取值运算符、const取值运算符</p><h2 id="75-explicit用在哪里？有什么作用？"><a href="#75-explicit用在哪里？有什么作用？" class="headerlink" title="75.explicit用在哪里？有什么作用？"></a>75.explicit用在哪里？有什么作用？</h2><p>只能用于修饰只有一个参数的类构造函数（有一个例外就是，当除了第一个参数以外的其他参数都有默认值的时候此关键字依然有效），它的作用是表明该构造函数是显示的，而非隐式的，跟它对应的另一个关键字是implicit，意思是隐藏的，类构造函数默认情况下声明为implicit。作用是防止类构造函数的隐式自动转换。</p><h2 id="76-成员变量初始化的顺序是什么？"><a href="#76-成员变量初始化的顺序是什么？" class="headerlink" title="76.成员变量初始化的顺序是什么？"></a>76.成员变量初始化的顺序是什么？</h2><p>成员变量在使用初始化列表初始化时，与构造函数中初始化成员列表的顺序无关，只与定义成员变量的顺序有关。如果不使用初始化列表初始化，在构造函数内初始化时，此时与成员变量在构造函数中的位置有关。<strong>类中const成员常量必须在构造函数初始化列表中初始化。类中static成员变量，只能在类外初始化。</strong></p><p>顺序：基类的静态变量或全局变量，派生类的静态变量或者全局变量，基类的成员变量，派生类的成员变量。</p><h2 id="77-指针占用的大小是多少？"><a href="#77-指针占用的大小是多少？" class="headerlink" title="77.指针占用的大小是多少？"></a>77.指针占用的大小是多少？</h2><p>64位电脑上占8字节，32位的占4字节，我们平时所说的计算机多少位是指计算机CPU中通用寄存器一次性处理、传输、暂时保存的信息的最大长度。即CPU在单位时间内能一次处理的二进制的位数，因此CPU所能访问的内存所有地址由多少位组成，而8比特位表示1字节，就可以得出在不同位数的机器中指针的大小。</p><h2 id="78-野指针和内存泄漏是什么？如何避免？"><a href="#78-野指针和内存泄漏是什么？如何避免？" class="headerlink" title="78.野指针和内存泄漏是什么？如何避免？"></a>78.野指针和内存泄漏是什么？如何避免？</h2><p>内存泄漏：是指程序中以动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果</p><p>避免：使用智能指针管理资源，在释放对象数组时使用delete[]，尽量避免在堆上分配内存</p><p>野指针：指向一个已删除的对象或未申请访问受限内存区域的指针。</p><p>避免：对指针进行初始化，用已合法的可访问内存地址对指针初始化，指针用完释放内存，将指针赋值nullptr。</p><h2 id="79-malloc-和-new-的区别是什么？"><a href="#79-malloc-和-new-的区别是什么？" class="headerlink" title="79.malloc 和 new 的区别是什么？"></a>79.malloc 和 new 的区别是什么？</h2><p>malloc&#x2F;free是标准库函数，new&#x2F;delete是C++运算符</p><p>malloc分配内存失败返回空，new失败抛异常</p><p>new&#x2F;delete会调用构造析构函数，malloc&#x2F;free不会，所以他们无法满足动态对象的要求。</p><p>New返回有类型的指针，malloc返回无类型的指针</p><p>分配内存的位置：malloc从堆上动态分配内存，new是从自由存储区为对象动态分配内存（取决于operator new的实现，可以为堆还可以是静态存储区）</p><p>new申请内存的步骤：调用operator new函数，分配一块足够大，且原始的，未命名的内存空间来存储特定类型的对象。运行相应的构造函数来构造对象，并为其传入初值，返回一个指向该对象的指针。</p><p>delete：先调用对象的析构函数，再调用operator delete函数释放内存空间</p><h2 id="80-☆-多线程会发生什么问题？线程同步有哪些手段？"><a href="#80-☆-多线程会发生什么问题？线程同步有哪些手段？" class="headerlink" title="80.(☆)多线程会发生什么问题？线程同步有哪些手段？"></a>80.(☆)多线程会发生什么问题？线程同步有哪些手段？</h2><p>会引发资源竞争的问题，频繁上锁会导致程序运行效率低下，甚至会导致发生死锁。</p><p><strong>线程同步手段</strong>：使用atomic原子变量，使用互斥量也就是上锁，使用条件变量或信号量制约对共享资源的并发访问。</p><h2 id="81-什么是STL？"><a href="#81-什么是STL？" class="headerlink" title="81.什么是STL？"></a>81.什么是STL？</h2><p>它是C++标准库的重要组成部分，不仅是一个可复用的组件库也是一个包含了数据结构与算法的软件架构。</p><p>STL可分为容器(containers)、迭代器(iterators)、空间配置器(allocator)、配接器(adapters)、算法(algorithms)、仿函数(functors)六个部分。</p><blockquote><p><a href="https://blog.csdn.net/weixin_53332395/article/details/123948946">STL基础知识 简介</a></p></blockquote><h2 id="82-对比迭代器和指针的区别"><a href="#82-对比迭代器和指针的区别" class="headerlink" title="82.对比迭代器和指针的区别"></a>82.对比迭代器和指针的区别</h2><p>迭代器不是指针，是一个模板类，通过重载了指针的一些操作符模拟了指针的一些功能，迭代器返回的是对象引用而不是对象的值。</p><p>指针能够指向函数而迭代器不行,迭代器只能指向容器</p><h2 id="83-空间配置器"><a href="#83-空间配置器" class="headerlink" title="83.空间配置器?"></a>83.空间配置器?</h2><p>空间配置器是操作系统开辟的一大段内存空间。STL需要扩容申请内存时，就从空间配置器中申请，不需要再经过操作系统。并且，它还能回收释放的空间，供下一次使用。一个进程中有一个空间配置器，进程中所有容器需要的空间都到对应空间配置器申请。进程终止，对应空间配置器空间释放。</p><p>空间配置器有两级结构，一级空间配置器是用来处理大块内存，二级空间配置器处理小块内存。SGI-STL规定以<strong>128字节作为小块内存和大块内存的分界线</strong>。</p><p><strong>为什么这样区分成两级？</strong></p><p>因为STL容器，一般申请的都会是小块的内存，二级空间配置器，主要是管理容器申请空间和释放的空间。<br>如果用户申请的空间直接大于的128字节直接找的是一级空间配置器申请空间。</p><hr><p><strong>一级空间配置器</strong>：<br>一级空间配置器原理很简单，直接是对malloc和free进行了封装，并且增加了C++中的申请空间失败抛异常机制。<br>主要的作用是：向操作系统申请内存，申请失败会抛异常。<br>为什么不直接用 C++ 的 new 和 delete，因为这里并不需要调用构造函数和析构函数。</p><hr><p><strong>二级空间配置器</strong>：<br>二级空间配置器专门负责处理小于128字节的小块内存。</p><p>SGI-STL采用了内存池的技术来提高申请空间的速度以及减少额外空间的浪费，采用哈希桶的方式来提高用户获取空间的速度和高效管理。</p><p><a href="https://blog.csdn.net/weixin_51164515/article/details/125743478">https://blog.csdn.net/weixin_51164515&#x2F;article&#x2F;details&#x2F;125743478</a></p><h2 id="84-NULL和nullptr的区别与联系？"><a href="#84-NULL和nullptr的区别与联系？" class="headerlink" title="84.NULL和nullptr的区别与联系？"></a>84.NULL和nullptr的区别与联系？</h2><p><code>NULL</code> 是一个预处理器变量，在头文件 <code>cstdlib</code> 中定义为 0 值。预处理器是运行在编译过程之前的一段程序，预处理变量不属于命名空间 std，它是由预处理器负责管理。当用到一个预处理变量时，在编译时，预处理器会自动把它替换为实际值，因此使用 NULL 初始化指针和使用 0 初始化指针是一样的。</p><p><code>nullptr</code> 是一个字面值常量，它可以被转化为任何其他类型的指针。</p><p>另外，把int 型变量直接赋值给指针是错误的操作，即使 int 型变量等于 0 也不行！</p><p>为了解决二义性，C++11标准引入了关键字nullptr，它作为一种空指针常量。</p><h2 id="85-为什么C-中-void-0-是空指针常量，而C-中不是？"><a href="#85-为什么C-中-void-0-是空指针常量，而C-中不是？" class="headerlink" title="85.为什么C 中 (void*)0 是空指针常量，而C++中不是？"></a>85.为什么C 中 (void*)0 是空指针常量，而C++中不是？</h2><p>因为 C 语言中任何类型的指针都可以（隐式地）转换为 void* 型，反过来也行。<br>而 C++ 中void* 型不能隐式地转换为别的类型指针（例如：int  *p &#x3D; (void *) 0;  使用C++编译器编译会报错）。</p><h2 id="86-☆-线程有哪些状态，线程锁有哪些？"><a href="#86-☆-线程有哪些状态，线程锁有哪些？" class="headerlink" title="86.(☆)线程有哪些状态，线程锁有哪些？"></a>86.(☆)线程有哪些状态，线程锁有哪些？</h2><p>五种状态：创建，就绪，运行，阻塞，死亡</p><p>线程锁的种类：互斥锁，条件锁，自旋锁，读写锁，递归锁</p><h2 id="87-解释说明一下-map-和-unordered-map？"><a href="#87-解释说明一下-map-和-unordered-map？" class="headerlink" title="87.解释说明一下 map 和 unordered_map？"></a>87.解释说明一下 map 和 unordered_map？</h2><p>map 内部实现是一个红黑树，内部所有的元素都是有序的，而 hashmap 则是内部实现了一个哈希表，内部存储元素是无序的</p><p><strong>map优点</strong>：有序性，其次是内部实现的是一个红黑树，使得很多操作都可以在logn的复杂度下可以实现效率较高。</p><p><strong>map缺点</strong>：空间占用率高</p><p><strong>unorderedmap优点</strong>：查找效率非常高；</p><p><strong>unorderedmap缺点</strong>：哈希表的建立比较费时间。</p><h2 id="88-vector中的push-back-和emplace-back-的区别、以及使用场景"><a href="#88-vector中的push-back-和emplace-back-的区别、以及使用场景" class="headerlink" title="88.vector中的push_back()和emplace_back()的区别、以及使用场景"></a>88.vector中的push_back()和emplace_back()的区别、以及使用场景</h2><p>当使用 <code>push_back</code> 时会先调用类的有参构造函数创建一个临时变量，再将这个元素拷贝或者移动到容器之中，而 <code>emplace_back</code> 则是直接在容器尾部进行构造比 push_back 少进行一次构造函数调用。在大部分场景中 <code>emplace_back</code> 可以替换 <code>push_back</code>，但是 <code>push_back</code> 会比 <code>emplace_back</code> 更加安全，<code>emplace_back</code> 只能用于直接在容器中构造新元素的情况，如果要将现有的对象添加到容器中则需要使用 <code>push_back</code>。</p><h2 id="89-☆-如何实现线程安全，除了加锁还有没有其他的方式？"><a href="#89-☆-如何实现线程安全，除了加锁还有没有其他的方式？" class="headerlink" title="89.(☆)如何实现线程安全，除了加锁还有没有其他的方式？"></a>89.(☆)如何实现线程安全，除了加锁还有没有其他的方式？</h2><p>除了锁之外还可以使用互斥量（防止多个线程来同时访问共享资源，从而避免数据竞争的问题），原子操作（原子操作是不可分割的，使用原子操作可以确保在多线程环境中操作是安全的），条件变量（协调线程之间的协作，用来在线程之间传递信号，从而控制线程的执行流程）等方式。</p><h2 id="90-vector扩容，resize和reserve的区别？"><a href="#90-vector扩容，resize和reserve的区别？" class="headerlink" title="90.vector扩容，resize和reserve的区别？"></a>90.vector扩容，resize和reserve的区别？</h2><p>使用resize改变的是vector的大小（size），可能会添加或删除元素。</p><p>使用reserve改变的是vector的容量（capacity），不会改变当前元素的数量，仅仅是为了优化内存使用和性能。</p><h2 id="91-vector-扩容为了避免重复扩容做了哪些机制？"><a href="#91-vector-扩容为了避免重复扩容做了哪些机制？" class="headerlink" title="91.vector 扩容为了避免重复扩容做了哪些机制？"></a>91.vector 扩容为了避免重复扩容做了哪些机制？</h2><p>当vector内存不够时本身内存会以1.5或者2倍的增长，以减少扩容次数</p><p>引入了reserve，自定义vector最大容量</p><h2 id="92-C-中空类的大小是多少？"><a href="#92-C-中空类的大小是多少？" class="headerlink" title="92.C++中空类的大小是多少？"></a>92.C++中空类的大小是多少？</h2><p>1字节</p><p>空类同样可以被实例化，并且每个实例在内存中都有独一无二的地址，因此，编译器会给空类隐含加上一个字节，这样空类实例化之后就会拥有独一无二的内存地址。如果没有这一个字节的占位，那么空类就无所谓实例化了，因为实例化的过程就是在内存中分配一块地址。</p><p>注意：<strong>当该空白类作为基类时，该类的大小就优化为0了，这就是所谓的空白基类最优化。</strong></p><p>注意：<strong>空白基类最优化无法被施加于多重继承上只适合单一继承</strong>。</p><h2 id="93-weak-ptr-是怎么实现的？"><a href="#93-weak-ptr-是怎么实现的？" class="headerlink" title="93.weak_ptr 是怎么实现的？"></a>93.weak_ptr 是怎么实现的？</h2><p>实现依赖于计数器和寄存器实现的，计数器用来记录弱引用的数量，寄存器用来存储shared_ptr</p><p>shared_ptr：a 和 b的对象内部，具有各自指向对方的shared_ptr，并且 a 和 b 的引用计数都是2.当程序退出时，引用计数减为1，对象并不会被析构掉。</p><p>weak_ptr是为了配合shared_ptr而引入的一种智能指针，它指向一个由shared_ptr管理的对象而不影响所指对象的生命周期，即就是将一个weak_ptr绑定到shared_ptr不会改变shared_ptr的引用计数。不论是否有用weak_ptr指向一旦最后一个指向对象的shared_ptr被销毁，对象就会是释放。从这个角度看，weak_ptr更像是一个shared_ptr的助手，weak_ptr并不拥有对对象的管辖权，weak_ptr指向shared_ptr的目标也不会增加计数器值。</p><p><a href="https://blog.csdn.net/m0_57719144/article/details/131153455">weak_ptr</a></p><h2 id="94-虚函数的底层原理是什么？"><a href="#94-虚函数的底层原理是什么？" class="headerlink" title="94.虚函数的底层原理是什么？"></a>94.虚函数的底层原理是什么？</h2><p>C++中的虚函数是一种特殊类型的成员函数，用于实现运行时多态性。虚函数允许在基类中使用基类指针或引用来调用派生类的函数实现，从而根据对象的实际类型来执行相应的函数代码。</p><hr><p>虚函数的作用和优势包括：</p><ol><li><strong>多态性</strong>：通过虚函数，可以在运行时根据对象的实际类型来选择调用相应的函数实现。这样可以实现多态性，使得程序更加灵活和易于扩展。</li><li><strong>继承和接口</strong>：虚函数为派生类提供了一种方式来继承基类的接口。基类中声明的虚函数在派生类中可以被覆盖（重写）以提供特定的实现。</li><li><strong>避免判断对象类型</strong>：通过使用虚函数，不需要手动判断对象的实际类型，而是让编译器自动处理，使代码更加简洁和可读。</li><li><strong>动态绑定</strong>：虚函数通过动态绑定（Dynamic Binding）实现多态性。在运行时，基类指针或引用会根据对象的实际类型调用相应的虚函数，而不是根据指针或引用的类型。</li></ol><hr><p><strong>底层原理：</strong></p><p>在底层，虚函数的实现依赖于虚函数表（VTable）和虚指针（VPtr）。</p><p><strong>虚函数表（VTable）</strong>：对于包含虚函数的类，编译器会为该类创建一个虚函数表。虚函数表是一个包含了虚函数指针的数组，每个虚函数对应一个表项。每个类只有一个虚函数表，不管有多少个对象实例。<em>虚函数表在编译阶段就确定，并在程序运行时使用</em>。</p><p><strong>虚指针（VPtr）</strong>：对于包含虚函数的类，每个对象都会有一个虚指针，用于指向该对象所属类的虚函数表。这个虚指针通常是隐藏的，存储在对象的内存布局的开始位置。通过虚指针，程序可以在运行时找到正确的虚函数表，从而实现动态绑定。</p><p>当调用一个虚函数时，程序会根据对象的虚指针找到对应的虚函数表，然后根据函数在虚函数表中的索引找到正确的函数实现并调用。这就是C++中虚函数实现多态性的底层原理。</p><p>需要注意的是，虚函数的使用会引入虚函数表和虚指针，略微增加了对象的内存开销和函数调用的性能损耗，但对于大多数情况而言，这种开销是可以接受的，并且带来了更强大的代码组织和设计能力。</p><h2 id="95-一个函数f-int-a-int-b-，其中a和b的地址关系是什么？"><a href="#95-一个函数f-int-a-int-b-，其中a和b的地址关系是什么？" class="headerlink" title="95.一个函数f(int a,int b)，其中a和b的地址关系是什么？"></a>95.一个函数f(int a,int b)，其中a和b的地址关系是什么？</h2><p>a和b的地址是相邻的。</p><h2 id="96-移动构造和拷贝构造的区别是什么？"><a href="#96-移动构造和拷贝构造的区别是什么？" class="headerlink" title="96.移动构造和拷贝构造的区别是什么？"></a>96.移动构造和拷贝构造的区别是什么？</h2><p><strong>移动构造函数本质上是基于指针的拷贝，实现对堆区内存所有权的移交</strong>，在一些特定场景下，可以减少不必要的拷贝。</p><p>比如用一个临时对象或者右值对象初始化类实例时。我们可以使用move()函数，将一个左值对象转变为右值对象。而<strong>拷贝构造则是将传入的对象复制一份然后放进新的内存中</strong>。</p><h2 id="97-☆-lamda表达式捕获列表捕获的方式有哪些？如果是引用捕获要注意什么？"><a href="#97-☆-lamda表达式捕获列表捕获的方式有哪些？如果是引用捕获要注意什么？" class="headerlink" title="97.(☆)lamda表达式捕获列表捕获的方式有哪些？如果是引用捕获要注意什么？"></a>97.(☆)lamda表达式捕获列表捕获的方式有哪些？如果是引用捕获要注意什么？</h2><p>所谓捕获列表，其实可以理解为参数的一种类型，<strong>lambda 表达式内部函数体在默认情况下是不能够使用函数体外部的变量的，这时候捕获列表可以起到传递外部数据的作用</strong>。 根据传递的行为，捕获列表也分为以下几种：</p><ol><li><p><strong>值捕获</strong>：<br>与参数传值类似，值捕获的前提是变量可以拷贝，不同之处则在于，被捕获的变量在 lambda 表达式被创建时拷贝，而非调用时才拷贝</p></li><li><p><strong>引用捕获：</strong><br>与引用传参类似，引用捕获保存的是引用，值会发生变化。</p></li><li><p><strong>隐式捕获</strong>：<br>手动书写捕获列表有时候是非常复杂的，这种机械性的工作可以交给编译器来处理，这时候可以在捕获列表中写一个 &amp; 或 &#x3D; 向编译器声明采用 引用捕获或者值捕获。<br>总结一下，捕获提供了 Lambda 表达式对外部值进行使用的功能，捕获列表的最常用的四种形式可以是：</p><p> （1）[] 空捕获列表；<br> （2）[name1, name2, …] 捕获一系列变量；<br> （3）[&amp;] 引用捕获, 让编译器自行推导捕获列表；<br> （4）[&#x3D;] 值捕获, 让编译器执行推导应用列表；</p></li><li><p><strong>容器for_each遍历中嵌入Lambda 表达式</strong>：<br>利用stl中迭代写法for_each进行动态数组内元素奇偶数的判断。</p></li></ol><p><a href="https://blog.csdn.net/Dasis/article/details/121372235">https://blog.csdn.net/Dasis/article/details/121372235</a></p><hr><p>按值捕获和引用捕获，默认的引用捕获可能会导致悬挂引用，引用捕获会导致闭包包含一个局部变量的引用或者形参的引用，如果一个由lambda创建的闭包的生命周期超过了局部变量或者形参的生命期，那么闭包的引用将会空悬。解决方法是对个别参数使用值捕获。</p><p><a href="https://blog.csdn.net/zzhongcy/article/details/88019153?spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-88019153-blog-121372235.235%5Ev43%5Epc_blog_bottom_relevance_base8&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-88019153-blog-121372235.235%5Ev43%5Epc_blog_bottom_relevance_base8&utm_relevant_index=6">C++11：lambda表达式的陷阱</a></p><h2 id="98-哈希碰撞的处理方法"><a href="#98-哈希碰撞的处理方法" class="headerlink" title="98.哈希碰撞的处理方法"></a>98.哈希碰撞的处理方法</h2><p><strong>链地址法</strong>：将所有的哈希地址相同的记录都链接在同一链表中</p><p><strong>开放定址法</strong>：当遇到哈希冲突时，去寻找一个新的空闲的哈希地址（线性探测，平方探测）。</p><p><strong>多次哈希</strong>：同时构造多个哈希函数，等发生哈希冲突时就使用其他哈希函数直到不发生冲突为止，虽然不易发生聚集，但是增加了计算时间。</p><p><strong>建立公共溢出区</strong>：将哈希表分为基本表和溢出表，将发生冲突的都存放在溢出表中。查找时，先从哈希表查，查不到再去公共溢出区查。</p><h2 id="99-unordered-map-的扩容过程"><a href="#99-unordered-map-的扩容过程" class="headerlink" title="99.unordered_map 的扩容过程"></a>99.unordered_map 的扩容过程</h2><p>当 <code>unordered_map</code> 中的元素数量 <strong>达到桶的负载因子（0.75）时，会重新分配桶的数量</strong> （通常会按照原有桶的数量 <code>*2</code> 的方式进行扩容，但是具体的增长策略也可以通过修改容器中的 <code>max_load_factor</code> 成员变量来进行调整），并 <strong>将所有的元素重新哈希到新的桶中</strong>。</p><blockquote><p>unordered_map是一个关联容器，存储key,value.其中元素并没有特别的次序关系.</p><p>特点：</p><ol><li>关联容器中的元素是通过主键（Key）而不是它们在容器中的绝对位置来引用的。</li><li>无序（Unordered）无序容器通过 hash 表来组织它们的元素，允许通过主键快速地访问元素。</li><li>映射（Map）每个元素为一个值（Mapped value）绑定一个键（Key）：以主键来标志主要内容等于被映射值的元素。</li><li>键唯一（Unique keys）容器中不存在两个元素有相同的主键。</li><li>能够感知内存分配器的（Allocator-aware）容器使用一个内存分配器对象来动态地处理它的存储需求。</li></ol><p>在 unordered_map 内部，元素不会按任何顺序排序，而是通过主键的 hash 值将元素分组放置到<br>各个槽（Bucket，也可译成“桶”）中，这样就能通过主键快速地访问各个对应的元素（平均耗时为一个常量，即时间复杂度为 O(1)）。</p></blockquote><h2 id="100-vector如何判断应该扩容？（size和capacity）"><a href="#100-vector如何判断应该扩容？（size和capacity）" class="headerlink" title="100.vector如何判断应该扩容？（size和capacity）"></a>100.vector如何判断应该扩容？（size和capacity）</h2><p>由当前容器内元素数量的大小和容器最大大小进行比较如果二者相等就会进行扩容，一般是1.5倍，部分的有两倍</p><h2 id="101-构造函数是否能声明为虚函数？为什么？"><a href="#101-构造函数是否能声明为虚函数？为什么？" class="headerlink" title="101.构造函数是否能声明为虚函数？为什么？"></a>101.构造函数是否能声明为虚函数？为什么？</h2><p>构造函数不能为虚函数，虚函数的调用是通过虚函数表来查找的，而虚函数表由类的实例化对象的 <code>vptr</code> 指针指向，该指针存放在对象的内部空间之中，需要调用构造函数完成初始化，如果构造函数为虚函数，那么调用构造函数就需要去寻找 <code>vptr</code> ，但此时 <code>vptr</code> 还没有完成初始化，导致无法构造对象。</p><h2 id="102-类中static函数是否能声明为虚函数？"><a href="#102-类中static函数是否能声明为虚函数？" class="headerlink" title="102.类中static函数是否能声明为虚函数？"></a>102.类中static函数是否能声明为虚函数？</h2><p>不能，因为类中的 <code>static</code> 函数是所有类实例化对象所共有的，没有 <code>this</code> 指针，而虚函数依靠 <code>vptr</code> 和 <code>vtable</code> 来处理，<code>vptr</code> 是一个指针，在类中的构造函数中生成，并且只能通过 <code>this</code> 指针访问，对于静态成员函数来说，他没有 <code>this</code> 指针，无法访问 <code>vptr</code>，因此 <code>static</code> 函数无法声明为虚函数.</p><h2 id="103-☆-哪些函数不能被声明为虚函数？"><a href="#103-☆-哪些函数不能被声明为虚函数？" class="headerlink" title="103.(☆)哪些函数不能被声明为虚函数？"></a>103.(☆)哪些函数不能被声明为虚函数？</h2><p>常见的不不能声明为虚函数的有：<strong>普通函数（非成员函数）；静态成员函数；内联成员函数；构造函数；友元函数。</strong></p><p><strong>普通函数(非成员函数)</strong>:多态依托于类实现，因此普通函数不可被声明为虚函数</p><p><strong>构造函数</strong>:虚表指针在构造函数中初始化，而虚函数保存在虚表中，调用虚函数时需要通过虚表指针找到虚函数;<br>若构造函数是虚函数，则调用构造函数需要先得到虚表指针，而虚表指针又需要在构造函数中初始化，矛盾</p><p><strong>内联成员函数</strong>:内联函数在编译时被展开，而多态是运行时多态，也就是运行时才确定要调用哪个虚函数，矛盾</p><p><strong>静态成员函数</strong>:虚函数保存在虚表中，调用虚函数时需要通过 this 指针得到虚表指针，再通过虚表指针找到虚函数,而静态函数不传入 this 函数，因此不可声明为虚函数</p><p><strong>友元函数</strong>:对于没有继承特性的函数没有虚函数的说法。友元函数不属于类的成员函数，不能被继承。</p><h2 id="104-☆-如何保证类的对象只能被开辟在堆上？（将构造函数声明为私有、单例）"><a href="#104-☆-如何保证类的对象只能被开辟在堆上？（将构造函数声明为私有、单例）" class="headerlink" title="104.(☆)如何保证类的对象只能被开辟在堆上？（将构造函数声明为私有、单例）"></a>104.(☆)如何保证类的对象只能被开辟在堆上？（将构造函数声明为私有、单例）</h2><p>将构造函数设置为私有，这样只能使用new运算符来建立对象，但是我们必须准备一个destory函数来进行内存的释放，然后将析构函数设置为 protected，提供一个 public 的 static 函数来完成构造，类似于单例模式</p><p>如果在栈上分配呢？则是重载 new 操作符，使得 new 操作符的功能为空，这样就使得外层程序无法在堆上分配对象，只可以在栈上分配.</p><h2 id="105-C-C-堆和栈的区别"><a href="#105-C-C-堆和栈的区别" class="headerlink" title="105.C&#x2F;C++堆和栈的区别"></a>105.C&#x2F;C++堆和栈的区别</h2><p><strong>1.生命周期不同</strong></p><pre><code>堆：一般由程序员分配释放，若程序员不释放，程序结束时可能由 OS 回收。栈：由编译器（Compiler）自动分配释放，存放函数的参数值、局部变量的值等。其操作方式类似于数据结构中的栈。</code></pre><p><strong>2.申请方式不同</strong></p><pre><code>堆：程序中要分配一个堆空间可以使用 new（new 这是 C++中专用的关键字） 关键字、malloc 函数， calloc()函数， realloc 函数实现;当不再需要这个堆空间时，可以使用 delete（delete 这是 C++中专用的关键字） 关键字、 free 函数完成释放工作。栈：由系统自动分配。只要是局部变量 ，操作系统自动在栈中其开辟空间。比如在 main 函数中定义一个变量 int b,则 b 使用的空间就是栈空间。</code></pre><p><strong>3.底层实现机制不同</strong></p><pre><code>堆：堆的生长方向是向上生长，内存地址由低到高，一般是通过链表进行存储空间管理，内存上可以是不连续的。栈：栈的生长方向是向下生长（有的系统可能是向上生长），内存地址由高到低。且在使用上， 空间是连续的。</code></pre><p><strong>4.申请空间大小上限不同</strong></p><pre><code>堆：堆的大小受限于计算机系统中有效的虚拟内存。在 32 位系统上，其大小可以达 4G，使用起来比较灵活。栈：在 Windows 下，栈的大小是固定的（是一个编译时就确定的常数），所以程序员不适合在函数内申请过多的栈空间，否则可能会导致程序栈溢出。</code></pre><p><strong>5.内存利用率不同</strong></p><pre><code>堆：堆空间的申请分配一般是随机的，不连续的内存空间， 容易产生内存碎片。栈：由系统自动分配，速度较快，但程序员是无法控制的。</code></pre><p><strong>6.分配方式不同</strong></p><pre><code>堆：都是动态分配的，没有静态分配的堆。栈：有2种分配方式：静态分配和动态分配。静态分配是由操作系统完成的，比如局部变量的分配;动态分配由alloca函数进行分配，但是栈的动态分配和堆是不同的，他的动态分配是由操作系统进行释放，无需我们手工实现。</code></pre><p><a href="https://www.jb51.net/article/215546.htm">https://www.jb51.net/article/215546.htm</a></p><h2 id="106-讲讲你理解的虚基类"><a href="#106-讲讲你理解的虚基类" class="headerlink" title="106.讲讲你理解的虚基类"></a>106.讲讲你理解的虚基类</h2><p><a href="https://www.cnblogs.com/DOTA-SPE/p/15920853.html">https://www.cnblogs.com/DOTA-SPE/p/15920853.html</a></p><p>虚基类是 C++ 中一种特殊的类，用于解决多继承所带来的“菱形继承”问题。如果一个派生类同时从两个基类派生，而这两个基类又共同继承自同一个虚基类，就会形成一个“菱形”继承结构，导致派生类中存在两份共同继承的虚基类的实例，从而引发一系列的问题。</p><p>为了解决这个问题，我们可以将虚基类作为共同基类，并在派生类中采用虚继承的方式。</p><p><strong>虚基类只能被实例化一次</strong>—&gt;虚继承会使得派生类中只存在一份共同继承的虚基类的实例，从而避免了多个实例之间的冲突。</p><p>虚基类子对象是由<strong>最远派生类的构造函数</strong>(在继承结构中建立对象时所指定的类)通过调用虚基类的构造函数进行初始化的。</p><p> 派生类的构造函数的成员初始化列表中<strong>必须列出对虚基类构造函数的调用</strong>；如果未列出，则表示使用该虚基类的<strong>缺省构造函数</strong>。</p><p>在一个成员初始化列表中同时出现对虚基类和非虚基类构造函数的调用时，<font color="#F100">虚基类的构造函数先于非虚基类的构造函数执行。</font></p><h2 id="107-C-哪些运算符不能被重载？"><a href="#107-C-哪些运算符不能被重载？" class="headerlink" title="107.C++哪些运算符不能被重载？"></a>107.C++哪些运算符不能被重载？</h2><p><strong>成员访问运算符<code>.</code><strong>，</strong>指针运算符 <code>.*</code><strong>，</strong>域解析操作符<code>::</code><strong>，</strong>条件运算符<code>?:</code></strong>,**长度运算符 <code>sizeof</code>**之类的不能重载。其中并不推荐对逗号运算符，逻辑或逻辑与之类运算符进行重载，容易造成歧义。</p><pre><code>.* 和 -&gt;* 返回表达式左侧所指定的对象的特定类成员的值</code></pre><h2 id="108-动态链接和静态链接的区别，动态链接的原理是什么？"><a href="#108-动态链接和静态链接的区别，动态链接的原理是什么？" class="headerlink" title="108.动态链接和静态链接的区别，动态链接的原理是什么？"></a>108.动态链接和静态链接的区别，动态链接的原理是什么？</h2><p><strong>区别</strong>：他们的最大区别就是在于链接的时机不同，静态链接是在形成可执行程序前，而动态链接的进行则是程序执行时。</p><p><strong>静态库</strong>：就是将库中的代码包含到自己的程序之中，每个程序链接静态库后，都会包含一份独立的代码，当程序运行起来时，所有这些重复的代码都需要占用独立的存储空间，显然很浪费计算机资源。</p><p><strong>动态库</strong>：不会将代码直接复制到自己程序中，只会留下调用接口，程序运行时再去将动态库加载到内存中，所有程序只会共享这一份动态库，因此动态库也被称为共享库。</p><p><strong>动态链接原理</strong>：是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件</p><h2 id="109-C-中怎么编译C语言代码？"><a href="#109-C-中怎么编译C语言代码？" class="headerlink" title="109.C++中怎么编译C语言代码？"></a>109.C++中怎么编译C语言代码？</h2><p>需要使用 C++ 的外部链接功能，即 <code>extern &quot;C&quot;</code>。这告诉 C++ 编译器，被这个声明的函数或变量是用 C 的方式进行链接的。</p><h2 id="110-初始化全局变量和未初始化全局变量有什么区别？"><a href="#110-初始化全局变量和未初始化全局变量有什么区别？" class="headerlink" title="110.初始化全局变量和未初始化全局变量有什么区别？"></a>110.初始化全局变量和未初始化全局变量有什么区别？</h2><p><a href="https://blog.csdn.net/qq_70799748/article/details/130712416">https://blog.csdn.net/qq_70799748&#x2F;article&#x2F;details&#x2F;130712416</a></p><p>全局变量初始化而且初始值不为0，那么这样的全局变量是放在内存的**.data段<strong>的，如果全局变量初始值为0或者未初始化，那么这样的全局变量是放在</strong>.bss**（Block Started By Symbol）段的。</p><p><font color="#F100">未初始化的全局变量的默认值是 0，而未初始化的局部变量的值却是垃圾值（任意值）。</font></p><p>内存中运行着很多程序，我们的程序只占用一部分空间，这部分空间又可以细分为以下的区域：</p><p><strong>1.程序代码区</strong>：存放函数体的二进制代码。</p><p>**2.静态数据区(data area)**：也称全局数据区,包含的数据类型比较多，如全局变量、静态变量、一般常量、字符串常量</p><p>(1)全局变量区和静态变量区的存储是返回在一块的，初始化的全局变量和静态变量在一块区域。未初始化的全局变量和未初始化的静态变量在相邻的另一区域。</p><p>(2)常量区域包括字符串常量和一般常量存储在另一区域</p><p>注意：静态区的内存在程序结束后由系统释放。</p><p><strong>3.堆区</strong>：一般由程序员分配和释放，若程序员不释放，则程序运行结束后由系统回收。malloc(),calloc(),free()，操作的就是这块内存。</p><p>注意：这里的堆区不同于数据结构的堆，堆区的分配方式倒是和数据结构的链表比较相似。</p><p><strong>4.栈区</strong>：由系统自动分配释放，存放函数的参数值和局部变量的值等。其操作方式类似于数据结构中的栈。</p><p><strong>5.命令形参区</strong>：存放命令型参数和环境变量的值，如通过<code>main()</code>传递的值。</p><h2 id="111-说一下内联函数及其优缺点"><a href="#111-说一下内联函数及其优缺点" class="headerlink" title="111.说一下内联函数及其优缺点"></a>111.说一下内联函数及其优缺点</h2><p><strong>每调用一次函数,都要为其分配一片栈空间(栈帧)。</strong>并且在函数调用的时候，需要跳转到函数所在的位置，这是需要做很多的准备——比如: 记录程序执行的位置,状态等。因此，<strong>函数调用是有一定时间开销的。</strong></p><p>内联函数是在编译期将函数体内嵌到程序之中，以此来节省函数调用的开销。</p><p><strong>优点</strong>：调用函数是不需要给函数分配占空间，不需要跳转。节省了函数调用的开销，让程序运行更加快速。</p><p><strong>缺点</strong>：内联函数函数体占用的是调用者的栈空间，如果函数体过长，频繁使用内联函数会导致代码编译膨胀问题。不能递归执行。</p><p><a href="https://blog.csdn.net/weixin_61084441/article/details/128776893">https://blog.csdn.net/weixin_61084441&#x2F;article&#x2F;details&#x2F;128776893</a></p><h2 id="112-C-11中的auto是怎么实现自动识别类型的？模板是怎样实现转化成不同类型的？"><a href="#112-C-11中的auto是怎么实现自动识别类型的？模板是怎样实现转化成不同类型的？" class="headerlink" title="112.C++11中的auto是怎么实现自动识别类型的？模板是怎样实现转化成不同类型的？"></a>112.C++11中的auto是怎么实现自动识别类型的？模板是怎样实现转化成不同类型的？</h2><p><code>auto</code> 仅仅只是一个占位符，在编译期间它会被真正的类型替代，或者说 C++ 中变量必须要有明确类型的，只是这个类型是由编译器自己推导出来的。<br>使用auto可以提高代码的简洁性和易读性，并减少一些显式类型声明的工作。</p><ol><li>auto 不能用于函数参数</li><li>auto 不能用于非静态成员变量</li><li>auto 无法定义数组</li><li>实例化模板时不能使用 auto 作为模板参数。</li></ol><p>函数模板是一个蓝图，它本身并不是函数，是编译器用使用方式具体类型函数的模具，所以模板其实就是将原本应该我们做重复的事情交给了编译器。</p><h2 id="113-map-和-set-的区别和底层实现是什么？map取值的-find，-，at方法的区别-at有越界检查功能"><a href="#113-map-和-set-的区别和底层实现是什么？map取值的-find，-，at方法的区别-at有越界检查功能" class="headerlink" title="113.map 和 set 的区别和底层实现是什么？map取值的 find，[]，at方法的区别(at有越界检查功能)"></a>113.map 和 set 的区别和底层实现是什么？map取值的 find，[]，at方法的区别(at有越界检查功能)</h2><p><strong>序列式容器</strong>：vector&#x2F;list&#x2F;string&#x2F;deque；<br>序列式容器才支持push等操作，关联式容器不支持</p><p><strong>关联式容器</strong>：map&#x2F;set&#x2F;unordered_map&#x2F;unordered_set；set和map的底层实现是<strong>平衡搜索二叉树</strong></p><ul><li><strong>set的特性</strong>：①、会对插入的数据自动排序 ②、set是不允许修改值的 ③、set中不允许出现重复的数值，即使存在，也只会留一个</li><li><strong>set的遍历</strong>：①、迭代器遍历 ②、范围for遍历（因为支持迭代器遍历就一定支持范围for）</li><li>set的拷贝构造</li><li><strong>set的插入</strong>只有insert，其没有push、pop等，因为它是关联式容器</li><li>set的find，<strong>find找到了会返回被查找元素的迭代器，没找到返回end()，故应检查找没找到</strong></li><li><strong>set的删除</strong>：①、erase(待删除位置的迭代器)  ②、erase(待删除数据) ③、erase(s.begin(), s.end())【即迭代器头和尾，其效果等价于clear】</li></ul><blockquote><p>set的find和库里面提供的find有什么区别呢？<br>（1）都可实现查找，区别在于效率<br>（2）set是搜索二叉树的：时间复杂度：O（logN），而算法中的是O（N）<br>（3）算法中的find是个模板，其实现是为了所有容器可以通用它，故set尽量用自己的find </p></blockquote><ul><li>map就是搜索树中的key&#x2F;value模型</li><li>map的遍历：①、迭代器遍历 ②、范围for遍历</li><li>map的类型是pair，pair存的一个是key的，一个是value的类型</li><li>map的构造函数：①、pair构造函数 ②、make_pair函数模板构造一个pair对象</li></ul><p><code>multiset</code> 和 <code>multimap</code> 除了在set和map的基础上支持数据重复出现外，根本没什么区别</p><p><code>Map</code> 中存储的是 <code>Key-Value</code> 的键值对，<code>Set</code> 中只存储了 <code>Key</code></p><p>都是红黑树，</p><p><code>find</code> 查找需要判断返回的结果才知道有没有查询成功。</p><p><code>[]</code>不管有没有就是 <code>0</code>，如果原先不存在该 <code>key</code>，则插入，如果存在则覆盖插入，</p><p><code>at</code> 方法则会进行越界检查，这会损失性能，如果存在则返回它的值，如果不存在则抛出异常。</p><h2 id="114-详细说一说-fcntl-的作用"><a href="#114-详细说一说-fcntl-的作用" class="headerlink" title="114.详细说一说 fcntl 的作用"></a>114.详细说一说 fcntl 的作用</h2><p><strong>作用</strong>：用于控制打开的文件描述符的一些属性和行为。</p><pre><code>#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;int fcntl(int fd, int cmd, ... /* arg */ );</code></pre><p>有五个功能：</p><p>1.复制一个现有的描述符(cmd&#x3D;F_DUPFD)</p><p>2.获得&#x2F;设置文件描述符标记（cmd&#x3D;F_GETFD或F_SETFD）</p><p>3.获取&#x2F;设置文件状态标记（cmd&#x3D;F_GETFL或F_SETFL）</p><p>4.获取设置异步IO所有权（cmd&#x3D;F_GETOWN或F_SETFL）</p><p>5.获取设置记录锁（cmd&#x3D;F_GETLK或F_SET）</p><h2 id="115-C-的面向对象主要体现在那些方面？"><a href="#115-C-的面向对象主要体现在那些方面？" class="headerlink" title="115.C++的面向对象主要体现在那些方面？"></a>115.C++的面向对象主要体现在那些方面？</h2><p>体现在C++引入了面向对象的一些特征，例如加入了封装继承多态的特点。（然后介绍一下封装继承多态）</p><h2 id="116-介绍一下-extern-C-关键字，为什么会有这个关键字？"><a href="#116-介绍一下-extern-C-关键字，为什么会有这个关键字？" class="headerlink" title="116.介绍一下 extern C 关键字，为什么会有这个关键字？"></a>116.介绍一下 extern C 关键字，为什么会有这个关键字？</h2><p>extern “C” 关键字常用于 C++ 和 C 混合编程中，用于指定函数或变量采用 C 语言的命名和调用约定。加上 extern “C” 后，会指示编译器这部分代码按 C 语言（而不是C++）的方式进行编译。</p><blockquote><p>由于C++支持函数重载，因此编译器编译函数的过程中会将函数的参数类型也加到编译后的代码中，而不仅仅是函数名（而C语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般只包括函数名）。</p></blockquote><p>也就是说：C++和C对产生的函数名字的处理是不一样的，extern “C”的目的就是主要实现C与C++的相互调用问题。</p><h2 id="117-讲一讲迭代器失效及其解决方法"><a href="#117-讲一讲迭代器失效及其解决方法" class="headerlink" title="117.讲一讲迭代器失效及其解决方法"></a>117.讲一讲迭代器失效及其解决方法</h2><p>迭代器的主要作用：就是让算法能够不用关心底层数据结构，其底层实际就是一个指针，或者是对指针进行了封装</p><p><strong>迭代器失效</strong>：实际就是迭代器底层对应指针所指向的空间被销毁了，而使用一块已经被释放的空间，造成的后果是程序崩溃(即如果继续使用已经失效的迭代器，程序可能会崩溃)。</p><p>总结：迭代器失效分三种情况考虑，也是非三种数据结构考虑，分别为数组型，链表型，树型数据结构。</p><p><strong>数组型数据结构：</strong> 该数据结构的元素是分配在连续的内存中，insert和erase操作，都会使得删除点和插入点之后的元素挪位置，所以，插入点和删除掉之后的迭代器全部失效，也就是说insert(*iter)(或erase(*iter))，然后在iter++，是没有意义的。解决方法：erase(*iter)的返回值是下一个有效迭代器的值。 iter &#x3D;cont.erase(iter);</p><p><strong>链表型数据结构：</strong> 对于list型的数据结构，使用了不连续分配的内存，删除运算使指向删除位置的迭代器失效，但是不会失效其他迭代器.解决办法两种，erase(*iter)会返回下一个有效迭代器的值，或者erase(iter++).</p><p><strong>树形数据结构：</strong> 使用红黑树来存储数据，插入不会使得任何迭代器失效；删除运算使指向删除位置的迭代器失效，但是不会失效其他迭代器.erase迭代器只是被删元素的迭代器失效，但是返回值为void，所以要采用erase(iter++)的方式删除迭代器。</p><p>注意：经过 erase(iter) 之后的迭代器完全失效，该迭代器 iter 不能参与任何运算，包括 iter++,*ite</p><p><a href="https://blog.csdn.net/lujiandong1/article/details/49872763?spm=1001.2101.3001.6650.3&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-49872763-blog-130630570.235%5Ev43%5Epc_blog_bottom_relevance_base8&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-3-49872763-blog-130630570.235%5Ev43%5Epc_blog_bottom_relevance_base8&utm_relevant_index=6">迭代器失效的几种情况总结</a></p><h2 id="118-编译器是如何实现重载的？"><a href="#118-编译器是如何实现重载的？" class="headerlink" title="118.编译器是如何实现重载的？"></a>118.编译器是如何实现重载的？</h2><p>在编译时，编译器如果遇到了函数，就会在符号表里面命名一个符号来存放函数的地址，</p><p>1.如果函数的使用在定义之前编译，无法在符号表中找到对应函数地址，则先标记为“<code>？</code>”（暂时未知），在全部编译结束后的链接过程将“<code>？</code>”在符号表里找到并替代为相应的函数地址，</p><p>2.如果函数的定义在使用之前编译，则可以直接在符号表里找到对应函数地址直接使用，</p><p>而在C语言中的符号表是以函数名为符号来存储函数地址，函数名相同的重载函数的地址应该不同，于是符号表中存在两个同符号的函数地址，在查找使用时会存在歧义和冲突。</p><p>而C++符号表中的符号不是以函数名命名的，称为<strong>函数名修饰规则</strong>，虽然函数名相同，但是函数参数等其他属性不同，取的符号也不同，所以不会产生查询歧义的问题，使得函数可以重载。</p><h2 id="119-什么是函数调用约定？"><a href="#119-什么是函数调用约定？" class="headerlink" title="119.什么是函数调用约定？"></a>119.什么是函数调用约定？</h2><p>函数调用约定就是对函数调用的一个约束和规定，描述了函数参数是怎么传递和由谁清除堆栈的。它决定了，函数参数传递的方式（是否采用寄存器传递参数，采用哪个寄存器传递参数，参数压栈的顺序等），函数调用结束后栈指针由谁恢复（被调用的函数恢复还是调用者恢复），函数修饰名的产生方法。</p><p>__stdcall：是standardcall的缩写，是C++的标准调用方式，规则如下：所有参数从右到左依次入栈，如果是调用类成员的话，最后一个入栈的是this指针。被调用函数自动清理堆栈，返回值在EAX。函数修饰名约定：VC将函数编译后会在函数名前面加上下划线前缀，在函数名后加上“@”和参数的字节数。</p><p>__cdecl：是C DECLaration的缩写（declaration，声明），表示C语言的默认函数调用方法，规定如下：所有参数从右往左依次入栈，所有参数由调用者清除，称为手动清栈。返回值在EAX中。函数修饰名约定：VC将函数编译后会在函数名前面加上下划线前缀，由于由调用者清理栈，所以允许可变参数函数存在。</p><p>__fastcall：是快速调用约定，通过寄存器来传送参数，规则如下：用ECX和EDX传送前两个双字（DWORD）或更小的参数，剩下的参数仍然自右向左压栈传送。被调用函数在返回前清理传送参数的内存栈，返回值在EAX中。函数修饰名约定：VC将函数编译后会在函数名前面加上“@”前缀，在函数名后加上“@”和参数的字节数。</p><p>__thiscall：是唯一一个不能明确指明的函数修饰符，thiscall只能用于处理C++类成员函数的调用，同时thiscall也是C++成员函数缺省的调用约定，由于成员函数调用还有一个this指针，因此必须特殊处理，规定如下：采用栈传递参数，参数从右向左入栈，如果参数个数确定，this指针通过TCX传递给被调用者，如果参数个数不确定，this指针在所有参数压栈后被压入堆栈。对参数个数不确定的，调用者清理堆栈，否则由被调函数清理堆栈，<br>__thiscall不是关键字，程序员不能使用</p><p>__pascal：与 __stdcall一样，在VC中已经被废弃</p><h2 id="120-类内普通成员函数可以调用类内静态变量吗，类内静态成员函数可以访问类内普通变量吗？"><a href="#120-类内普通成员函数可以调用类内静态变量吗，类内静态成员函数可以访问类内普通变量吗？" class="headerlink" title="120.类内普通成员函数可以调用类内静态变量吗，类内静态成员函数可以访问类内普通变量吗？"></a>120.类内普通成员函数可以调用类内静态变量吗，类内静态成员函数可以访问类内普通变量吗？</h2><p>类内普通成员函数可以调用类内静态变量，因为类内静态变量在编译时就已经完成了初始化和内存分配，类内普通函数调用类内静态变量说明类已经完成实例化，所以可以调用。</p><p>静态函数可以直接访问静态变量，静态函数不能直接访问非静态变量，但是可以通过将类实例化对象后，静态函数去访问对象的非静态成员变量。</p><h2 id="121-强制类型转换有哪几种类型，分别有什么特点？原理是什么？"><a href="#121-强制类型转换有哪几种类型，分别有什么特点？原理是什么？" class="headerlink" title="121.强制类型转换有哪几种类型，分别有什么特点？原理是什么？"></a>121.强制类型转换有哪几种类型，分别有什么特点？原理是什么？</h2><p><strong>Static_cast</strong>：用于数据类型的强制转换，强制将一种数据类型转化为另一种数据类型。</p><ol><li>用于类层次结构中基类和派生类之间指针或引用的转换，进行上行切换（把派生类的指针或引用转换成基类表示）是安全的，进行下行转换（把基类的指针或引用转换为派生类表示），由于没有动态类型检查，所以是不安全的。</li><li>用于基本类型之间的转换，如把int转换成char，这种类型的转换也需要开发人员来保证</li><li>把空指针转换成目标类型的空指针。</li><li>把任意类型的表达式转换成void类型</li><li>涉及到类时，只能在有相互联系的类型中进行相互转换，不一定包含虚函数</li></ol><p><strong>注意</strong>：不能转换掉表达式中的const，volitale，__unaligned属性</p><hr><p><strong>Const_cast</strong>：用于强制去除类似于const这种不能被修改的常数特性。</p><ol><li>用来修改类型的const或者volatile属性，除了const或volatile修饰之外，type_id和expression的类型是一样的。</li><li>常量指针被转化为非常量指针，并且仍然指向原来的对象</li><li>常量引用被转换为非常量引用，并且仍指向原来的对象，常量对象被转换成非常量对象。</li></ol><p><strong>注意</strong>：const_cast 不适用于去除变量的常量性，而是去除指向常数对象的指针或引用的常量性，即<strong>去除常量性的对象必须为指针或者引用</strong>。</p><hr><p><strong>Reinterpret_cast</strong>：用于改变指针或引用的类型，将指针或引用类型转换成一个足够长的整形，将整形转换为指针或引用。</p><ol><li>传入类型必须是一个指针，引用，算术类型，函数指针，成员函数或成员指针</li><li>它可以把一个指针转换成一个整数，也可以把一个整数转换成一个指针。</li></ol><p><strong>注意</strong>：在强制转换的过程中只是比特位的拷贝，在使用中必须特别谨慎。</p><hr><p><strong>Dynamic_cast</strong>：其他三种都是在编译时完成的，它是在运行时处理的，运行时要进行类型检查。</p><ol><li>不能用于内置的基本数据类型的强制转换。</li><li>如果转换成功会返回一个指向类的指针或者引用，转换失败会返回NULL。</li><li>进行转换的时候基类中一定要有虚函数，否则编译不通过（因为类中存在虚函数就说明它有想让基类指针或引用指向派生类对象的情况，此时转换才有意义）。</li><li>在类的转换时，在类层次间进行上行转换时，与 <code>static_cast</code> 的转换效果是一样的，在下行转换时，它具有类型检查功能，比 <code>static_cast</code> 更安全。</li></ol><p><strong>注意</strong>：向下转换的成功与否还与将要转换的类型有关，即要转换的指针指向的对象的实际类型与转换以后的对象类型一定要相同，否则转换失败。如果转换目标是指针类型转换失败，则结果返回0，如果是引用类型则抛出<code>std::bad_cast</code>异常</p><p>原理：改变了其内存二进制的存储形式。</p><h2 id="122-回调函数是什么，为什么要有回调函数？有什么优缺点？回调的本质是什么？"><a href="#122-回调函数是什么，为什么要有回调函数？有什么优缺点？回调的本质是什么？" class="headerlink" title="122.回调函数是什么，为什么要有回调函数？有什么优缺点？回调的本质是什么？"></a>122.回调函数是什么，为什么要有回调函数？有什么优缺点？回调的本质是什么？</h2><p><strong>回调函数</strong>是指使用者自己定义一个函数，实现这个函数的程序内容，然后别人把这个函数（入口地址）作为参数传入别人的函数中，由别人的函数在运行时来调用的函数，简单说就是放发生某种事件时，系统或其他函数将会自动调用你定义的一段函数。</p><p>可以把调用者和被调用者分开。调用者不关心谁是被调用者，所以它只需要知道的，只是一个存在某种特定类型原型，某些限制条件的被调用函数。</p><p>优点：</p><ol><li>可以让实现方根据回调方的多种形态进行不同的处理和操作</li><li>可以让实现方，根据自己的需要定制回调方的不同形态</li><li>可以将耗时的操作隐藏在回调方，不影响实现方其他信息的展示。</li><li>让代码的逻辑更加集中，更加易读。</li></ol><p>缺点：</p><ol><li>回调函数过多会导致代码难以维护</li><li>回调函数容易造成资源竞争：如果回调函数中有共享资源访问，容易出现资源争抢，导致程序出错</li><li>代码可读性差，可能会破坏代码的结构和可读性</li></ol><p><strong>本质</strong>：是将函数当作参数使用，目的是为了使程序更加普适。</p><h2 id="123-什么是尾递归？"><a href="#123-什么是尾递归？" class="headerlink" title="123.什么是尾递归？"></a>123.什么是尾递归？</h2><p>尾递归时递归的一种特殊情形，尾递归是一种特殊的尾调用，即在尾部直接调用自身的递归函数。核心思想是边调用便产生结果。</p><p><strong>原理</strong>：当编译器检测到一个函数调用是尾递归的时候，它会覆盖当前的活动记录而不是在栈中创建一个新的。编译器可以做到这一点，因为递归调用是当前活跃期内最后一条待执行的语句，于是当这个调用返回时栈帧中并没有其他事情可以做，因此也就没有保存栈帧的必要了，通过覆盖当前的栈帧而不是在其之上重新添加一个，这样所使用的栈空间就大大缩减了，这使得实际的运行效率会变得更高。</p><p><strong>特点</strong>：在尾部调用的是函数自身，可通过优化使得计算仅占用常量栈空间。</p><h2 id="124-为什么会有栈溢出，为什么栈会设置容量？"><a href="#124-为什么会有栈溢出，为什么栈会设置容量？" class="headerlink" title="124.为什么会有栈溢出，为什么栈会设置容量？"></a>124.为什么会有栈溢出，为什么栈会设置容量？</h2><p><em>栈空间是预设的</em>，它通常用于存放临时变量，如果你在函数内部定义一个局部变量，空间超出了设置的栈空间大小，就会溢出。<br>不仅如此，如果函数嵌套太多，也会发生栈溢出，因为函数没有结束前，函数占用的变量也不被释放，占用了栈空间。</p><p><strong>原因</strong>：是栈的地址空间必须连续，如果任其任意成长，会给内存管理带来困难。对于多线程程序来说，每个线程都必须分配一个栈，因此没办法让默认值太大。</p><h2 id="125-二叉树和平衡二叉树的区别"><a href="#125-二叉树和平衡二叉树的区别" class="headerlink" title="125.二叉树和平衡二叉树的区别"></a>125.二叉树和平衡二叉树的区别</h2><p>二叉树没有平衡因子的限制，而平衡二叉树有。</p><p>二叉树可能退化为链表，而平衡二叉树不会。</p><h2 id="126-平衡二叉树的优缺点"><a href="#126-平衡二叉树的优缺点" class="headerlink" title="126.平衡二叉树的优缺点"></a>126.平衡二叉树的优缺点</h2><p><strong>优点</strong>：避免了二叉排序树可能出现最极端情况（退化为链表），其平均查找的时间复杂度为logN</p><p><strong>缺点</strong>：对AVL树做一些结构修改的操作，性能非常低下，比如：插入时要维护其绝对平衡，旋转的次数比较多，更差的是在删除时，有可能一直要让旋转持续到根的位置。</p><h2 id="127-什么是this指针，为什么存在this指针？"><a href="#127-什么是this指针，为什么存在this指针？" class="headerlink" title="127.什么是this指针，为什么存在this指针？"></a>127.什么是this指针，为什么存在this指针？</h2><p>类和对象中的成员函数存储在公共的代码段，不同的对象调用成员函数时编译器为了知道具体操作的是哪一个对象给每个“非静态的成员函数”增加了一个隐藏的指针参数，让该指针指向当前对象，在函数体中所有成员变量的操作，都是通过这个指针来完成的由编译器自动完成。</p><h2 id="128-什么是重载、重写、隐藏？"><a href="#128-什么是重载、重写、隐藏？" class="headerlink" title="128.什么是重载、重写、隐藏？"></a>128.什么是重载、重写、隐藏？</h2><p>重载：函数名相同，函数参数不同，两个函数在同一作用域。</p><p>重写：两个函数分别在子类和父类中，函数名，返回值，参数均相同，函数必须为虚函数。</p><p>隐藏：在继承关系中，子类实现了一个和父类名字名字一样的函数。这样子类的函数就把父类的同名函数隐藏了。隐藏只与函数名有关。</p><h2 id="127-静态成员函数可以是虚函数吗？为什么？"><a href="#127-静态成员函数可以是虚函数吗？为什么？" class="headerlink" title="127.静态成员函数可以是虚函数吗？为什么？"></a>127.静态成员函数可以是虚函数吗？为什么？</h2><p>它不属于类中的任何一个对象或示例，属于类共有的一个函数，不依赖于对象调用，静态成员函数没有this指针，无法放进虚函数表。</p><h2 id="128-构造函数可以为虚函数吗？为什么？"><a href="#128-构造函数可以为虚函数吗？为什么？" class="headerlink" title="128.构造函数可以为虚函数吗？为什么？"></a>128.构造函数可以为虚函数吗？为什么？</h2><p>虚表指针是存储在对象的内存空间，当调虚函数时，是通过虚表指针指向的虚表里的函数地址进行调用的。如果将构造函数定义为虚函数，就要通过虚表指针指向的虚表的构造函数地址来调用。而构造函数是实例化对象，定义为虚函数后，对象空间还没有实例化，那就没有虚表指针，自然无法调用构造函数，那构造函数就失去意义，所以不能将构造函数定义为虚函数。</p><h2 id="129-make-shared-函数的优点，缺点？"><a href="#129-make-shared-函数的优点，缺点？" class="headerlink" title="129.make_shared 函数的优点，缺点？"></a>129.make_shared 函数的优点，缺点？</h2><p><code>shared_ptr</code>：可以指向特定类型的对象，用于自动释放所指的对象；</p><p><code>make_shared</code>：功能是在动态内存中分配一个对象并初始化它，返回指向此对象的 <code>shared_ptr</code>；</p><pre><code>shared_ptr&lt;string&gt; p1 = make_shared&lt;string&gt;(10, &#39;9&#39;);  shared_ptr&lt;string&gt; p2 = make_shared&lt;string&gt;(&quot;hello&quot;);  shared_ptr&lt;string&gt; p3 = make_shared&lt;string&gt;(); </code></pre><p>从上面可以看出：</p><p>1）<code>make_shared</code> 是一个模板函数；</p><p>2）<code>make_shared</code> 必须显式指定想要创建的对象类型，如上题所示 <code>make_shared(10, 9)</code>,如果不传递显式模板实参 <code>string</code> 类型，<code>make_shared</code> 无法从<code>(10, ‘9’)</code>两个模板参数中推断出其创建对象类型。</p><p>3）<code>make_shared</code> 在传递参数格式是可变的，参数传递为生成类型的构造函数参数，因此在创建 <code>shared_ptr</code> 对象的过程中调用了类型 <code>T</code> 的某一个构造函数。</p><hr><p><code>shared_ptr</code> 需要维护引用计数的信息。</p><p><strong>强引用</strong>，用来记录当前有多少个存活的 <code>shared_ptr</code> 正在持有该对象，共享的对象会在最后一个强引用离开的时候销毁（也可能释放）</p><p><strong>弱引用</strong>，用来记录当前有多少个正在观察该对象的 <code>weak_ptr</code>，当最后一个弱引用离开的时候，共享的内部信息控制块会被销毁和释放（共享的对象也会被释放，如果还没有释放的话）</p><p><strong>如果通过使用原始的 <code>new</code> 表示分配对象，然后传递给 <code>shared_ptr</code>（也就是 <code>shared_ptr</code> 的构造函数）的话，<code>shared_ptr</code> 的实现没有办法选择，而只能单独的分配控制块</strong></p><p><a href="https://blog.csdn.net/zhizhengguan/article/details/123700323">C&#x2F;C++编程：理解make_shared</a></p><p><code>std::shared_ptr</code> 构造函数会执行两次内存申请，<br><code>std::shared_ptr</code> 在实现的时候使用 <code>refcount</code> 技术，因此内部会有一个计数器(控制块)用来管理数据和一个指针。</p><p><strong>因此在  <code>std::shared_ptr&lt;A&gt; p2(new A)</code> 的时候，首先会申请数据的内存，然后申请内控制块，因此是两次内存申请</strong>。</p><hr><p><code>std::make_shared&lt;A&gt;()</code>则是只执行一次内存申请，将数据和控制块的申请放到一起。</p><p>因为 <code>make_shared</code> 只申请一次内存，因此控制块和数据块在一起，只有但控制块中不再使用时，内存才会释放。<br>但是如果还有 <code>weak_ptr</code> 指向该块对象所在的内存，存放管理对象的部分内存仍然不会被释放，因而导致在所有其他 <code>weak_ptr</code> 销毁前整块内存（尽管被管理对象已经析构了）将不会进入系统的内存池循环使用</p><hr><p><strong>优点</strong>：</p><ol><li>减少内存分配次数：与 <code>std::shared_ptr</code> 相比，<code>std::make_shared</code> 只进行一次内存分配，这可以减少内存碎片和分配开销。</li><li>提高性能：由于只进行一次内存分配，因此 <code>std::make_shared</code> 在某些情况下可以提高性能。</li><li>简化代码：使用 <code>std::make_shared</code> 可以简化代码，避免显式地创建和管理 <code>std::shared_ptr</code> 控制块的开销。</li></ol><p><strong>缺点</strong>：当构造函数是保护或者私有的时候无法使用 make_shared 函数。</p><p>会导致 <code>weak_ptr</code> 保持控制块的生命周期，连带着保持了对象分配的内存，只有当最后一个 <code>weak_ptr</code> 离开作用域时，内存才会被释放，对于内存要求高的场景来说，是一个需要注意的问题。</p><h2 id="130-函数调用进行的操作"><a href="#130-函数调用进行的操作" class="headerlink" title="130.函数调用进行的操作"></a>130.函数调用进行的操作</h2><p>1.将参数压栈：按照参数顺序的逆序进行，如果参数中有对象则先进行拷贝构造；</p><p>2.保存返回地址：即函数调用结束返回后接着执行的语句的地址；</p><p>3.保护维护函数栈帧信息的寄存器内容如，SP（堆栈指针），FP（栈帧指针）等。</p><p>4.保存一些通用寄存器的内容：因为有些通用寄存器会被所有函数用到，所以在函数调用之前，这些寄存器就可能已经放置了对函数有用的信息。</p><p>5.调用函数，函数执行完毕；</p><p>6.恢复通用寄存器的值；</p><p>7.恢复保存函数栈帧信息的那些寄存器的值；</p><p>8.通过移动栈指针，销毁函数的栈帧；</p><p>9.将保存的返回地址出栈，并赋给寄存器。</p><p>10.通过移动栈指针，回收传给函数的参数所占用的空间。</p><hr><h1 id="const"><a href="#const" class="headerlink" title="const"></a>const</h1><h2 id="131-说说-const-int-a-int-const-a-const-int-a-int-const-a-const-int-const-a-分别是什么，有什么特点。"><a href="#131-说说-const-int-a-int-const-a-const-int-a-int-const-a-const-int-const-a-分别是什么，有什么特点。" class="headerlink" title="131.说说 const int *a, int const *a, const int a, int *const a, const int *const a 分别是什么，有什么特点。"></a>131.说说 const int *a, int const *a, const int a, int *const a, const int *const a 分别是什么，有什么特点。</h2><p><code>const int *a==int const *a</code>：可以通过 a 访问整数值，但不能通过 a 修改该整数的值，指针本身是可变的，可以指向不同的整数；</p><blockquote><p>首先 a 是一个整形指针，而 const 修饰的是 int*，表示 a 所指向的地址的内容不能被改变，但是 a 本身还可以指向别的地址。</p></blockquote><p><code>const int a</code>：a变量变成常量，不可修改；</p><p><code>int *const a</code>：a的值可以更改，但是指向它的指针不能更改；</p><blockquote><p>a 是一个指向整形变量的指针，但与 <code>const int* a</code> 不同，<code>const</code> 修饰的是 <code>a</code> 本身，那么效果也就可想而知，并且 <code>int* const a</code> 在声明时就<strong>必须初始化</strong>，它表示的含义与 <code>const int* a</code> 相反，它<strong>表示 a 本身一旦指向一个地址后就不能重新指向别的地址，但可以用解引用的方式改变其指向的空间的值。</strong></p></blockquote><p><code>int const *const a</code>：a本身和指向它的指针都不能更改。</p><blockquote><p>const 同时修饰了 int* 和 a 本身，就表示 a 既不能通过解引用的方式改变其所指的空间的值，同时 a 一旦被初始化后就不能再指向别的地址。</p></blockquote><h2 id="132-const-成员函数"><a href="#132-const-成员函数" class="headerlink" title="132.const 成员函数"></a>132.const 成员函数</h2><p>常函数内不能修改成员变量</p><p>对于类的成员函数，有时候必须指定其返回值为 <code>const</code> 类型，以使得其返回值不为“左值”。</p><p>如果成员变量被 <code>mutable</code> 关键字修饰，那么就可以在常函数中修改</p><h2 id="133-const-和-define-的区别"><a href="#133-const-和-define-的区别" class="headerlink" title="133.const 和 #define 的区别"></a>133.const 和 #define 的区别</h2><p>（1） const 常量有数据类型，而宏常量没有数据类型。编译器可以对前者进行类型安全检查。<br>而对后者只进行字符替换，没有类型安全检查，并且在字符替换可能会产生意料不到的错误（边际效应）。</p><p>（2）有些集成化的调试工具可以对 const 常量进行调试，但是不能对宏常量进行调试。</p><p>（3）#define是在编译的预处理阶段起作用，而const是在编译、运行的时候起作用。</p><p>（4）#define定义的常量不分配内存，而const定义的常量会分配在常量存储区中。</p><h2 id="134-什么-const-在常量区，什么-const-在栈区，什么-const-放入符号表优化？"><a href="#134-什么-const-在常量区，什么-const-在栈区，什么-const-放入符号表优化？" class="headerlink" title="134.什么 const 在常量区，什么 const 在栈区，什么 const 放入符号表优化？"></a>134.什么 const 在常量区，什么 const 在栈区，什么 const 放入符号表优化？</h2><ul><li>如果const修饰的是全局变量放到常量区（不可以通过地址修改该变量的值，定义为全局变量或者static变量的const常量通常被存放在常量区）</li><li>如果const修饰的是局部变量放在栈区（虽然是只读的，但可以通过变量指针修改变量的值，但是修改后的值只能在函数内部使用）</li><li>如果const修饰的变量没有被使用则会放到符号表中，其内容不会分配空间（如果一个const变量没有被使用，那么它就不会被分配内存，而是被优化掉。这种情况下，const 常量的值会被放在符号表中，而不会被放在内存中。当程序需要使用 const 变量时，编译器会根据符号表中的信息生成相应的指令。）</li></ul><h2 id="135-C-中内存中的几个区域分别存放什么？"><a href="#135-C-中内存中的几个区域分别存放什么？" class="headerlink" title="135.C++ 中内存中的几个区域分别存放什么？"></a>135.C++ 中内存中的几个区域分别存放什么？</h2><p>在 C++ 中，内存被分为以下几个区域：</p><ul><li><strong>栈区（Stack）</strong>：由编译器自动分配和释放，存放函数的参数值、局部变量的值等，其大小受限于操作系统和硬件。</li><li><strong>堆区（Heap）</strong>：由程序员手动分配和释放，通常用于动态内存分配，其大小受限于系统可用的虚拟内存大小。</li><li><strong>全局区&#x2F;静态区（Data Segment）</strong>：存放全局变量、静态变量等，包括初始化和未初始化的数据，其大小由编译器决定。</li><li><strong>常量区</strong>：存储常量，一般不允许修改。</li><li><strong>代码区（Code Segment）</strong>：存放程序的二进制码。</li></ul><p>在程序执行期间，操作系统会为每个进程分配一段内存，进程的内存空间被划分为多个段，每个段有其独立的属性和限制。C++ 中的内存分区可以帮助程序员更好地管理内存，提高程序的效率和可靠性。</p><h2 id="136-堆和栈的区别？"><a href="#136-堆和栈的区别？" class="headerlink" title="136.堆和栈的区别？"></a>136.堆和栈的区别？</h2><p>在计算机科学中，堆(heap)和栈(stack)都是内存中用于存储数据的区域，但是它们在访问方式、内存管理方式和用途等方面存在很大的差别。</p><hr><p><strong>为什么要把堆和栈分开？– 设计思想</strong></p><p>第一，从软件设计的角度看，<strong>栈代表了处理逻辑</strong>，<strong>而堆代表了数据</strong>。</p><p>这样分开，使得处理逻辑更为清晰。分而治之的思想。这种隔离、模块化的思想在软件设计的方方面面都有体现。</p><p>第二，堆与栈的分离，使得<strong>堆中的内容可以被多个栈共享（也可以理解为多个线程访问同一个对象）</strong>。</p><p>这种共享的收益是很多的。一方面这种共享提供了一种<strong>有效的数据交互方式</strong>(如：共享内存)，另一方面，<strong>堆中的共享常量和缓存可以被所有栈访问，节省了空间</strong>。</p><p>第三，栈因为运行时的需要，比如保存系统运行的上下文，需要进行地址段的划分。<strong>由于栈只能向下生长，因此就会限制住栈存储内容的能力</strong>。而堆不同，堆中的对象是可以根据需要动态增长的，因此栈和堆的拆分，使得动态增长成为可能，相应栈中只需记录堆中的一个地址即可。</p><blockquote><p>为什么栈向下增长？</p><p>这个问题与虚拟地址空间的分配规则有关，每一个可执行程序，从低地址到高地址依次是：text，data，bss(BSS段（Block Started by Symbol segment）是计算机程序中的一个重要概念，主要用来存放程序中未初始化的全局变量和静态变量)，堆，栈，环境参数变量；其中堆和栈之间有很大的地址空间空闲着，在需要分配空间的时候，堆向上涨，栈往下涨。</p></blockquote><blockquote><p>如果栈向上涨的话，我们就必须得指定栈和堆的一个严格分界线，但这个分界线怎么确定呢？平均分？但是有的程序使用的堆空间比较多，而有的程序使用的栈空间比较多。所以就可能出现这种情况：一个程序因为栈溢出而崩溃的时候，其实它还有大量闲置的堆空间呢，但是我们却无法使用这些闲置的堆空间。所以呢，最好的办法就是让堆和栈一个向上涨，一个向下涨，这样它们就可以<strong>最大程度地共用这块剩余的地址空间，达到利用率的最大化</strong></p></blockquote><p>第四，面向对象就是堆和栈的完美结合。其实，面向对象方式的程序与以前结构化的程序在执行上没有任何区别。但是，面向对象的引入，使得对待问题的思考方式发生了改变，而更接近于自然方式的思考。当我们把对象拆开，你会发现，<strong>对象的属性其实就是数据，存放在堆中；而对象的行为（方法），就是运行逻辑，放在栈中</strong>。我们在编写对象的时候，其实即编写了数据结构，也编写的处理数据的逻辑。</p><hr><p><strong>堆和栈访问方式的区别</strong></p><p>栈是一种后进先出(LIFO)的数据结构，数据的添加和删除只能在栈顶进行，而且只能访问栈顶的元素，访问其他元素必须先弹出栈顶的元素。栈的访问速度比堆快。</p><p>堆是一种无序的数据结构，数据的添加和删除没有任何限制，任何一个数据都可以通过指针进行访问。但是，由于堆内存的分配和释放不是按照固定的顺序进行的，所以访问堆中的数据需要较多的时间。</p><hr><p><strong>堆和栈内存管理方式的区别</strong></p><p>栈内存的分配和释放由系统自动完成，无需程序员手动干预。在需要时由编译器⾃动分配空间，在不需要时候⾃动回收空间，⼀般保存的是局部变量和函数参数等。</p><p>大多数编译器中，参数是从右向左入栈。（可以使得 C&#x2F;C++ 中函数参数可变的特性更方便）</p><p>堆内存的分配和释放由程序员手动完成。程序员需要显式地请求内存分配，并在不需要该内存时显式地释放该内存，否则会出现内存泄漏的问题。</p><hr><p><strong>函数调用栈</strong></p><ul><li>在 C++ 中，函数调用栈是一个运行时的数据结构，用于管理程序中的函数调用。每当<strong>调用一个函数时，都会在调用栈上创建一个新的栈帧</strong>，该栈帧包含了函数的参数、局部变量和返回地址等信息。</li><li>当程序调用一个函数时，该函数的参数被压入栈中，接着程序跳转到该函数的入口点，开始执行函数体内的语句。在函数体内，函数的局部变量也会被分配在栈帧中，然后按照语句<strong>顺序执行</strong>。</li><li>在函数返回时，<strong>返回值会被存储在特定的寄存器中，并将栈帧弹出调用栈</strong>。返回地址被恢复，程序再次从该地址继续执行。如果函数有多个返回点，则返回地址可能存储在栈中的某个位置，由于这些返回地址被存储在堆栈中，因此<strong>函数调用栈也被称为堆栈</strong>。</li><li>如果一个函数调用了另一个函数，则新的函数的栈帧会被压入当前栈帧的顶部。这样就可以递归地调用函数，直到函数返回。当函数返回时，栈帧将被弹出，控制权将返回到调用该函数的函数。</li></ul><hr><p><strong>堆和栈的用途</strong></p><ul><li>栈通常用于存储程序的局部变量、函数的参数、函数的返回地址等临时性数据。</li><li>堆通常用于存储程序中的动态数据，如使用malloc()或new()函数分配的内存，可以在程序的任何位置访问。堆还用于存储一些需要动态分配的数据结构，如链表、树等。</li><li>总的来说，栈和堆都是非常重要的内存管理方式，它们分别适用于不同的场合和用途。在编写程序时，需要根据具体的需求和要求选择合适的内存管理方式，以保证程序的效率和稳定性。</li></ul><h2 id="137-静态变量存放在哪？为什么？"><a href="#137-静态变量存放在哪？为什么？" class="headerlink" title="137.静态变量存放在哪？为什么？"></a>137.静态变量存放在哪？为什么？</h2><p>在C&#x2F;C++中，静态变量（static变量）存放在程序的全局数据区（Data Segment）或者全局代码区（Code Segment）中，具体存放位置取决于静态变量的作用域和存储类型。</p><ul><li>如果静态变量在<strong>函数内部定义</strong>，那么它的<strong>作用域仅限于该函数</strong>，但是它的存储类型是静态的，也就是说这个变量在程序运行期间只被初始化一次，然后一直存在于内存中。这种情况下， <strong>静态变量会被存放在全局数据区中</strong>。</li><li>如果静态变量在<strong>函数外部定义</strong>，那么它的作用域可以是整个程序，这种情况下<strong>静态变量也会被存放在全局数据区中</strong>。</li><li>但是如果静态变量是<strong>const类型</strong>的，它就会被存放在全局代码区中。因为const类型的变量是只读的，<strong>放在代码区可以避免被意外修改</strong>。</li></ul><hr><h1 id="虚函数"><a href="#虚函数" class="headerlink" title="虚函数"></a>虚函数</h1><h2 id="138-C-虚函数和纯虚函数的区别？"><a href="#138-C-虚函数和纯虚函数的区别？" class="headerlink" title="138.C++ 虚函数和纯虚函数的区别？"></a>138.C++ 虚函数和纯虚函数的区别？</h2><p><a href="https://blog.csdn.net/hackbuteer1/article/details/7558868">虚函数和纯虚函数的区别</a></p><font color="#F100">1.定义一个函数为虚函数，不代表函数为不被实现的函数。<p>2.定义他为虚函数是为了允许用基类的指针来调用子类的这个函数。</p><p>3.定义一个函数为纯虚函数，才代表函数没有被实现。<br></font></p><p>4.定义纯虚函数是为了实现一个接口，起到一个规范的作用，规范继承这个类的程序员必须实现这个函数。</p><p><strong>虚函数只能借助于指针或者引用来达到多态的效果。</strong></p><hr><p><strong>纯虚函数</strong>：纯虚函数是<strong>在基类中声明的</strong>虚函数，它在基类中没有定义，但要求任何派生类都要定义自己的实现方法。在基类中实现纯虚函数的方法是在函数原型后加“<code>=0</code>” <code>virtual void funtion1()=0</code></p><p><strong>引入原因：</strong></p><p>1、为了方便使用多态特性，我们常常需要在基类中定义虚拟函数。</p><p>2、在很多情况下，基类本身生成对象是不合情理的。</p><p><strong>同时含有纯虚拟函数的类称为抽象类，它不能生成对象。</strong></p><p><font color="#F100">定义纯虚函数的目的在于，使派生类仅仅只是继承函数的接口。</font></p><hr><p>总结：</p><ol><li>纯虚函数声明如下： <code>virtual void funtion1()=0; </code>纯虚函数一定没有定义，纯虚函数用来规范派生类的行为，即接口。包含纯虚函数的类是抽象类，抽象类不能定义实例，但可以声明指向实现该抽象类的具体类的指针或引用。</li><li>虚函数声明如下：<code>virtual ReturnType FunctionName(Parameter)；</code>虚函数必须实现，如果不实现，编译器将报错，错误提示为：<br>error LNK****: unresolved external symbol “public: virtual void __thiscall ClassName::virtualFunctionName(void)”</li><li>对于虚函数来说，父类和子类都有各自的版本。由多态方式调用的时候动态绑定。</li><li>实现了纯虚函数的子类，该纯虚函数在子类中就编程了虚函数，子类的子类即孙子类可以覆盖该虚函数，由多态方式调用的时候动态绑定。</li><li>虚函数是C++中用于实现多态(polymorphism)的机制。核心理念就是通过基类访问派生类定义的函数。</li><li>在有动态分配堆上内存的时候，析构函数必须是虚函数，但没有必要是纯虚的。</li><li>友元不是成员函数，只有成员函数才可以是虚拟的，因此友元不能是虚拟函数。但可以通过让友元函数调用虚拟成员函数来解决友元的虚拟问题。</li><li>析构函数应当是虚函数，将调用相应对象类型的析构函数，因此，如果指针指向的是子类对象，将调用子类的析构函数，然后自动调用基类的析构函数。</li></ol><h2 id="139-什么是动态绑定？"><a href="#139-什么是动态绑定？" class="headerlink" title="139.什么是动态绑定？"></a>139.什么是动态绑定？</h2><p>动态绑定是将一个过程调用与相应代码链接起来的行为。是指与给定的过程调用相关联的代码，只有在运行期才可知的一种绑定，他是多态实现的具体形式。</p><p><strong>C++中的实现原理：</strong><br>C++中，通过基类的引用或指针调用虚函数时，发生动态绑定。引用（或指针）既可以指向基类对象也可以指向派生类对象，这一事实是动态绑定的关键。用引用（或指针）调用的虚函数在运行时确定，被调用的函数是引用（或指针）所指对象的实际类型所定义的。</p><p><strong>虚函数表的实现：</strong><br>C++中动态绑定是通过虚函数实现的。而虚函数是通过一张虚函数表（virtual table）实现的。这个表中记录了虚函数的地址，解决继承、覆盖的问题，保证动态绑定时能够根据对象的实际类型调用正确的函数。</p><p><strong>虚函数表的指针位置：</strong><br>在C++的标准规格说明书中说到，编译器必需要保证虚函数表的指针存在于对象实例中最前面的位置（这是为了保证正确取到虚函数的偏移量）。这意味着我们通过对象实例的地址得到这张虚函数表，然后就可以遍历其中函数指针，并调用相应的函数。</p><h2 id="140-虚函数在什么时候调用？"><a href="#140-虚函数在什么时候调用？" class="headerlink" title="140.虚函数在什么时候调用？"></a>140.虚函数在什么时候调用？</h2><p>虚函数在运行时根据实际对象的类型来确定调用哪个函数，而不是根据指针或引用的类型来确定。当一个虚函数被定义为类的成员函数时，它会被标记为虚函数。</p><p>在调用虚函数时，程序会查找该函数的实际类型，并在运行时调用该类型的实现。这就允许程序在运行时动态地选择执行哪个版本的虚函数，从而实现多态性。虚函数通常与基类指针或引用一起使用，可以实现基类指针或引用调用派生类的函数。</p><h2 id="141-虚函数表的大小"><a href="#141-虚函数表的大小" class="headerlink" title="141.虚函数表的大小"></a>141.虚函数表的大小</h2><p>虚函数表是一个存储虚函数指针的数组，每个类有一个虚函数表，每个对象有一个指向虚函数表的指针。虚函数表的大小取决于类中有多少个虚函数，而对象中的虚函数表指针的大小取决于编译器和操作系统2。一般来说，在32位系统下，指针占4个字节，在64位系统下，指针占8个字节。</p><h2 id="142-C-中哪些函数不能被声明为虚函数？"><a href="#142-C-中哪些函数不能被声明为虚函数？" class="headerlink" title="142.C++ 中哪些函数不能被声明为虚函数？"></a>142.C++ 中哪些函数不能被声明为虚函数？</h2><p><strong>构造函数</strong>：构造函数不能被声明为虚函数。</p><p>因为构造函数是用来创建对象的，而虚函数是根据对象的类型来动态调用的。如果构造函数是虚函数，那么在创建对象时就无法确定调用哪个版本的构造函数，会导致逻辑错误</p><p><strong>友元函数</strong>：友元函数实际上并不属于类的成员函数，所以不能被定义为虚函数</p><p><strong>普通函数</strong>：普通函数只能被重载，不能被重写</p><h2 id="143-为什么虚函数不能是模板函数？"><a href="#143-为什么虚函数不能是模板函数？" class="headerlink" title="143.为什么虚函数不能是模板函数？"></a>143.为什么虚函数不能是模板函数？</h2><p>因为模板函数在编译时会被实例化为多个不同的函数，而虚函数需要在运行时才能确定调用哪个函数。在C++中，虚函数的实现依赖于虚函数表（vtable）和虚函数指针（vptr），而这些在编译时就需要确定下来。因此，虚函数不能是模板函数。</p><h2 id="144-虚函数表既然希望类的所有对象共享为什么不放在全局区？"><a href="#144-虚函数表既然希望类的所有对象共享为什么不放在全局区？" class="headerlink" title="144.虚函数表既然希望类的所有对象共享为什么不放在全局区？"></a>144.虚函数表既然希望类的所有对象共享为什么不放在全局区？</h2><p>虚函数表不能放在全局区，因为<strong>全局区是存放全局变量和静态变量的</strong>，而虚函数表不是变量，而是一组指向类成员函数的指针。如果放在全局区，会导致内存浪费和混乱。</p><p>混乱：<strong>虚函数表是在编译期就确定了大小和内容的</strong>，而全局区是在运行期才分配空间的。如果把虚函数表放在全局区，就需要在运行期动态地为每个类分配空间，并且要保证不同类之间不会发生冲突。这样就增加了程序的复杂度和出错的可能性。</p><h2 id="145-菱形继承"><a href="#145-菱形继承" class="headerlink" title="145.菱形继承"></a>145.菱形继承</h2><p>菱形继承（Diamond Inheritance）是一种多重继承的情况，其中一个派生类同时继承自两个直接或间接共同基类，而这两个基类又继承自同一个共同的基类。这样就形成了一种菱形的继承结构，因此称为”菱形继承”。</p><blockquote><p>假设Person类有一个成员变量_age，Student类的对象中包含了这个 _age 成员，Teacher类的对象中也包含了 _age 成员，但是 Assistant 类依次继承了 Student 和 Teacher类，不考虑其他成员，就最终结果而言，Assistant 类中确实包含了两份 _age 成员。</p></blockquote><blockquote><p><strong>冗余性</strong>：存在重复的数据，比如_age 要存两份<br><strong>&gt;二义性</strong>：如果要访问 _age 成员，是访问 Student 类的 _age，还是访问 Teacher类的_age</p></blockquote><p>解决方法：将两个父类添加成 <code>virtual</code>，相当于爷爷直接拿出指针给孙子</p><blockquote><p>其实就是将 Student 类和 Teacher 类重复的部分，放到一个公共位置，访问的时候，直接访问这块公共位置。</p></blockquote><h2 id="146-volatile-关键字"><a href="#146-volatile-关键字" class="headerlink" title="146.volatile 关键字"></a>146.volatile 关键字</h2><p>在 C++ 中，关键字 volatile 用于声明一个变量是易变的（volatile variable），即该变量可能会在程序中的任意时刻被意外地改变。这意味着，当读取一个易变的变量时，<strong>编译器不会从缓存中读取该变量的值，而是每次都会从内存中重新读取该变量的值</strong>。同样地，当写入一个易变的变量时，编译器也不会将该变量的值存储在缓存中，而是<strong>立即将该变量的值写入内存中</strong>。</p><h2 id="147-一个参数既可以是-const-还可以是-volatile-吗？为什么？"><a href="#147-一个参数既可以是-const-还可以是-volatile-吗？为什么？" class="headerlink" title="147.一个参数既可以是 const 还可以是 volatile 吗？为什么？"></a>147.一个参数既可以是 const 还可以是 volatile 吗？为什么？</h2><p>是的。一个例子是只读的状态寄存器。它是 volatile 因为它可能被意想不到地改变。它是 const 因为程序不应该试图去修改它。</p><p>一个定义为volatile的变量是说这变量可能会被意想不到地改变，这样，编译器就不会去假设这个变量的值了。精确地说就是，优化器在用到这个变量时必须每次都小心地重新读取这个变量的值，而不是使用保存在寄存器里的备份。</p><p>volatile 修饰符告诉 complier 变量值可以以任何不被程序明确指明的方式改变，最常见的例子就是外部端口的值，它的变化可以不用程序内的任何赋值语句就有可能改变的，这种变量就可以用 volatil e来修饰，complier 不会优化掉它。</p><p>const 修饰的变量在程序里面是不能改变的，但是可以被程序外的东西修改，就象上面说的外部端口的值，如果仅仅使用 const，有可能 complier 会优化掉这些变量，加上 volatile 就万无一失了。</p><h2 id="148-一个指针可以是volatile吗？为什么？"><a href="#148-一个指针可以是volatile吗？为什么？" class="headerlink" title="148.一个指针可以是volatile吗？为什么？"></a>148.一个指针可以是volatile吗？为什么？</h2><p>是的。因为指针和普通变量一样，有时也有变化程序的不可控性。</p><p>常见例：子中断服务子程序修改一个指向一个 buffer 的指针时，必须用 volatile 来修饰指针。</p><p><a href="https://blog.csdn.net/qq_41709234/article/details/123028868">一文彻底搞懂volatile用法</a></p><h1 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h1><h2 id="149-什么时候调用拷贝构造函数？"><a href="#149-什么时候调用拷贝构造函数？" class="headerlink" title="149.什么时候调用拷贝构造函数？"></a>149.什么时候调用拷贝构造函数？</h2><ul><li>用已经初始化的对象给另一个初始化的对象赋值</li><li>函数用对象作为返回值</li><li>函数用对象作为参数</li></ul><h2 id="150-析构函数为什么要用虚的？"><a href="#150-析构函数为什么要用虚的？" class="headerlink" title="150.析构函数为什么要用虚的？"></a>150.析构函数为什么要用虚的？</h2><pre><code>A* p = new B;delete p;（A是父类 B是子类）</code></pre><p>如果不定义虚析构 那么删除P只调用A的析构<br>定义为虚析构之后，删除P就会调用AB的析构</p><p>虚析构函数是为了解决父类指针指向子类对象时，释放子类对象的资源时，释放不完全，造成的内存泄漏问题。</p><h2 id="151-为什么用移动构造函数？"><a href="#151-为什么用移动构造函数？" class="headerlink" title="151.为什么用移动构造函数？"></a>151.为什么用移动构造函数？</h2><p>在C++中，当一个对象被复制时，其内部资源通常会被复制，这可能会导致性能问题，特别是在处理大型数据结构时。</p><p>移动语义是指，当一个对象被移动而不是复制时，其内部资源可以被“窃取”，而不需要进行复制操作。移动操作比复制操作更高效，因为它不需要分配新的内存或复制现有的内存。</p><h2 id="152-C-类内是否可以定义引用？"><a href="#152-C-类内是否可以定义引用？" class="headerlink" title="152.C++类内是否可以定义引用？"></a>152.C++类内是否可以定义引用？</h2><p>可以，但是必须使用成员初始化列表为引用变量初始化，构造函数的形参也必须是引用类型，因为引用必须在创建时被初始化，并且不能在其生存期内引用不同的对象。</p><p>C++类内可以定义引用成员变量，但要遵循以下三个规则：</p><ul><li>不能用默认构造函数初始化，必须提供构造函数来初始化引用成员变量。否则会造成引用未初始化错误。</li><li>构造函数的形参也必须是引用类型</li><li>不能在构造函数的函数体赋值（为什么不是说初始化呢？因为所有的成员变量都是在初始化列表中完成的），必须在初始化列表中进行初始化。<strong>构造函数分为初始化和计算两个阶段，前者对应成员初始化链表，后者对应构造函数函数体</strong>。引用必须在初始化阶段，也即在成员初始化链表中完成，否则编译时会报错（引用未初始化）。</li></ul><hr><h1 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h1><h2 id="153-模板类是什么时候实现的？"><a href="#153-模板类是什么时候实现的？" class="headerlink" title="153.模板类是什么时候实现的？"></a>153.模板类是什么时候实现的？</h2><p>模板类的实现不是在程序运行时期间动态生成的，而是在编译阶段根据需要进行实例化和生成对应的代码。这也是为什么在使用模板类时，模板类的声明和定义通常需要放在头文件中，以便编译器在需要的地方进行实例化，并生成相应的代码。</p><h2 id="154-模板的具体化"><a href="#154-模板的具体化" class="headerlink" title="154.模板的具体化"></a>154.模板的具体化</h2><p>当模板使用某种类型类型实例化后生成的类或函数不能满足需要时，可以考虑对模板进行具体化。具体化时可以修改原模板的定义，当使用该类型时，按照具体化后的定义实现，具体化相当于对某种类型进行特殊处理。</p><h2 id="155-模板的声明和定义为什么不能分开写，要想分开写该怎么做？"><a href="#155-模板的声明和定义为什么不能分开写，要想分开写该怎么做？" class="headerlink" title="155.模板的声明和定义为什么不能分开写，要想分开写该怎么做？"></a>155.模板的声明和定义为什么不能分开写，要想分开写该怎么做？</h2><p>模板的声明和定义不能分开写的原因是，编译器在编译模板时需要知道模板的完整定义，才能根据具体的类型参数生成相应的代码。如果只有声明而没有定义，编译器就无法生成正确的代码，链接时就会出现未定义引用的错误。</p><p>方法一：一种是在声明文件中包含定义文件；<br>这样做的好处是可以保持声明和定义的分离，但缺点是每次修改定义文件都需要重新编译所有包含声明文件的源文件。</p><pre><code>// template.cpptemplate &lt;typename T&gt;void swap(T&amp; a, T&amp; b) &#123;  T temp = a;  a = b;  b = temp;&#125;</code></pre><p>法二：在定义文件中显式实例化需要用到的类型参数；这样做的好处是可以避免重复编译和代码膨胀，但缺点是需要提前知道所有可能用到的类型参数，并且每增加一个类型参数都需要修改定义文件。</p><pre><code>// template.cpptemplate &lt;typename T&gt;void swap(T&amp; a, T&amp; b) &#123;  T temp = a;  a = b;  b = temp;&#125;// explicit instantiation for int and double typestemplate void swap&lt;int&gt;(int&amp;, int&amp;);template void swap&lt;double&gt;(double&amp;, double&amp;);</code></pre><h2 id="156-模板的特化，全特化，偏特化"><a href="#156-模板的特化，全特化，偏特化" class="headerlink" title="156.模板的特化，全特化，偏特化"></a>156.模板的特化，全特化，偏特化</h2><ul><li><strong>模板特化</strong>是指为某些特定类型提供不同于通用模板的具体实现</li><li><strong>全特化</strong>是指为所有的模板参数都指定具体类型或值的情况</li><li><strong>偏特化</strong>是指只为部分的模板参数指定具体类型或值，或者限制参数的范围。偏特化只适用于类模板，不适用于函数模板</li></ul><h2 id="157-模板在编译时生成的代码是否会相同，生成的相同的代码如何处理？"><a href="#157-模板在编译时生成的代码是否会相同，生成的相同的代码如何处理？" class="headerlink" title="157.模板在编译时生成的代码是否会相同，生成的相同的代码如何处理？"></a>157.模板在编译时生成的代码是否会相同，生成的相同的代码如何处理？</h2><ul><li>一种情况是，如果模板的定义和声明都放在头文件中，并且在多个源文件中被包含和使用，那么编译器会为每个源文件生成相同的模板实例化代码。这样会导致目标文件中存在重复的代码段，增加了目标文件的大小，并且可能引起链接错误。为了避免这种情况，可以使用 extern 关键字来声明一个外部模板，在一个源文件中显式地实例化该模板，并且在其他源文件中只引用该实例化。</li><li>另一种情况是，如果模板的定义放在一个源文件中，并且在其他源文件中被包含和使用，那么编译器会根据不同的类型参数生成不同的模板实例化代码。这样可以避免重复的代码段，但是<strong>也可能导致链接错误，因为其他源文件无法找到该源文件中定义的模板</strong>。为了避免这种情况，可以将模板的声明放在头文件中，并且在需要使用该模板的源文件中包含该头文件。</li></ul><h2 id="158-C-构造函数调用顺序"><a href="#158-C-构造函数调用顺序" class="headerlink" title="158.C++构造函数调用顺序"></a>158.C++构造函数调用顺序</h2><ol><li><pre><code>创建派生类的对象，基类的构造函数优先被调用（也优先于派生类里的成员类）；</code></pre></li><li>如果类里面有成员类，成员类的构造函数优先被调用；(也优先于该类本身的构造函数）</li><li><pre><code>基类构造函数如果有多个基类，则构造函数的调用顺序是某类在类派生表中出现的顺序而不是它们在成员初始化表中的顺序；</code></pre></li><li><pre><code>成员类对象构造函数如果有多个成员类对象，则构造函数的调用顺序是对象在类中被声明的顺序而不是它们出现在成员初始化表中的顺序；</code></pre></li><li><pre><code>派生类构造函数，作为一般规则派生类构造函数应该不能直接向一个基类数据成员赋值而是把值传递给适当的基类构造函数,否则两个类的实现变成紧耦合的（tightly coupled）将更加难于正确地修改或扩展基类的实现。（基类设计者的责任是提供一组适当的基类构造函数）</code></pre></li></ol><p>综上可以得出，初始化顺序：</p><p>父类构造函数–&gt;成员类对象构造函数–&gt;自身构造函数</p><hr><h1 id="STL"><a href="#STL" class="headerlink" title="STL"></a>STL</h1><h2 id="159-vector-的第二个模板形参？"><a href="#159-vector-的第二个模板形参？" class="headerlink" title="159.vector 的第二个模板形参？"></a>159.vector 的第二个模板形参？</h2><p>vector 的第二个模板形参是分配器（allocator），用于分配和管理 vector 内部存储元素的内存。分配器可以控制内存分配的策略，例如内存池等。如果不指定分配器，默认使用 std::allocator。</p><p>分配器通常是一个模板类，提供了 allocate 和 deallocate 等成员函数来分配和释放内存。在 vector 内部，使用分配器来分配和释放存储元素的内存，可以方便地替换默认的内存分配器，实现自定义的内存分配策略。</p><blockquote><p>vecotr 特点：顺序序列、动态数组、尾删有较佳性能</p></blockquote><h2 id="160-vector-调用-resize-的时候，如果是元素是一个类，会不会调用这些函数的析构函数？"><a href="#160-vector-调用-resize-的时候，如果是元素是一个类，会不会调用这些函数的析构函数？" class="headerlink" title="160.vector 调用 resize 的时候，如果是元素是一个类，会不会调用这些函数的析构函数？"></a>160.vector 调用 resize 的时候，如果是元素是一个类，会不会调用这些函数的析构函数？</h2><p>如果调用 resize 函数使得 vector 的大小变小了，那么后面的元素会被析构掉，也就是会调用元素类的析构函数。如果调用 resize 函数使得 vector 的大小变大了，那么新添加的元素会调用元素类的默认构造函数进行初始化，而不会调用析构函数。</p><h2 id="161-使用Vector需要注意什么？"><a href="#161-使用Vector需要注意什么？" class="headerlink" title="161.使用Vector需要注意什么？"></a>161.使用Vector需要注意什么？</h2><ul><li><p>为避免频繁的扩容操作，可以使用 reserve() 方法在插入元素之前预留一定的空间，以提高性能</p></li><li><p>在使用 vector 进行大量元素操作时，可以使用 emplace_back() 方法而不是 push_back() 方法，以避免元素拷贝的开销</p></li><li><p>在需要删除元素时，可以使用 erase() 方法进行删除。但是，需要注意的是，如果要删除多个元素，应该首先对要删除的元素进行排序，并使用 erase() 方法一次性删除，以避免多次删除操作</p></li></ul><blockquote><p>void reserve( size_type new_cap );   &#x2F;&#x2F;不改变vector的大小size，改变vector的容量capacity</p></blockquote><h2 id="162-如果扩容时会引发自定义类型挨个复制构造，C-有什么机制来避免这一点？"><a href="#162-如果扩容时会引发自定义类型挨个复制构造，C-有什么机制来避免这一点？" class="headerlink" title="162.如果扩容时会引发自定义类型挨个复制构造，C++有什么机制来避免这一点？"></a>162.如果扩容时会引发自定义类型挨个复制构造，C++有什么机制来避免这一点？</h2><p>在进行 vector 扩容时，如果存储的是自定义类型，会挨个复制构造元素，可能会造成性能问题。为了避免这一点，可以使用移动语义来优化。</p><p>在 C++11 引入的移动语义中，我们可以通过 std::move() 函数将一个对象转化为右值引用，这样就可以在元素的拷贝构造函数中实现移动语义，将对象的资源所有权从一个对象转移到另一个对象中，而不是进行深拷贝。</p><h2 id="163-各种容器的特点"><a href="#163-各种容器的特点" class="headerlink" title="163.各种容器的特点"></a>163.各种容器的特点</h2><p>deque 特性：</p><ul><li>双向队列</li><li>在两端增删元素有较佳性能</li></ul><p>list 特性：</p><ul><li>双向链表</li><li>不支持随机存取</li></ul><p>set 特性：</p><ul><li>不允许相同元素</li><li>自动排序</li><li>原理：红黑树</li></ul><p>map 特性：</p><ul><li>first和second，并且根据first排序</li><li>实现原理：红黑树</li><li>map不允许容器中有重复的key值元素</li></ul><p>红黑树的性质，各种操作时间复杂度：</p><ul><li>自动排序，稳定</li><li>查找，插入，删除都是O（logn）</li></ul><p>unordered_map</p><ul><li>umap底层是哈希表</li></ul><h2 id="164-哈希表跟红黑树的比较，优缺点、适用场合，各种操作的时空复杂度"><a href="#164-哈希表跟红黑树的比较，优缺点、适用场合，各种操作的时空复杂度" class="headerlink" title="164.哈希表跟红黑树的比较，优缺点、适用场合，各种操作的时空复杂度"></a>164.哈希表跟红黑树的比较，优缺点、适用场合，各种操作的时空复杂度</h2><p>哈希表适合小数据，查找插入删除最好都是O(1)，最坏O(n)，缺点是容易发生哈希冲突，设计哈希函数也比较困难<br>红黑树适合大数据集，但是代码实现较为复杂</p><h2 id="165-空间配置器？"><a href="#165-空间配置器？" class="headerlink" title="165.空间配置器？"></a>165.空间配置器？</h2><p>在C++ STL中，空间配置器便是用来实现内存空间(一般是内存，也可以是硬盘等空间)分配的工具，他与容器联系紧密，每一种容器的空间分配都是通过空间分配器alloctor实现的。</p><p>关于内存空间的配置与释放，SGI STL采用了两级配置器：一级配置器主要是考虑大块内存空间，利用 malloc 和 free 实现；二级配置器主要是考虑小块内存空间而设计的（为了最大化解决内存碎片问题，进而提升效率），采用链表 free_list 来维护内存池（memory pool），free_list 通过 union 结构实现，空闲的内存块互相挂接在一块，内存块一旦被使用，则被从链表中剔除，易于维护。</p><h2 id="166-迭代器用过吗？什么时候会失效？"><a href="#166-迭代器用过吗？什么时候会失效？" class="headerlink" title="166.迭代器用过吗？什么时候会失效？"></a>166.迭代器用过吗？什么时候会失效？</h2><p><strong>顺序容器</strong>使用删除会使后面的迭代器失效（自动往前进一，导致地址全变，所以会失效），解决办法：it&#x3D;earse(it)，即返回删除元素下一个的迭代器；<br><strong>关联容器</strong> map 由于内部是红黑树，使用 erase 不会失效，但是需要记录一下下一个元素的迭代器，list 使用上面两种方法都行</p><h2 id="167-迭代器和指针的区别？"><a href="#167-迭代器和指针的区别？" class="headerlink" title="167.迭代器和指针的区别？"></a>167.迭代器和指针的区别？</h2><p>迭代器不是指针，是类模板，表现的像指针。他只是模拟了指针的一些功能，重载了指针的一些操作符，–&gt;、++、–等。迭代器封装了指针，是一个<strong>“可遍历STL（ Standard Template Library）容器内全部或部分元素”</strong>的对象，本质是封装了原生指针，是指针概念的一种提升，提供了比指针更高级的行为，相当于一种智能指针，他可以根据不同类型的数据结构来实现不同的++，–等操作。</p><p>迭代器相对于指针的优点在于，它提供了一些安全性和抽象性的保证。例如，如果你使用一个指向数组元素的指针，你可以对它进行任何操作，包括越界访问和非法修改等操作，这可能会导致内存错误和程序崩溃。而如果你使用一个vector迭代器，则可以避免这些问题，因为<strong>迭代器会自动检查越界和非法操作，并在出错时抛出异常或者进行其他处理</strong>。</p><h2 id="168-说说-STL-中-resize-和-reserve-的区别？"><a href="#168-说说-STL-中-resize-和-reserve-的区别？" class="headerlink" title="168.说说 STL 中 resize 和 reserve 的区别？"></a>168.说说 STL 中 resize 和 reserve 的区别？</h2><p>capacity：该值在容器初始化时赋值，指的是容器能够容纳的最大的元素的个数。还不能通过下标等访问，因为此时容器中还没有创建任何对象。</p><p>size：指的是此时容器中实际的元素个数。可以通过下标访问 0-(size-1) 范围内的对象。</p><p>resize 既修改 capacity 大小，也修改 size 大小；<br>reserve 只修改 capcaity 大小。</p><p>resize 既分配了空间，也创建了对象；reserve 表示容器预留空间，但并不是真正的创建对象，需要通过 insert() 或 push_back() 等创建对象。</p><h2 id="169-STL-容器动态链接可能产生的问题"><a href="#169-STL-容器动态链接可能产生的问题" class="headerlink" title="169.STL 容器动态链接可能产生的问题?"></a>169.STL 容器动态链接可能产生的问题?</h2><p>给动态库函数传递容器的对象本身，则会出现内存堆栈破坏的问题。</p><p><strong>产生问题的原因</strong>：容器和动态链接库相互支持不够好，动态链接库函数中使用容器时，参数中只能传递容器的引用，并且要保证容器的大小不能超出初始大小，否则导致容器自动重新分配，就会出现内存堆栈破坏问题。</p><hr><h1 id="新特性"><a href="#新特性" class="headerlink" title="新特性"></a>新特性</h1><h2 id="170-智能指针"><a href="#170-智能指针" class="headerlink" title="170.智能指针"></a>170.智能指针</h2><p><code>std::shared_ptr</code> 是一种共享式智能指针，它可以让多个 <code>shared_ptr</code> 实例同时拥有同一个内存资源。<code>shared_ptr</code> 内部维护了一个计数器，记录当前有多少个<code>shared_ptr </code>实例共享同一块内存。只有当计数器变为 <code>0</code> 时，才会自动释放内存。因此，<code>shared_ptr</code> 可以避免多个指针指向同一块内存时出现的内存泄漏和悬空指针等问题。</p><p><code>std::unique_ptr</code> 是一种独占式智能指针，它可以保证指向的内存只被一个 <code>unique_ptr</code> 实例所拥有。当 <code>unique_ptr</code> 被销毁时，它所拥有的内存也会被自动释放。<br><code>unique_ptr</code> 还支持移动语义，因此可以通过 <code>std::move</code> 来转移拥有权。</p><blockquote><p>使用 release() 方法来移交指向的对象，release方法将一个对象的内存的管理权限丢弃，一般会交给另一个对象。</p></blockquote><p><code>weak_ptr</code> 用来解决 <code>shared_prt</code> 相互引用冲突的结果。</p><blockquote><p><strong>解决循环引用</strong>：当两个或多个对象相互持有对方的 <code>shared_ptr</code>，会形成循环引用，导致对象无法释放。通过将其中一个对象的指针设置为 <code>weak_ptr</code>，而不是 <code>shared_ptr</code>，可以打破循环引用，避免内存泄漏。</p></blockquote><p><strong>安全地访问对象</strong>：在需要访问被 <code>shared_ptr</code> 管理的对象时，可以通过 <code>weak_ptr</code> 的 <code>lock()</code> 方法尝试转换为 <code>shared_ptr</code>，如果对象仍然存在，则返回一个有效的 <code>shared_ptr</code>，否则返回一个空指针。</p><blockquote></blockquote><p><strong>提高性能</strong>：<code>weak_ptr</code> 不会增加对象的引用计数，因此不会影响对象的生命周期，也不会阻止对象的销毁。这样可以更灵活地管理对象的生命周期，提高程序性能。</p><h2 id="171-怎么知道weak-ptr失效了没"><a href="#171-怎么知道weak-ptr失效了没" class="headerlink" title="171.怎么知道weak_ptr失效了没?"></a>171.怎么知道weak_ptr失效了没?</h2><p>可以通过<code>expired()</code>函数来判断一个 <code>weak_ptr</code> 是否已经失效，如果<code>expired()</code>返回 <code>true</code>，则表示它指向的对象已经被销毁或释放了。另外，使用 <code>lock()</code> 函数获取 <code>weak_ptr</code> 指向的对象时，如果返回的是一个空的 <code>shared_ptr</code>，也可以判断 <code>weak_ptr</code> 是否已经失效。</p><blockquote><p><code>bool expired() const noexcept; </code>函数返回 <code>weak_ptr</code> 对象是否是空的，或是它所属的所有者组中不再有 <code>shared_ptr</code>。此函数与 <code>use_count() == 0</code> 意义相同。<br><code>shared_ptr&lt;element_type&gt; lock() const noexcept; </code>函数返回一个 <code>shared_ptr</code>，其中包含 <code>weak_ptr</code> 对象在未过期时保留的信息。如果 <code>weak_ptr</code> 对象已过期（包括它是否为空），该函数将返回一个空的 <code>shared_ptr</code>（就像默认构造的一样）。</p></blockquote><p><a href="https://blog.csdn.net/tianyexing2008/article/details/131249712?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-4-131249712-blog-120806965.235%5Ev43%5Epc_blog_bottom_relevance_base8&spm=1001.2101.3001.4242.3&utm_relevant_index=7">weak_ptr 智能指针的使用</a></p><hr><h1 id="lambda表达式"><a href="#lambda表达式" class="headerlink" title="lambda表达式"></a>lambda表达式</h1><p><strong>lambda语法：</strong> <code>[capture] (parameters) mutable -&gt;return-type&#123;statement&#125;</code></p><p><strong>[capture]含义：</strong></p><ul><li><code>[]</code>。没有任何函数对象参数。</li><li><code>[=]</code>。函数体内可以使用 Lambda 所在范围内所有可见的局部变量（包括 Lambda 所在类的this），并且是值传递方式（相当于编译器自动为我们按值传递了所有局部变量）。</li><li><code>[&amp;]</code>。函数体内可以使用 Lambda 所在范围内所有可见的局部变量（包括 Lambda 所在类的this），并且是引用传递方式（相当于是编译器自动为我们按引用传递了所有局部变量）。</li><li><code>[this]</code>。函数体内可以使用 Lambda 所在类中的成员变量。</li><li><code>[a]</code>。将 a 按值进行传递。按值进行传递时，函数体内不能修改传递进来的 a 的拷贝，因为默认情况下函数是 const 的，要修改传递进来的拷贝，可以添加 mutable 修饰符。</li><li><code>[&amp;a]</code>。将 a 按引用进行传递。</li></ul><p><strong>（parameters）含义：</strong></p><p>标识重载的 () 操作符的参数，没有参数时，这部分可以省略。参数可以通过按值（如: (a, b)）和按引用 (如: (&amp;a, &amp;b))<br>两种方式进行传递。</p><p><code>[](int x, int y) -&gt; int &#123; return x + y; &#125;</code> 圆括号 “()” 表示 Lambda 表达式的参数列表，可以包含零个或多个参数。在这个例子中，Lambda表达式有两个参数，分别是一个整数 “x” 和一个整数 “y”</p><p><strong>mutable 或 exception 声明：</strong></p><p>这部分可以省略。按值传递函数对象参数时，加上 mutable 修饰符后，可以修改传递进来的拷贝（注意是能修改拷贝，而不是值本身）。<br>exception 声明用于指定函数抛出的异常，如抛出整数类型的异常，可以使用 throw(int)。</p><p><strong>-&gt;return-type-&gt;</strong></p><p>返回值类型：标识函数返回值的类型，当返回值为 void，或者函数体中只有一处 return<br>的地方（此时编译器可以自动推断出返回值类型）时，这部分可以省略</p><p><strong>{statement}{函数体}</strong></p><p>标识函数的实现，这部分不能省略，但函数体可以为空。</p><h2 id="172-Lambda-表达式如何对应到函数对象？"><a href="#172-Lambda-表达式如何对应到函数对象？" class="headerlink" title="172.Lambda 表达式如何对应到函数对象？"></a>172.Lambda 表达式如何对应到函数对象？</h2><p>当定义一个 Lambda 表达式时，编译器会生成一个与 Lambda 表达式对应的新的（未命名的）函数对象类型和该类型的一个对象。这个函数对象可以重载函数调用运算符()，从而具有类似函数的行为。</p><h2 id="173-圆括号传参数是如何实现的？"><a href="#173-圆括号传参数是如何实现的？" class="headerlink" title="173.圆括号传参数是如何实现的？"></a>173.圆括号传参数是如何实现的？</h2><p>圆括号传参数是通过函数调用运算符()来实现的。</p><p>当你使用圆括号传递参数给一个 lambda 表达式时，实际上是调用了它生成的函数对象的函数调用运算符()，并将参数传递给它。</p><p>函数调用运算符()会根据 lambda 表达式的定义来执行相应的代码，并返回一个值（如果有的话）。</p><p>所以，你<strong>可以把圆括号传参数看作是一种调用函数对象的方式</strong>，它让你不需要知道函数对象的名字或者类型就可以使用它。</p><h2 id="174-方括号捕获外部变量（闭包）是如何实现的"><a href="#174-方括号捕获外部变量（闭包）是如何实现的" class="headerlink" title="174.方括号捕获外部变量（闭包）是如何实现的?"></a>174.方括号捕获外部变量（闭包）是如何实现的?</h2><p><strong>闭包</strong>是一个捕获了全局上下文的常量或者变量的函数，通俗来讲，闭包可以是常量也可以是函数</p><p>方括号捕获外部变量（闭包）是通过<strong>将外部变量作为函数对象的成员</strong>来实现的。</p><p>当你在方括号中指定一个外部变量时，编译器会为你生成一个函数对象类型，它包含了这个外部变量作为它的一个成员。</p><p>当你创建一个函数对象时，这个成员会被初始化为外部变量的值或者引用，这取决于你是用<code>=</code>还是<code>&amp;</code>来捕获它。</p><p>当你调用函数对象时，这个成员就可以在 lambda 表达式中使用，就像一个普通的局部变量一样。</p><p>所以，你可以把方括号捕获外部变量看作是一种创建闭包的语法糖，它让你不需要显式地定义一个类或者接口来保存外部变量的状态。</p><ul><li><p><strong>值捕获（capture by value）</strong>：使用 “&#x3D;”<br>-将外部变量按值进行捕获。Lambda表达式会在创建时将外部变量的值复制一份到闭包中</p></li><li><p><strong>引用捕获（capture by reference）</strong>：使用 “&amp;”。将外部变量按引用进行捕获。Lambda表达式会在创建时绑定到外部变量的内存地址，以便在Lambda表达式中修改变量的值</p></li><li><p><strong>隐式捕获</strong> ：使用 “[]” 作为空方括号，表示隐式捕获所有在Lambda表达式中使用的外部变量。在Lambda表达式中使用的变量会被自动按值进行捕获。</p><p>  对于值捕获和隐式捕获，Lambda表达式在创建时会复制一份外部变量的值到闭包中，如果在Lambda表达式中修改闭包中的变量值，不会影响外部变量的值。而对于引用捕获，Lambda表达式会直接操作外部变量，可以改变其值。</p></li></ul><hr><h1 id="右值引用"><a href="#右值引用" class="headerlink" title="右值引用"></a>右值引用</h1><p>右值引用是C++11引入的一种引用类型，它用于表示临时对象和即将销毁的对象。</p><p><strong>左值</strong>是指可以出现在赋值运算符左边的表达式，也就是<em><strong>具有内存地址且可被取地址的表达式</strong></em>。通常来说，变量、对象以及可以引用的表达式都是左值。左值表示的是一个具体的内存位置，可以对其进行读取和写入操作。</p><p><strong>右值</strong>是指不能出现在赋值运算符左边的表达式，通常是<em><strong>临时性的、不具有明确内存地址的值</strong></em>。字面常量、临时对象、函数返回值等都属于右值。右值表示的是一个临时的值，不能被取地址。</p><p><strong>左值引用</strong>是 C++ 中最常见的引用类型，用于绑定到左值表达式上。左值引用通过 &amp; 符号表示。</p><p><strong>右值引用</strong>是 C++11 引入的一个重要特性，用于绑定到临时对象或右值表达式上，以支持移动语义和完美转发。右值引用通过 &amp;&amp; 符号表示。</p><pre><code>int num = 10;//int &amp;&amp; a = num;  //右值引用不能初始化为左值int &amp;&amp; a = 10;</code></pre><p>和常量左值引用不同的是，右值引用还可以对右值进行修改。例如：</p><pre><code>int&amp;&amp; a = 10;a = 100;std::cout &lt;&lt; a &lt;&lt; std::endl;//输出100</code></pre><p>右值引用的具体案例包括移动语义和完美转发</p><h2 id="175-移动语义？"><a href="#175-移动语义？" class="headerlink" title="175.移动语义？"></a>175.移动语义？</h2><p>移动语义是 C++11引入的重要特性，旨在<strong>提高资源管理的效率和性能</strong>。</p><p>在传统的拷贝操作中，对象的资源是通过复制（拷贝构造函数）的方式从一个对象传递到另一个对象，这会涉及到深拷贝操作，即将资源完全复制一份，导致了额外的开销。</p><p>而移动语义则引入了右值引用和移动构造函数（移动赋值运算符），允许对象的资源在不需要进行深拷贝的情况下进行高效地转移。简单的理解，<strong>移动语义指的就是将其他对象（通常是临时对象）拥有的内存资源“移为已用”</strong>。换句话说，就是以浅拷贝的方式复制指针，然后将原指针置为空指针。<strong>移动构造函数就是通过移动语义的方式来初始化对象的。</strong></p><pre><code>std::vector&lt;int&gt; vec1 = &#123;1, 2, 3&#125;;std::vector&lt;int&gt; vec2 = std::move(vec1);</code></pre><h2 id="176-如何将左值强制转换为右值？"><a href="#176-如何将左值强制转换为右值？" class="headerlink" title="176.如何将左值强制转换为右值？"></a>176.如何将左值强制转换为右值？</h2><p>move函数</p><pre><code>int x = 10;int&amp;&amp; r = move(x);   //将左值强制转换为右值</code></pre><h2 id="177-移动构造函数和拷贝构造函数的区别？"><a href="#177-移动构造函数和拷贝构造函数的区别？" class="headerlink" title="177.移动构造函数和拷贝构造函数的区别？"></a>177.移动构造函数和拷贝构造函数的区别？</h2><ul><li>拷贝构造函数用于创建一个新对象，并将其初始化为<strong>已存在的对象的副本</strong>。这个过程通常涉及到<strong>内存的分配和数据的复制</strong>，因此它可能比较昂贵。</li><li>移动构造函数用于创建一个新对象，并将其初始化为<strong>另一个对象的资源所有权的转移</strong>。这个过程通常涉及到<strong>指针的复制</strong>，而不是数据的复制，因此它通常比拷贝构造函数更加高效。移动构造函数通常会使用右值引用来接受一个临时对象或者一个即将被销毁的对象，并将其资源所有权转移到新对象中。</li></ul><h2 id="178-转发和完美转发？"><a href="#178-转发和完美转发？" class="headerlink" title="178.转发和完美转发？"></a>178.转发和完美转发？</h2><p>转发是指在函数中将参数按照原始的类型和值，转发给另一个函数。</p><p><strong>常规转发</strong> 是指将参数通过传值或引用的方式传递给另一个函数，这是C++中的传参方式。<br>但是在传递参数时，会存在一些问题。例如，当我们想把一个右值参数传递给一个函数时，我们可能会遇到编译器错误。另一个例子是当我们要将一个右值参数转发给一个函数时，但是我们不知道该使用传值还是传引用，因为这个决定取决于被调用的函数的定义。为了解决这些问题，C++11 引入了完美转发。</p><p>在常规转发中，参数被传递给了被调用函数，但是它们的类型都是引用类型，因此<strong>在函数内部处理时，不会进行任何类型转换</strong>。也就是说，<strong>如果我们传递给常规转发的参数是一个左值，那么被调用函数内部处理时，它们依然是左值引用；如果我们传递的是一个右值，那么它们依然是右值引用</strong>。这样可能会导致一些效率问题，比如如果被调用函数需要将参数进行复制，那么这个过程可能会比较耗时。</p><pre><code>//错误案例void func(int&amp;&amp; x) &#123;    std::cout &lt;&lt; &quot;传递右值参数：&quot; &lt;&lt; x &lt;&lt; std::endl;&#125;template &lt;typename T&gt;void wrapper(T&amp;&amp; arg) &#123;    func(arg);  // 尝试将通用引用参数传递给接受右值引用的函数，会导致编译错误&#125;int main() &#123;    int value = 42;    wrapper(std::move(value));  // 将左值转换为右值传递给 wrapper    return 0;&#125;</code></pre><p><strong>普通的引用传递无法正确地将右值参数传递给接受右值引用的函数</strong>，这种情况下需要使用完美转发来解决。</p><p><strong>完美转发</strong> 是指将参数以原始的类型和值传递给另一个函数，并保留其右值或左值特性。<br>这可以通过使用转发引用（forwarding reference）和 std::forward 函数来实现。<strong>转发引用是一种通用引用，它可以引用任何类型的值，并且可以保留值的右值或左值特性。</strong> 当我们使用转发引用作为函数的参数时，我们可以在函数内部使用 <code>std::forward</code> 来将参数转发给另一个函数，以保留参数的右值或左值特性。</p><ul><li>必须使用转发引用作为参数类型。</li><li>必须使用 std::forward 函数进行转发</li><li>被转发的参数必须是右值或左值引用。</li></ul><p>在完美转发中，我们使用了转发引用 <code>T&amp;&amp;</code>，并在函数内部使用了 <code>std::forward</code> 函数来进行类型转换。这样可以保留参数的原有类型特性，使得被调用函数内部处理时，参数的类型会根据传递给它的参数类型进行调整，从而避免了一些不必要的类型转换操作。此外，通过完美转发，我们还可以保留参数的右值特性，避免了一些额外的复制操作，从而提高了代码的效率。</p><pre><code>void func(int&amp; x) &#123;    std::cout &lt;&lt; &quot;传引用：&quot; &lt;&lt; x &lt;&lt; std::endl;&#125;template &lt;typename T&gt;void wrapper(T&amp;&amp; arg) &#123;    func(std::forward&lt;T&gt;(arg));  // 使用 std::forward 进行完美转发&#125;int main() &#123;    int value = 42;    wrapper(value);  // 正确地将左值参数传递给 wrapper，然后再传递给 func    return 0;&#125;</code></pre><hr><h1 id="Static-关键字"><a href="#Static-关键字" class="headerlink" title="Static 关键字"></a>Static 关键字</h1><p><strong>面向过程</strong></p><p><strong>静态全局变量</strong>：静态全局变量在声明它的整个文件中都是可见的，而在文件之外是不可见的；（作用域是整个文件）变量的生存周期存在于整个程序运行期间。</p><p><strong>静态局部变量</strong>：内存存放在程序的全局数据区中，静态局部变量在程序执行到该对象声明时，会被首次初始化。其后运行到该对象的声明时，不会再次初始化（只会被初始化一次），变量的生存周期存在于整个程序运行期间。</p><blockquote><p>无论是静态全局变量还是静态局部变量都存放在全局区</p></blockquote><p><strong>静态函数（主要目的确定作用域）</strong>：作用域只在声明它的文件当中，不能被其他文件引用，其他文件可以定义同名的全局函数，其他文件想要调用本文件的静态函数，需要显式的调用 extern 关键字修饰其声明。</p><p><strong>面向对象</strong></p><p><strong>静态成员变量</strong>：用于修饰 class 的数据成员，即所谓“静态成员”。这种数据成员的生存期大于 class 的对象（实体 instance）。静态数据成员是每个 class 有一份，普通数据成员是每个 instance 有一份，因此静态数据成员也叫做类变量，而普通数据成员也叫做实例变量。</p><blockquote><p>诞生比构造函数早，在类声明的时候就产生了；<br>静态数据成员必须显式的初始化分配内存，在其包含类没有任何实例化之前已经有内存分配；</p></blockquote><p>静态数据成员与其他成员一样，遵从<code>public,protected,private</code>的访问规则；静态数据成员内存存储在全局数据区，只随着进程的消亡而消亡。</p><p>静态数据成员不进入程序全局命名空间，不会与其他全局名称的同名同类型变量冲突，静态数据成员可以实现C++的封装特性，由于其遵守类的访问权限规则，所以相比全局变量更加灵活；</p><p><strong>静态成员函数</strong>：静态成员函数不能访问非静态(包括成员函数和数据成员)，但是非静态可以访问静态。</p><p>在没有实例化的类对象的条件下可以调用类的静态成员函数；<br><strong>静态成员函数中没有隐含的 this 指针，所以静态成员函数不可以操作类中的非静态成员</strong>（类的非静态成员是在类实例化后存在的，而类的成员函数可以在类没有实例化的时候调用，故不能操作类的非静态成员）；</p><p><strong>初始化</strong></p><p>对于C语言的全局和静态变量，初始化发生在任何代码执行之前，属于编译期初始化。</p><p>而C++标准规定：全局或静态对象当且仅当对象首次用到时才进行构造（静态全局和静态局部）。<br>然而，静态成员变量与静态局部变量和全局变量不同，它们必须在类的外部进行初始化，并且在程序开始执行之前就已经被分配内存并初始化了。</p><hr><h1 id="C-编译过程"><a href="#C-编译过程" class="headerlink" title="C++ 编译过程"></a>C++ 编译过程</h1><ul><li>预编译：在预处理阶段，预处理器会处理以#开头的预处理指令，比如#include、宏定义等。预处理器会展开头文件，替换宏定义，并进行条件编译等操作，生成一个被预处理后的源文件。</li><li>编译：编译阶段是将预处理后的源文件翻译成汇编代码的过程。编译器会对源代码进行词法分析、语法分析、语义分析和优化，最终生成相应的汇编代码。</li><li>汇编：汇编阶段将上一步生成的汇编代码翻译成目标文件。汇编器会将汇编代码转换成机器指令，生成一个二进制目标文件（.obj 文件或 .o 文件）。</li><li>链接：链接阶段是将多个目标文件和库文件合并成一个可执行文件的过程。链接器会解析目标文件之间的引用关系，填充地址空间，解决符号重定位，并将它们合并成一个可执行文件（.exe 文件或可执行程序）。</li></ul><p><strong>动态链接和静态链接</strong></p><p><strong>静态</strong>：连接的时候就把需要的函数或者过程放进了可执行文件中，即使静态库删除了依旧可以运行；</p><p><strong>动态</strong>：是在链接的时候没有把调用的函数代码链接进去，而是在执行的过程中，再去找要链接的函数，生成的可执行文件中没有函数代码，动态库删除就找不到函数了。</p><hr><h1 id="内联函数"><a href="#内联函数" class="headerlink" title="内联函数"></a>内联函数</h1><p>如果函数是内联的，编译器在编译时，会把内联函数的实现替换到每个调用内联函数的地方，可以与宏函数作类比，但<strong>宏函数不会进行类型检查</strong>。</p><h2 id="179-内联函数的意义？"><a href="#179-内联函数的意义？" class="headerlink" title="179. 内联函数的意义？"></a>179. 内联函数的意义？</h2><p>引入内联函数主要是解决一些频繁调用的小函数消耗大量空间的问题。</p><p>通常情况下，在调用函数时，程序会将控制权从调用程序处转移到被调用函数处，在这个过程中，传递参数、寄存器操作、返回值等会消耗额外的时间和内存，如果调用的函数代码量很少，也许转移到调用函数的时间比函数执行的时间更长。</p><h2 id="180-哪些不适合作为内联函数？"><a href="#180-哪些不适合作为内联函数？" class="headerlink" title="180.哪些不适合作为内联函数？"></a>180.哪些不适合作为内联函数？</h2><ol><li>递归调用本身的函数</li><li>包含复杂语句的函数，例如：for、while、switch 等；</li><li>函数包含静态变量（内联函数的定义和调用是在编译期进行的，而不是在运行期。编译器会将内联函数的代码直接嵌入到调用它的地方，从而避免了函数调用的开销。但是，这也意味着每次调用内联函数时，都会生成一份新的函数代码。<br><strong>如果内联函数中有静态变量，那么每次生成新的函数代码时，也会生成新的静态变量。这样就会导致多个静态变量共存于程序中，并且互相独立，无法保持一致性</strong>）；</li></ol><h2 id="181-使用内联的缺点？"><a href="#181-使用内联的缺点？" class="headerlink" title="181.使用内联的缺点？"></a>181.使用内联的缺点？</h2><p>如果使用很多内联函数，生成的二进制文件会变大；</p><p>编译的时间会增加，因为每次内联函数有修改，就需要重新编译代码。</p><p>所以，并不是所有函数都要声明为内联函数，需要视具体情况而定。</p><h2 id="182-内联函数和宏的区别"><a href="#182-内联函数和宏的区别" class="headerlink" title="182. 内联函数和宏的区别?"></a>182. 内联函数和宏的区别?</h2><p><strong>宏函数是在预编译的时候把所有的宏名用宏体来替换</strong>，简单的说就是字符串替换 ；而<strong>内联函数则是在编译的时候进行代码插入</strong>，编译器会在每处调用内联函数的地方直接把内联函数的内容展开，这样可以省去函数的调用的开销，提高效率</p><p><strong>宏定义是没有类型检查的</strong>，无论对还是错都是直接替换；而内联函数在编译的时候会进行类型检查，内联函数满足函数的性质，比如有返回值、参数列表等</p><hr><h1 id="程序启动的过程"><a href="#程序启动的过程" class="headerlink" title="程序启动的过程?"></a>程序启动的过程?</h1><ol><li>加载可执行程序：操作系统根据可执行的文件信息，分配进程空间，将代码段，数据段，BSS段等映射到进程的虚拟空间中</li><li>初始化：操作系统调用C++运行库的初始化代码，进行初始化，包括初始化全局变量，构造静态对象等</li><li>调用main（）函数</li><li>根据程序设计和逻辑，在运行过程中，可能需要分配动态内存、创建新的线程、进行 I&#x2F;O 操作等。</li><li>退出：当 main() 函数执行完毕，或者调用 exit() 函数结束程序运行，操作系统会回收进程空间和资源，完成程序的退出过程。</li><li></li></ol><hr><h1 id="多态"><a href="#多态" class="headerlink" title="多态"></a>多态</h1><p>静态多态：编译器在编译期间完成的，编译器会根据实参类型来推断该调用哪个函数，如果有对应的函数，就调用，没有则在编译时报错。</p><p>动态多态</p><h2 id="183-动态绑定是什么？"><a href="#183-动态绑定是什么？" class="headerlink" title="183.动态绑定是什么？"></a>183.动态绑定是什么？</h2><p><strong>动态绑定是指在运行时确定函数的实际调用函数</strong>。如果一个函数被声明为虚函数，那么在运行时就可以使用动态绑定，使得调用正确的实现。这种绑定通常是通过虚函数表（Virtual Table）来实现的，虚函数表是一个存储指向虚函数地址的指针数组，每个包含虚函数的类都有一个虚函数表。例如调用 ptr-&gt;speak() 时，根据指针实际指向的对象类型进行动态绑定，调用相应的 speak() 实现</p><h2 id="184-多态的好处"><a href="#184-多态的好处" class="headerlink" title="184.多态的好处?"></a>184.多态的好处?</h2><p>增强程序的可扩充性，即程序需要修改或增加功能时，只需改动或增加较少的代码。简化代码，使得不同的子类对象都可以使用同一个名称的函数，而具有不同的实现。实现动态绑定，即在运行时根据对象的实际类型来调用相应的虚函数。</p><h2 id="185-多态的形式"><a href="#185-多态的形式" class="headerlink" title="185.多态的形式"></a>185.多态的形式</h2><ul><li>虚函数多态</li><li>类模板多态</li><li>重载多态</li></ul><h2 id="186-32位整型在大小端的区别"><a href="#186-32位整型在大小端的区别" class="headerlink" title="186.32位整型在大小端的区别"></a>186.32位整型在大小端的区别</h2><p>小端：78 56 34 12(低位在低字节)<br>大端：12 34 56 78(低位在高字节)</p><h2 id="187-内存对齐"><a href="#187-内存对齐" class="headerlink" title="187.内存对齐"></a>187.内存对齐</h2><p>经过内存对齐之后，CPU 的内存访问速度大大提升。因为 CPU 把内存当成是一块一块的，块的大小可以是 2，4，8，16 个字节，因此 CPU 在读取内存的时候是一块一块进行读取的，<strong>块的大小称为内存读取粒度</strong>。</p><p>比如说 CPU 要读取一个 4 个字节的数据到寄存器中（假设内存读取粒度是 4），如果数据是从 0 字节开始的，那么直接将 0-3 四个字节完全读取到寄存器中进行处理即可。</p><p>如果数据是从 1 字节开始的，就首先要将前 4 个字节读取到寄存器，并再次读取 4-7 个字节数据进⼊寄存器，接着把 0 字节，5，6，7 字节的数据剔除，最后合并 1，2，3，4字节的数据进入寄存器，所以说，当内存没有对奇时，寄存器进⾏了很多额外的操作，大大降低了 CPU 的性能。</p><h2 id="188-内存对齐的原因？"><a href="#188-内存对齐的原因？" class="headerlink" title="188.内存对齐的原因？"></a>188.内存对齐的原因？</h2><p><strong>平台原因</strong>：不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。</p><p><strong>性能原因</strong>：应该尽可能地在自然边界上对齐。原因在于，为了访问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次就可以了。</p><h2 id="189-什么时候不应该内存对齐？"><a href="#189-什么时候不应该内存对齐？" class="headerlink" title="189.什么时候不应该内存对齐？"></a>189.什么时候不应该内存对齐？</h2><p>什么时候不希望进行内存对齐呢？一般来说，当我们追求空间效率而不是时间效率时，我们可以选择取消或者减小内存对齐。例如，在嵌入式系统中，由于资源有限，我们可能更关心节省空间而不是提高速度。此时我们可以使用编译器提供的选项来调整或者关闭内存对齐。</p><h2 id="190-内存对齐的规则？"><a href="#190-内存对齐的规则？" class="headerlink" title="190.内存对齐的规则？"></a>190.内存对齐的规则？</h2><ul><li>对于结构体的各个成员，第一个成员位于偏移为 <code>0</code> 的位置，结构体第一个成员的偏移量( <code>offset</code> )为  <code>0</code>，以后每个成员相对于结构体首地址的 <code>offset</code> 都是该成员大小与有效对齐值中较小那个的整数倍，如有需要编译器会在成员之间加上填充字节。</li><li>有效对齐值是给定值 <code>#pragma pack (n) </code>和结构体中最长数据类型长度中较小的那个，其中 <code>n</code> 是编译器提供的选项，可以是 <code>1,2,4,8,16</code> 等。</li><li>除了结构成员需要对齐，结构本身也需要对齐，结构的长度必须是编译器默认的对齐长度和成员中最长类型中最小的数据大小的倍数对齐。</li></ul><h2 id="191-指针和引用的区别？"><a href="#191-指针和引用的区别？" class="headerlink" title="191.指针和引用的区别？"></a>191.指针和引用的区别？</h2><p>引用和引用变量共同占一个空间，可以说，指针看的是地址，引用看的是变量本身，所以引用更加安全（不能取到引用本身的地址。如果去取引用的地址，编译器会帮你变成去所指向变量的地址。所以对引用取地址，其实取到的是所指向的值的地址）</p><h2 id="192-浅拷贝和深拷贝的区别？"><a href="#192-浅拷贝和深拷贝的区别？" class="headerlink" title="192.浅拷贝和深拷贝的区别？"></a>192.浅拷贝和深拷贝的区别？</h2><p>浅拷贝只复制指针，新旧两个东西共享同一块内存，当对象拥有动态分配的内存时，使用浅拷贝可能会导致资源泄露或内存访问错误<br>深拷贝会创建一个新的对象，包括内存，这意味着每个对象都有自己独立的内存副本，即使一个对象被改变，另一个也不会受影响</p><h2 id="193-struct和class的区别？"><a href="#193-struct和class的区别？" class="headerlink" title="193.struct和class的区别？"></a>193.struct和class的区别？</h2><p>struct默认公有继承，class默认私有继承;</p><p>struct内不能声明函数，class可以</p><h2 id="194-导入-C-函数的关键字是什么，C-编译时和-C-有什么不同？"><a href="#194-导入-C-函数的关键字是什么，C-编译时和-C-有什么不同？" class="headerlink" title="194.导入 C 函数的关键字是什么，C++ 编译时和 C 有什么不同？"></a>194.导入 C 函数的关键字是什么，C++ 编译时和 C 有什么不同？</h2><ul><li><p>C++中，导入C函数的关键字是extern，表达形式为extern “C”， extern “C”的主要作用就是为了能够正确实现C++代码调用其他C语言代码。加上extern “C”后，会指示编译器这部分代码按C语言的进行编译，而不是C++的。</p></li><li><p>由于C++支持函数重载，因此编译器编译函数的过程中会将函数的参数类型也加到编译后的代码中，而不仅仅是函数名；而 C 语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般只包括函数名。</p></li></ul><h2 id="195-函数指针"><a href="#195-函数指针" class="headerlink" title="195.函数指针"></a>195.函数指针</h2><ul><li><p>函数A（）；</p></li><li><p>函数B（）；</p></li><li><p>Bfuc(A);</p></li><li><p>B就是回调</p></li><li><p>意义：因为传进来的函数是不确定的。可以传函数1，也可以传函数2，直接在函数体里面调用就写死了，可以用这种方法实现多态。</p></li></ul><h2 id="196-new-和-malloc？"><a href="#196-new-和-malloc？" class="headerlink" title="196.new 和 malloc？"></a>196.new 和 malloc？</h2><ul><li>new是操作符 malloc是函数</li><li>new在调用的时候先分配内存，再调用构造函数，释放的时候先调用析构，后释放内存；而 malloc 没有构造函数和析构函数。</li><li>new 发生错误抛出异常，malloc 返回 null</li><li>new 返回具体类型指针，malloc 需要强制转换</li></ul><h2 id="197-delete-如何知道该释放多大的空间，这些信息存在什么位置？"><a href="#197-delete-如何知道该释放多大的空间，这些信息存在什么位置？" class="headerlink" title="197.delete 如何知道该释放多大的空间，这些信息存在什么位置？"></a>197.delete 如何知道该释放多大的空间，这些信息存在什么位置？</h2><ul><li>一种是在分配内存时，在内存首地址之前存储一个额外的值，表示数组的大小或者元素个数。这样，在释放内存时，就可以根据这个值来确定要释放多少空间。</li><li>另一种是在编译时，编译器会记录数组类型和大小的信息，并在生成代码时，将这些信息传递给delete[]操作符。这样，在运行时，delete[]就可以根据类型和大小来调用相应的析构函数和free函数</li></ul><h2 id="198-delete-和delete的区别，基本数据类型的数组使用delete可以释放完全吗？"><a href="#198-delete-和delete的区别，基本数据类型的数组使用delete可以释放完全吗？" class="headerlink" title="198.delete[]和delete的区别，基本数据类型的数组使用delete可以释放完全吗？"></a>198.delete[]和delete的区别，基本数据类型的数组使用delete可以释放完全吗？</h2><p>当new申请的是C++对象数组时，delete和delete []差别就很大了，delete只会析构一个对象<br>delete和delete[]的区别主要在于是否调用析构函数。如果用delete[]，则在回收空间之前所有对象都会首先调用自己的析构函数。基本类型的对象没有析构函数，所以回收基本类型组成的数组空间用delete和delete[]都是应该可以的；但是对于类对象数组，只能用delete[]。否则可能会造成内存泄漏或者其他错误。</p><h2 id="199-堆和栈的区别？"><a href="#199-堆和栈的区别？" class="headerlink" title="199.堆和栈的区别？"></a>199.堆和栈的区别？</h2><ul><li><strong>堆栈空间分配不同</strong>：栈由操作系统自行释放，堆一般由程序员释放</li><li><strong>缓冲方式不同</strong>：堆一般是二级存储，会慢一点，栈是一级存储，函数调用完直接释放</li><li><strong>数据结构不同</strong>：栈类似栈，而堆类似数组</li></ul><h2 id="200-内存泄漏？"><a href="#200-内存泄漏？" class="headerlink" title="200. 内存泄漏？"></a>200. 内存泄漏？</h2><ul><li><p>父类析构不是虚析构</p></li><li><p>父类析构函数如果不声明为虚函数，当使用基类指针指向派生类对象并进行 <code>delete</code> 操作时，只会调用基类的析构函数而不会调用派生类的析构函数，这样就无法正确释放派生类对象中的资源，可能导致内存泄漏或行为未定义。因此，为了确保在继承关系中正确释放资源，<strong>通常需要将基类的析构函数声明为虚析构函数</strong>。这样当通过基类指针删除派生类对象时，就能够按照继承关系依次调用每个类的析构函数，确保所有资源都得到正确释放。</p></li><li><p>用 malloc 或 new 申请资源后，没有释放</p></li><li><p>share_ptr 互相引用对方</p></li></ul><h1 id="201-说说C-的重载和重写是如何实现的"><a href="#201-说说C-的重载和重写是如何实现的" class="headerlink" title="201.说说C++的重载和重写是如何实现的?"></a>201.说说C++的重载和重写是如何实现的?</h1><ul><li><strong>重载</strong></li><li>函数重载的关键是函数的参数列表——也称为<strong>函数特征标（function signature）</strong>。如果两个函数的参数数目和类型相同，同时参数的排列顺序也相同，则它们的特征标相同，而变量名是无关紧要的。C++允许定义名称相同的函数，条件是它们的特征标不同。如果参数数目和或参数类型不同，则特征标也不同。</li><li><strong>重写</strong></li><li>在基类的函数前加上 <code>virtual</code> 关键字，在派生类中重写该函数，运行时将会根据对象的实际类型来调用相应的函数。如果对象类型是派生类，就调用派生类的函数；如果对象类型是基类，就调用基类的函数。</li></ul><h2 id="202-说说-C-语言如何实现-C-语言中的重载"><a href="#202-说说-C-语言如何实现-C-语言中的重载" class="headerlink" title="202.说说 C 语言如何实现 C++ 语言中的重载?"></a>202.说说 C 语言如何实现 C++ 语言中的重载?</h2><p>使用函数指针来实现，重载的函数不能使用同名称，只是类似的实现了函数重载功能</p><h2 id="203-简述下向上转型和向下转型"><a href="#203-简述下向上转型和向下转型" class="headerlink" title="203.简述下向上转型和向下转型?"></a>203.简述下向上转型和向下转型?</h2><ul><li><strong>子类转换为父类</strong></li><li><em>向上转型（Upcasting）</em>是指将一个派生类的指针或引用转换为它的基类的指针或引用的过程。这种转型是安全的，因为一个派生类对象也是一个基类对象，基类指针或引用可以指向派生类对象。</li><li><strong>父类转换为子类</strong></li><li><em>向下转型（Downcasting）</em>是指将一个基类的指针或引用转换为它的派生类的指针或引用的过程。这种转型是不安全的，<em><strong>因为一个基类对象可能不是一个派生类对象</strong></em>，如果对其进行向下转型，可能会导致未定义的行为或内存错误。向下转型应该尽可能避免使用，除非可以确定基类对象是派生类对象。</li></ul><h2 id="204-请问构造函数能不能调用虚函数"><a href="#204-请问构造函数能不能调用虚函数" class="headerlink" title="204.请问构造函数能不能调用虚函数?"></a>204.请问构造函数能不能调用虚函数?</h2><p>在 C++ 中，构造函数可以调用虚函数，但是要注意一些细节。在构造函数中调用虚函数时，<strong>实际调用的是当前正在构造的对象的虚函数</strong>，而不是派生类中重写的虚函数。这是因为在执行派生类的构造函数之前，基类的构造函数会先被执行，此时派生类的对象尚未构造完成，因此调用派生类中的虚函数是不安全的。</p><p><strong>基类先于派生类构造，所以构造时没法调用到派生类的虚函数，也就是说只能调用到自己这一层，也就是虚函数失去多态功能。</strong></p><h2 id="205-析构函数中能不能调用虚函数"><a href="#205-析构函数中能不能调用虚函数" class="headerlink" title="205.析构函数中能不能调用虚函数?"></a>205.析构函数中能不能调用虚函数?</h2><p>在析构函数中调用虚函数时，也会按照当前对象的类型来执行，而不是动态绑定到基类的实现</p><pre><code>Base constructorBase virtual methodDerived constructor</code></pre><p>可以看到，Base 的构造函数中调用了虚函数，但是实际执行的是 Base 类中的虚函数，而不是 Derived 类中的虚函数。因此，在构造函数中调用虚函数时，需要特别小心，以避免出现问题。</p><p><strong>派生类先于基类析构，所以析构时基类没法调用到派生类的虚函数，同样只能调用到自己这一层，虚函数也失去多态功能。</strong></p><h2 id="206-请问拷贝构造函数的参数是什么传递方式，为什么"><a href="#206-请问拷贝构造函数的参数是什么传递方式，为什么" class="headerlink" title="206.请问拷贝构造函数的参数是什么传递方式，为什么?"></a>206.请问拷贝构造函数的参数是什么传递方式，为什么?</h2><p>必须是引用，如果拷贝构造函数中的参数不是一个引用，即形如CClass(const CClass c_class)，那么就相当于采用了传值的方式(pass-by-value)，而传值的方式会调用该类的拷贝构造函数，从而造成无穷递归地调用拷贝构造函数。因此拷贝构造函数的参数必须是一个引用。</p><h2 id="207-C-仿函数？"><a href="#207-C-仿函数？" class="headerlink" title="207.C++  仿函数？"></a>207.C++  仿函数？</h2><ul><li>C++中的仿函数（Functor）是 一种可以像函数一样被调用对象。</li><li>仿函数是一个类或结构体，它重载了<code>operator()</code> 运算符，使其可以像函数一样被调用。</li><li>仿函数的实例可以像函数指针一样传递给STL算法或容器的操作，从而实现自定义行为。</li><li><strong>仿函数的灵活性：</strong> 仿函数可以具有任意数量的参数，并可以用于各种不同的操作。这使得它们非常灵活，可以根据需要进行定制。</li><li>STL中已经提供了一些常用的仿函数，例如std::less、std::greater、std::plus、std::minus等，它们可以在不编写自定义仿函数的情况下直接用</li><li>在某些情况下，使用仿函数可能会导致性能开销，因为它们引入了额外的函数调用。与普通函数相比，仿函数可能会有一些微小的性能损失。但在绝大多数情况下，这种性能损失非常小，通常可以忽略不计。在性能要求非常高的特定应用中，可以使用内联函数或其他优化手段来减小性能损失。</li></ul><h2 id="208-C-中类模板和模板类的区别？"><a href="#208-C-中类模板和模板类的区别？" class="headerlink" title="208.C++中类模板和模板类的区别？"></a>208.C++中类模板和模板类的区别？</h2><p>类模板是模板的定义，不是一个实实在在的类，定义中用到通用类型参数；</p><p>模板类是实实在在的类定义，是类模板的实例化。类定义中参数被实际类型所代替。</p><h2 id="209-64-位系统存一个地址多大空间？"><a href="#209-64-位系统存一个地址多大空间？" class="headerlink" title="209.64 位系统存一个地址多大空间？"></a>209.64 位系统存一个地址多大空间？</h2><p>64 位系统存一个地址的空间大小取决于内存地址的位数。</p><p>一个内存地址&#x3D;一个内存单元&#x3D;一个字节</p><p>一般来说，一个内存地址对应一个字节（8位），所以64位系统可以表示16个16进制数（64位）的内存地址。这样，<strong>64位系统的最大寻址空间为2的64次方字节</strong>，即16384PB或16777216TB。但是，并不是所有的 64 位系统都能使用这么大的寻址空间，因为有些CPU只有40位或48位的地址线，而且操作系统也有自己的限制。</p><h2 id="210-函数传递时会不会在内存拷贝？"><a href="#210-函数传递时会不会在内存拷贝？" class="headerlink" title="210.函数传递时会不会在内存拷贝？"></a>210.函数传递时会不会在内存拷贝？</h2><p>在C++中，定义函数int function(int a[], int b)，这里数组a不会在内存中拷贝，传递的是指针。数组名就是一个指向数组第一个元素的指针，所以当你把数组名作为参数传递时，实际上是传递了一个指针。如果你想要传递整个数组的副本，你可以使用引用或者复制数组的内容到另一个数组。<br>当你传递一个普通的整型变量（如参数 b）作为函数参数时，实际上会发生值传递。这意味着参数的值会被复制到函数调用的栈帧中，而不是传递参数本身的地址或引用。</p><h2 id="211-为什么要使用友元？"><a href="#211-为什么要使用友元？" class="headerlink" title="211.为什么要使用友元？"></a>211.为什么要使用友元？</h2><p>使用友元可以简化代码，提高效率。</p><p>举例来说，假设有一个类 A 和一个函数 F，A 中有一个私有成员变量 x，而 F 函数需要<strong>访问这个私有变量。</strong>如果不使用友元，就只能使用 A 的公有接口来获取 x，这样会增加代码的复杂性和开销。</p><ul><li>但是友元函数也有缺点：</li><li><strong>破坏封装性：</strong>友元函数或类可以直接访问类的私有成员，这样会破坏类的封装性，导致私有成员可以被外部函数或类直接操作，增加了代码的耦合性。</li><li><strong>降低可维护性：</strong>友元使得类的实现细节对外暴露，当类的实现发生变化时，所有依赖于友元关系的外部函数或类都可能受到影响，增加了代码的维护成本。</li></ul><h2 id="212-检查内存泄漏的方法？"><a href="#212-检查内存泄漏的方法？" class="headerlink" title="212.检查内存泄漏的方法？"></a>212.检查内存泄漏的方法？</h2><ul><li>使用第三方工具（在Linux平台valgrind）</li><li>重写new和delete，记录分配点（甚至是调用堆栈），定期打印。</li><li>使用智能指针</li></ul><p><a href="https://blog.csdn.net/bandaoyu/article/details/106913866">C++内存泄露检查的5个方法</a></p><h2 id="213-C-编译和-C-编译的区别？"><a href="#213-C-编译和-C-编译的区别？" class="headerlink" title="213.C++ 编译和 C 编译的区别？"></a>213.C++ 编译和 C 编译的区别？</h2><p><strong>文件后缀名</strong>：<br>C语言的源文件通常以 ,c为后缀名，而C++语言的源文件通常以.cpp为后缀名。这个命名约定是为了让编译器能够正确识别源文件<br>件的类型。</p><p><strong>链接库</strong>：C语言和C++语言使用的链接库不同，C语言使用C标准库，C++语言使用C++标准库。C++标准库中包含了C标准库中的所有函数，同时还包含了STL（标准模板库）和一些面向对象的特性，如命名空间、类、继承等。</p><h2 id="214-如何判断一段函数是-C-编译的还是-C-编译的？"><a href="#214-如何判断一段函数是-C-编译的还是-C-编译的？" class="headerlink" title="214.如何判断一段函数是 C++ 编译的还是 C 编译的？"></a>214.如何判断一段函数是 C++ 编译的还是 C 编译的？</h2><p>（1）如果是要你的代码在编译时就发现编译器类型，就判断 <code>_cplusplus</code> <code>或_STDC_</code> 宏，如果是一个 C 文件被编译，那么 <code>_STDC_</code> 就会被定义，<code>_STDC_</code> 是预定义宏，当它被定义后，编译器将按照ANSIC标准来编译C语言程序。通常许多编译器还有其他编译标志宏。</p><p>（2）如果要判断已经编译过的代码的编译类型，就查一下输出函数符号是否和函数名相同。（相同为c，不同为c++，因为C没有函数重载的概念，C++里有函数重载，所以为了避免编译后函数符号相同，<strong>C++里编译后，函数符号为参数类型加函数名组成的</strong>）</p><pre><code>#ifdef __cplusplus// Code being compiled as C++.#endif</code></pre><p>这是一个预处理器指令，它可以让你在编译前对源代码进行一些操作。<code>#ifdef __cplusplus</code> 的意思是如果 <code>__cplusplus</code>  宏被定义了，就执行后面的代码。<code>__cplusplus</code> 宏是一个特殊的宏，它只有在C++ 编译器下才会被定义，所以这个指令可以用来检查当前的编译环境是否是C++。#endif 的意思是结束#ifdef 的范围。</p><h2 id="215-如何用-C-判断一个系统是16位、32位还是64位？"><a href="#215-如何用-C-判断一个系统是16位、32位还是64位？" class="headerlink" title="215.如何用 C++ 判断一个系统是16位、32位还是64位？"></a>215.如何用 C++ 判断一个系统是16位、32位还是64位？</h2><p>方法一：使用指针的sizeof()判断；</p><pre><code>#include &lt;iostream&gt;using namespace std;int main()&#123;    int *p = nullptr;        if(sizeof(p) == 8)    &#123;        cout &lt;&lt; &quot;64 bits system&quot; &lt;&lt; endl;    &#125;    else if(sizeof(p) == 4)    &#123;        cout &lt;&lt; &quot;32 bits system&quot; &lt;&lt; endl;    &#125;    else if(sizeof(p) == 2)    &#123;        cout &lt;&lt; &quot;16 bits&quot; &lt;&lt;endl;    &#125;    else    &#123;        cout &lt;&lt; &quot;unknown system&quot; &lt;&lt; endl;    &#125;    return 0;&#125;</code></pre><p>方法二：使用预定义宏来判断；</p><pre><code>#include &lt;iostream&gt;using namespace std;int main()&#123;#ifdef __x86_64__    &#123;cout &lt;&lt; &quot;64 bits system&quot; &lt;&lt; endl;    &#125;#elif defined __x86_32__    &#123;        cout &lt;&lt; &quot;32 bits system&quot; &lt;&lt; endl;    &#125;#elif defined __x86_16__    &#123;        cout &lt;&lt; &quot;16 bits&quot; &lt;&lt;endl;&#125;    #else    &#123;        cout &lt;&lt; &quot;unknown system&quot; &lt;&lt; endl;    &#125;    #endif    return 0;&#125;</code></pre><p>方法三：使用整数溢出来判断(该方法可能有点小问题，同一个系统输出结果和其它 2 种不一致，原因暂未找到)<br>不同系统的基本数据类型的字节长度区别，</p><p>方法四：WIN32 API函数 IsWow64Process，就是判断指定程序是否运行在 WOW64 模拟系统中</p><table><thead><tr><th></th><th>OS 32bits</th><th>OS 64BITS</th></tr></thead><tbody><tr><td>32bits process</td><td>FALSE</td><td>TRUE</td></tr><tr><td>64bits process</td><td>ERROR</td><td>FALSE</td></tr></tbody></table><p>方法五：</p><ul><li><p>1.因为可能会判断系统是64位的，所以我们需要采用16进制来表示，那么此刻地址应该是16个十六进制＋结束符‘\0’,总共17位。</p></li><li><p>2.定义一个 char 类型的指针，让其指向 0 号地址单元（lont int），此时 p 的值为0x00000000(32位系统)或0x0000000000000000或者指向一个 -1(0xffff…)的地址强转；</p></li><li><p>3.把指针 p 按地址的打印方式，格式化到 buff 中；</p></li><li><p>4.调用 strlen 函数求得 buff 中字符个数，即 p 对应十六进制的字符个数，乘以 4 就可以得到系统位数了。</p><pre><code>  int main(int argc, char *argv[])  &#123;      char buf[17];      char * p = (char *)-1;                   sprintf_s(buf, &quot;%p&quot;, p);      printf(&quot;System is %d bit.\n&quot;, strlen(buf) * 4);  &#125;</code></pre></li></ul><table><thead><tr><th>平台&#x2F;类型</th><th>char</th><th>short</th><th>int</th><th>long</th><th>long long</th></tr></thead><tbody><tr><td>16位</td><td>1</td><td>2</td><td>2</td><td>4</td><td>8</td></tr><tr><td>32位</td><td>1</td><td>2</td><td>4</td><td>4</td><td>8</td></tr><tr><td>64位</td><td>1</td><td>2</td><td>4</td><td>8</td><td>8</td></tr></tbody></table><h2 id="216-重复多次-fclose-一个打开过一次的-FILE-fp-指针会有什么结果，并请解释"><a href="#216-重复多次-fclose-一个打开过一次的-FILE-fp-指针会有什么结果，并请解释" class="headerlink" title="216.重复多次 fclose 一个打开过一次的 FILE *fp 指针会有什么结果，并请解释?"></a>216.重复多次 fclose 一个打开过一次的 FILE *fp 指针会有什么结果，并请解释?</h2><p>导致文件描述符结构中指针指向的内存被重复释放，进而导致一些不可预期的异常。</p><h2 id="217-为什么函数传递数组参数，结果数组会被修改，而值不行？"><a href="#217-为什么函数传递数组参数，结果数组会被修改，而值不行？" class="headerlink" title="217.为什么函数传递数组参数，结果数组会被修改，而值不行？"></a>217.为什么函数传递数组参数，结果数组会被修改，而值不行？</h2><p>当数组名作为参数时，传递的实际上是地址。</p><p>而其他类型如 int 作为参数时，由于函数参数值实质上是实参的一份拷贝，被调函数内部对形参的改变并不影响实参的值。</p><h2 id="218-main-函数执行以前，还会执行什么代码？"><a href="#218-main-函数执行以前，还会执行什么代码？" class="headerlink" title="218.main 函数执行以前，还会执行什么代码？"></a>218.main 函数执行以前，还会执行什么代码？</h2><p>全局对象的构造函数会在main 函数之前执行。</p><h2 id="219-字符指针、浮点数指针、以及函数指针这三种类型的变量哪个占用的内存最大？为什么？"><a href="#219-字符指针、浮点数指针、以及函数指针这三种类型的变量哪个占用的内存最大？为什么？" class="headerlink" title="219.字符指针、浮点数指针、以及函数指针这三种类型的变量哪个占用的内存最大？为什么？"></a>219.字符指针、浮点数指针、以及函数指针这三种类型的变量哪个占用的内存最大？为什么？</h2><p>指针变量也占用内存单元，而且所有指针变量占用内存单元的数量都是相同的。32 位 4 个字节，64 位 8 个字节</p><p>就是说，<strong>不管是指向何种对象的指针变量，它们占用内存的字节数都是一样的，并且要足够把程序中所能用到的最大地址表示出来（通常是一个机器字长）</strong>。<strong>指针变量的大小固定是因为它们存储的是内存地址</strong>，而不是实际的数据。这使得指针变量在不同类型之间具有相同的大小，因为它们只是存储一个内存地址，无论指向的是什么类型的数据，所需的内存空间都是一样的。<br>当使用指针进行解引用操作时，不同类型的指针会导致不同大小的数据被读取。</p><h2 id="220-C-几个基本类型占用空间"><a href="#220-C-几个基本类型占用空间" class="headerlink" title="220.C++几个基本类型占用空间"></a>220.C++几个基本类型占用空间</h2><table><thead><tr><th>数据类型</th><th>16位系统</th><th>32位系统</th><th>64位系统</th></tr></thead><tbody><tr><td>bool</td><td>1字节</td><td>1字节</td><td>1字节</td></tr><tr><td>char</td><td>1字节</td><td>1字节</td><td>1字节</td></tr><tr><td>short</td><td>2字节</td><td>2字节</td><td>2字节</td></tr><tr><td>int</td><td>2字节</td><td>4字节</td><td>4字节</td></tr><tr><td>float</td><td>4字节</td><td>4字节</td><td>4字节</td></tr><tr><td>double</td><td>8字节</td><td>8字节</td><td>8字节</td></tr><tr><td>void</td><td>不占空间</td><td>不占空间</td><td>不占空间</td></tr><tr><td>wchar_t</td><td>2字节</td><td>2或4字节</td><td>2或4或8字节</td></tr></tbody></table><blockquote><p>wchar_t是C&#x2F;C++的字符类型，一种扩展的存储方式，主要用在国际化程序的实现中，但它不等同与Unicode编码；Unicode编码的字符一般是以wchar_t字符存储。</p><p>char字符类型只有8个位，只能包含256个字符，而像很多外文字符远超过256个字符，例如：中文、日文、韩文等，这些字符需要占用两个字节空间，所以c++提出了双字节字符类型wchar_t(或叫宽字符类型)。</p><p>wchar_t定义的是双字节类型，需要L告诉编译器content占用2字节的空间，否则编译产生类型报错。<br><a href="https://www.cnblogs.com/alex-space/p/13131526.html">https://www.cnblogs.com/alex-space/p/13131526.html</a></p></blockquote><h2 id="221-继承时应该要写哪些类的成员函数"><a href="#221-继承时应该要写哪些类的成员函数" class="headerlink" title="221.继承时应该要写哪些类的成员函数?"></a>221.继承时应该要写哪些类的成员函数?</h2><p>C++继承时，一般要写类的构造函数（包括拷贝构造）、析构函数、赋值运算符重载函数，以及其他需要实现类的功能或接口的成员函数</p><h2 id="222-怎样让对象只能创建在栈-堆-内存池中"><a href="#222-怎样让对象只能创建在栈-堆-内存池中" class="headerlink" title="222.怎样让对象只能创建在栈&#x2F;堆&#x2F;内存池中"></a>222.怎样让对象只能创建在栈&#x2F;堆&#x2F;内存池中</h2><p>在C++中，类的对象建立分为两种，一种是静态建立，如A a；另一种是动态建立，如A* ptr&#x3D;new A；这两种方式是有区别的。</p><p><strong>静态建立</strong>一个类对象，是由编译器为对象在栈空间中分配内存，是通过直接移动栈顶指针，挪出适当的空间，然后在这片内存空间上调用构造函数形成一个栈对象。使用这种方法，直接调用类的构造函数。</p><p><strong>动态建立</strong>类对象，是使用new运算符将对象建立在堆空间中。这个过程分为两步，第一步是执行operator new()函数，在堆空间中搜索合适的内存并进行分配；第二步是调用构造函数构造对象，初始化这片内存空间。</p><blockquote><p><strong>默认构造函数创建的对象通常是在调用它的地方所在的栈上</strong>。当你在函数内部声明一个对象并调用默认构造函数时，这个对象会被分配在函数的栈帧中。</p></blockquote><p><strong>只允许在栈上创建对象：</strong></p><p>方法一：<strong>只要禁用 new 运算符就可以实现类对象只能建立在栈上。将 operator new() 设为私有即可。</strong></p><p>如果对象是通过 new 关键字在堆上创建，那么它将在堆上分配内存；如果对象是通过普通的声明方式在函数中创建，那么它将在栈上分配内存。</p><pre><code>class A  &#123;  private:      void* operator new(size_t t)&#123;&#125; // 注意函数的第一个参数和返回值都是固定的      void operator delete(void* ptr)&#123;&#125; // 重载了new就需要重载delete  public:      A()&#123;&#125;      ~A()&#123;&#125;  &#125;; </code></pre><p>方法二：<strong>构造函数私有化 + 静态的公有接口</strong><br>静态方法的特点是可以在不实例化类的情况下调用，因此可以直接通过类名来调用该方法。说白了我们就可以不用new来创建对象。</p><pre><code>//只能在栈上创建的对象class StackOnly &#123;public:    //静态公有方法, 在栈上创建对象    static StackOnly getobj() &#123;        StackOnly so;        return so;    &#125;    //拷贝构造不用管, 本来就在栈上private:    //构造函数私有化    StackOnly() &#123;&#125;&#125;;</code></pre><p><strong>只允许在堆上创建对象：</strong><br><strong>将析构函数设为私有，类对象就无法建立在栈上了。</strong></p><p>类的析构函数是私有的，编译器无法调用析构函数来释放内存。所以，编译器在为类对象分配栈空间时，会先检查类的析构函数的访问性，其实不光是析构函数，只要是非静态的函数，编译器都会进行检查。如果类的析构函数是私有的，则编译器不会在栈空间上为类对象分配内存。</p><pre><code>class A  &#123;  public:      A()&#123;&#125;      void destory()&#123;delete this;&#125;  private:      ~A()&#123;&#125;  &#125;</code></pre><p>  试着使用 A a; 来建立对象，编译报错，提示析构函数无法访问。这样就只能使用 new 操作符来建立对象，构造函数是公有的，可以直接调用。类中必须提供一个 destory 函数，来进行内存空间的释放。类对象使用完成后，必须调用 destory 函数。</p><p>  上述方法的一个缺点就是，无法解决继承问题。如果A作为其它类的基类，则析构函数通常要设为virtual，然后在子类重写，以实现多态。因此析构函数不能设为private。</p><p>另一个问题是，类的使用很不方便，使用new建立对象，却使用destory函数释放对象，而不是使用delete。（使用delete会报错，因为delete对象的指针，会调用对象的析构函数，而析构函数类外不可访问）这种使用方式比较怪异。</p><p>为了统一，可以将构造函数设为 protected（类外无法访问protected成员，子类则可以访问），然后提供一个 public 的 static 函数（静态方法的特点是可以在不实例化类的情况下调用）来完成构造，这样不使用 new，而是使用一个函数来构造，使用一个函数来析构。</p><pre><code>class A  &#123;  protected:      A()&#123;&#125;      ~A()&#123;&#125;  public:      static A* create()      &#123;          return new A();      &#125;      void destory()      &#123;          delete this;      &#125;  &#125;;  </code></pre><p>这样，调用create()函数在堆上创建类A对象，调用destory()函数释放内存。</p><p><strong>只允许在内存池中创建对象：</strong><br>核心思路就是先把栈和堆的都取消<br>MyPool 类负责内存的分配和释放，MyObject 类重载了 new 和 delete 运算符，以便将对象的内存管理委托给 MyPool 类。</p><pre><code>class MyPool &#123;public:  static void* allocate(std::size_t size) &#123;    // 自定义内存池分配内存  &#125;  static void deallocate(void* ptr, std::size_t size) &#123;    // 自定义内存池释放内存  &#125;&#125;;class MyObject &#123;public:  void* operator new(std::size_t size) &#123;    return MyPool::allocate(size);  &#125;  void operator delete(void* ptr) &#123;    MyPool::deallocate(ptr, sizeof(MyObject));  &#125;  void* operator new[](std::size_t size) = delete;  void operator delete[](void* ptr) = delete;&#125;;</code></pre><blockquote><p>MyObject 类重载了 operator new 和 operator delete<br>运算符，从而实现了只允许在内存池中创建对象的功能。operator new 运算符调用 MyPool::allocate<br>方法从内存池中分配内存，而 operator delete 运算符调用 MyPool::deallocate 方法释放内存。同时，禁用了<br>operator new[] 和 operator delete[]<br>运算符，从而防止在自由存储区创建数组对象。在实际使用时，需要根据具体的内存池实现来修改 MyPool 类中的代码。</p></blockquote><h2 id="223-RTTI原理，type-info信息存在虚函数表的哪里？"><a href="#223-RTTI原理，type-info信息存在虚函数表的哪里？" class="headerlink" title="223.RTTI原理，type_info信息存在虚函数表的哪里？"></a>223.RTTI原理，type_info信息存在虚函数表的哪里？</h2><p>RTTI(Run Time Type Identification)即通过运行时类型识别，程序能够使用基类的指针或引用来检查着这些指针或引用所指的对象的实际派生类型，RTTI就是运行时动态绑定。</p><p>RTTI 包含三个内容：typeid 关键字、type_info 类型和 dynamic_cast 类型转换。typeid 用来确定目标的实际类型是什么，type_info 存储类型信息。dynamic_cast 用于基类向派生类的向下转型。typeid 会将类的相关信息存储到一个类型为 type_info（头文件）的对象中，在调用 typeid 后返回这个对象的常引用<code>（type_info const&amp;）</code>。</p><p>编译器也会在每个有虚函数的类对应的 type_info 对象中存储该类的类型信息。type_info对象是一个标准库提供的类，它包含了类型名称、哈希码等信息，并且重载了&#x3D;&#x3D;和!&#x3D;运算符来比较两个类型是否相同。</p><p>为了让type_info对象和虚函数表关联起来，<strong>编译器会在虚函数表的开头插入一个指针，指向当前类对应的type_info对象。这样，在运行时就可以通过基类指针p找到vfptr，再通过vfptr找到type_info对象指针，进而取得类型信息。</strong></p><p>type_info 信息存在虚函数表的开头，也就是虚函数表的第一个元素是一个指向type_info 对象的指针 。没有虚表，则RTTI毫无意义。</p><p><a href="http://t.csdnimg.cn/8yaEq">C++ RTTI 机制下判断类型的 typeid 和记录类型信息的 type_info</a></p><h2 id="224-C-在哪些情况下会产生临时对象？"><a href="#224-C-在哪些情况下会产生临时对象？" class="headerlink" title="224.C++在哪些情况下会产生临时对象？"></a>224.C++在哪些情况下会产生临时对象？</h2><p>C++中，临时对象是编译器在不同的情况下创建的没有名字的对象。</p><p>临时对象通常产生于5种情况：</p><ol><li>引用初始化，例如 const int&amp; r &#x3D; 42;</li><li>参数传递，例如 f(42);</li><li>表达式求值，例如 a + b;</li><li>函数返回，例如 return x + y;</li><li>异常抛出，例如 throw x;</li></ol><p>临时对象有一个生命周期，由它们的创建点和销毁点决定。任何创建多个临时对象的表达式最终会按照创建的逆序销毁它们。</p><p>临时对象的销毁时间取决于它们的使用方式：</p><ul><li>用于初始化const引用的临时对象：如果引用是局部变量，则在引用离开作用域时销毁；如果引用是类成员，则在类实例被销毁时销毁。</li><li>用于初始化非const引用或值类型的临时对象：在表达式结束后立即销毁。</li></ul><h2 id="225-C-静态链接库（lib）和动态链接库（dll）的区别"><a href="#225-C-静态链接库（lib）和动态链接库（dll）的区别" class="headerlink" title="225.C++静态链接库（lib）和动态链接库（dll）的区别?"></a>225.C++静态链接库（lib）和动态链接库（dll）的区别?</h2><p><strong>静态链接库（lib）</strong>是在编译时将库的代码直接复制到可执行文件中，所以在程序运行时不需要依赖任何外部库文件，所有的代码都在一个可执行文件中。因此，静态链接库的优点是移植方便，无需安装其他库文件，程序运行时速度较快。缺点是占用硬盘空间较大，同时也存在代码重复的情况，不利于代码的更新和维护。</p><p><strong>动态链接库（dll）</strong>是在程序运行时才被加载到内存中，程序需要调用库函数时才会加载对应的库文件。因此，动态链接库的优点是共享库文件，节省了硬盘空间，同时也方便了库文件的更新和维护。缺点是相对于静态链接库，程序运行时会存在一定的额外开销，如加载库文件、解析符号等。</p><h2 id="226-memory-move和memory-copy是什么，他们的区别？"><a href="#226-memory-move和memory-copy是什么，他们的区别？" class="headerlink" title="226.memory_move和memory_copy是什么，他们的区别？"></a>226.memory_move和memory_copy是什么，他们的区别？</h2><p>“memory_move” 和 “memory_copy” 是用于处理内存中数据的操作，用于移动或复制内存中的数据。</p><p>memcpy 的实现比较简单，它只是简单地<strong>把数据从源地址按字节逐一复制到目标地址</strong>。这意味着，如果源地址和目标地址存在重叠，即它们指向同一块内存区域，那么 memcpy 可能会出现未定义的行为，也就是数据会被错误地覆盖。因此，<strong>使用 memcpy 时需要确保源地址和目标地址不会发生重叠</strong>。</p><p>而 memmove 的实现则更为复杂，它<strong>能够处理源地址和目标地址重叠的情况</strong>，即使这两个地址相互重叠，也能够保证正确地复制数据。具体来说，memmove <strong>在复制数据时会先把数据拷贝到一个临时缓冲区中，然后再把数据从缓冲区复制到目标地址</strong>，这样就避免了源地址和目标地址重叠时数据被错误地覆盖的问题。但是，由于要使用临时缓冲区，所以 memmove 的性能可能会稍微低一些。</p><h2 id="227"><a href="#227" class="headerlink" title="227."></a>227.</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-C和C-的区别&quot;&gt;&lt;a href=&quot;#1-C和C-的区别&quot; class=&quot;headerlink&quot; title=&quot;1.C和C++的区别&quot;&gt;&lt;/a&gt;1.C和C++的区别&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;设计思想上：&lt;/strong&gt; C++是面向对象的语言，而C是面</summary>
      
    
    
    
    
    <category term="Offer" scheme="http://example.com/tags/Offer/"/>
    
  </entry>
  
  <entry>
    <title>MySQL</title>
    <link href="http://example.com/2024/06/09/MySQL/"/>
    <id>http://example.com/2024/06/09/MySQL/</id>
    <published>2024-06-09T07:32:59.000Z</published>
    <updated>2024-06-09T07:58:58.284Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><h2 id="1-MySQL-执行流程是怎样的？"><a href="#1-MySQL-执行流程是怎样的？" class="headerlink" title="1.MySQL 执行流程是怎样的？"></a>1.MySQL 执行流程是怎样的？</h2><p>MySQL 的架构共分为两层：Server 层和存储引擎层：</p><ol><li><strong>Server 层</strong>负责建立连接、分析和执行 SQL（连接器，查询缓存、解析器、预处理器、优化器、执行器等，内置函数，跨存储引擎的功能）；</li><li><strong>存储引擎层</strong>负责数据的存储和提取（支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。）。</li></ol><p><strong>连接器</strong>：建立连接，管理连接、校验用户身份；</p><p><strong>查询缓存</strong>：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；</p><p><strong>解析 SQL</strong>，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；</p><p><strong>执行 SQL</strong>：执行 SQL 共有三个阶段：</p><ul><li>预处理阶段：检查表或字段是否存在；将 select * 中的 * 符号扩展为表上的所有列。</li><li>优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；</li><li>执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；</li></ul><h2 id="2-MySQL-的-NULL-值是怎么存放的？"><a href="#2-MySQL-的-NULL-值是怎么存放的？" class="headerlink" title="2.MySQL 的 NULL 值是怎么存放的？"></a>2.MySQL 的 NULL 值是怎么存放的？</h2><p>MySQL 的 Compact 行格式中会用「NULL值列表」来标记值为 NULL 的列，NULL 值并不会存储在行格式中的真实数据部分。</p><p>NULL值列表会占用 1 字节空间，当表中所有字段都定义成 NOT NULL，行格式中就不会有 NULL值列表，这样可节省 1 字节的空间。</p><blockquote><p>表空间由段（segment）、区（extent）、页（page）、行（row）组成</p></blockquote><blockquote><ul><li>数据库表中的记录都是<strong>按行（row）进行存放的</strong>，每行记录根据不同的行格式，有不同的存储结构。</li><li>记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I&#x2F;O 操作）只能处理一行数据，效率会非常低。<br>因此，<strong>InnoDB 的数据是按「页」为单位来读写的</strong>，也就是说，当需要读一条记录的时候，并不是将这个行记录从磁盘读出来，而是以页为单位，将其整体读入内存。<font color="#F100">默认每个页的大小为 16KB，也就是最多能保证 16KB 的连续存储空间。</font></li><li>InnoDB 存储引擎是用 B+ 树来组织数据的。在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I&#x2F;O 了;</li><li><strong>表空间是由各个段（segment）组成的</strong>，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。</li></ul></blockquote><blockquote><ul><li>索引段：存放 B + 树的非叶子节点的区的集合；</li><li>数据段：存放 B + 树的叶子节点的区的集合；</li><li>回滚段：存放的是回滚数据的区的集合。</li></ul></blockquote><h2 id="3-MySQL-怎么知道-varchar-n-实际占用数据的大小？"><a href="#3-MySQL-怎么知道-varchar-n-实际占用数据的大小？" class="headerlink" title="3.MySQL 怎么知道 varchar(n) 实际占用数据的大小？"></a>3.MySQL 怎么知道 varchar(n) 实际占用数据的大小？</h2><p>MySQL 的 Compact 行格式中会用「变长字段长度列表」存储变长字段实际占用的数据大小。</p><h2 id="4-varchar-n-中-n-最大取值为多少？"><a href="#4-varchar-n-中-n-最大取值为多少？" class="headerlink" title="4.varchar(n) 中 n 最大取值为多少？"></a>4.varchar(n) 中 n 最大取值为多少？</h2><p>一行记录最大能存储 65535 字节的数据，但是这个是包含「变长字段字节数列表所占用的字节数」和「NULL值列表所占用的字节数」。所以， 我们在算 varchar(n) 中 n 最大值时，需要减去这两个列表所占用的字节数。</p><h2 id="5-行溢出后，MySQL-是怎么处理的？"><a href="#5-行溢出后，MySQL-是怎么处理的？" class="headerlink" title="5.行溢出后，MySQL 是怎么处理的？"></a>5.行溢出后，MySQL 是怎么处理的？</h2><p>如果一个数据页存不了一条记录，InnoDB 存储引擎会自动将溢出的数据存放到「溢出页」中。</p><p>Compact 行格式针对行溢出的处理是这样的：当发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在「溢出页」中，然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。</p><p>Compressed 和 Dynamic 这两种格式采用完全的行溢出方式，记录的真实数据处不会存储该列的一部分数据，只存储 20 个字节的指针来指向溢出页。而实际的数据都存储在溢出页中。</p><h2 id="6-为什么「变长字段长度列表」的信息要按照逆序存放？"><a href="#6-为什么「变长字段长度列表」的信息要按照逆序存放？" class="headerlink" title="6.为什么「变长字段长度列表」的信息要按照逆序存放？"></a>6.为什么「变长字段长度列表」的信息要按照逆序存放？</h2><p>因为「记录头信息」中指向下一个记录的指针，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。</p><p>「变长字段长度列表」中的信息之所以要逆序存放，是因为这样可以<strong>使得位置靠前的记录的真实数据和数据对应的字段长度信息可以同时在一个 CPU Cache Line 中</strong>，这样就可以提高 CPU Cache 的命中率。</p><p>同样的道理， NULL 值列表的信息也需要逆序存放。</p><hr><h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><h2 id="1-什么是索引？"><a href="#1-什么是索引？" class="headerlink" title="1.什么是索引？"></a>1.什么是索引？</h2><p>数据库中，索引的定义就是帮助存储引擎快速获取数据的一种数据结构，形象的说就是索引是数据的目录。</p><p>（1）按「数据结构」分类：B+Tree 索引、HASH 索引、Full-Text 索引。</p><p>（2）按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引）。</p><blockquote><p>主键索引的 B+Tree 的叶子节点存放的是<strong>实际数据</strong>，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；</p></blockquote><blockquote><p>二级索引的 B+Tree 的叶子节点存放的是<strong>主键值</strong>，而不是实际数据。</p></blockquote><pre><code>聚簇索引字段选择：如果有主键，默认会使用主键作为聚簇索引的索引键（key）；如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键（key）；在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键（key）；</code></pre><p>（3）按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引。</p><ul><li><strong>主键索引</strong>就是建立在主键字段上的索引，通常在创建表的时候一起创建，一张表最多只有一个主键索引，索引列的值不允许有空值。</li><li><strong>唯一索引</strong>建立在 UNIQUE 字段上的索引，一张表可以有多个唯一索引，索引列的值必须唯一，但是允许有空值。</li><li><strong>普通索引</strong>就是建立在普通字段上的索引，既不要求字段为主键，也不要求字段为 UNIQUE。</li><li><strong>前缀索引</strong>是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。使用前缀索引的目的是为了减少索引占用的存储空间，提升查询效率。</li></ul><p>（4）按「字段个数」分类：单列索引、联合索引。</p><ul><li>使用联合索引时，存在最左匹配原则，也就是按照最左优先的方式进行索引的匹配。在使用联合索引进行查询的时候，如果不遵循「最左匹配原则」，联合索引会失效，这样就无法利用到索引快速查询的特性了。</li><li>(a, b, c) 联合索引，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，b 和 c 是全局无序，局部相对有序的，这样在没有遵循最左匹配原则的情况下，是无法利用到索引的。</li></ul><h2 id="2-什么时候需要-不需要创建索引？"><a href="#2-什么时候需要-不需要创建索引？" class="headerlink" title="2.什么时候需要 &#x2F; 不需要创建索引？"></a>2.什么时候需要 &#x2F; 不需要创建索引？</h2><p>索引最大的好处是提高查询速度，但是索引也是有缺点的，比如：</p><ul><li>需要占用物理空间，数量越大，占用空间越大；</li><li>创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大；</li><li>会降低表的增删改的效率，因为每次增删改索引，B+ 树为了维护索引有序性，都需要进行动态维护。</li></ul><p><strong>适用索引：</strong></p><ul><li>字段有唯一性限制的，比如商品编码；</li><li>经常用于 WHERE 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。</li><li>经常用于 GROUP BY 和 ORDER BY 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。</li></ul><p><strong>不需要创建索引：</strong></p><ul><li>WHERE 条件，GROUP BY，ORDER BY 里用不到的字段，索引的价值是快速定位，如果<strong>起不到定位的字段</strong>通常是不需要创建索引的，因为索引是会占用物理空间的。</li><li><strong>字段中存在大量重复数据</strong>，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。</li><li><strong>表数据太少的时候</strong>，不需要创建索引；</li><li><strong>经常更新的字段</strong>不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的。</li></ul><h2 id="3-优化索引的方法？"><a href="#3-优化索引的方法？" class="headerlink" title="3.优化索引的方法？"></a>3.优化索引的方法？</h2><ol><li><p><strong>前缀索引优化</strong>：使用某个字段中字符串的前几个字符建立索引；</p><p> 使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。</p></li><li><p><strong>覆盖索引优化</strong>： SQL 中 query 的所有字段，在索引 B+Tree 的叶子节点上都能找得到的那些索引，从二级索引中查询得到记录，而不需要通过聚簇索引查询获得，可以避免回表的操作；</p><p> 使用覆盖索引的好处就是，不需要查询出包含整行记录的所有信息，也就减少了大量的 I&#x2F;O 操作。</p></li><li><p>主键索引最好是自增的；</p><p> 如果我们使用自增主键，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为<strong>每次插入一条新记录，都是追加操作，不需要重新移动数据</strong>，因此这种插入数据的方法效率非常高。</p><p> 如果我们使用非自增主键，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为<strong>页分裂</strong>。页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。</p><p> <font color="#F100">主键字段长度越小，意味着二级索引的叶子节点越小（二级索引的叶子节点存放的数据是主键值），这样二级索引占用的空间也就越小</font></p></li><li><p>索引最好设置为 NOT NULL：索引列要设置为 NOT NULL 约束；</p><ul><li><p>索引列存在 NULL 就<strong>会导致优化器在做索引选择的时候更加复杂</strong>，更加难以优化，因为可为 NULL 的列会使索引、索引统计和值比较都更复杂，比如进行索引统计时，count 会省略值为 NULL 的行。</p></li><li><p>NULL 值是一个没意义的值，但是它<strong>会占用物理空间</strong>，所以会带来的存储空间的问题，因为 InnoDB 存储记录的时候，如果表中存在允许为 NULL 的字段，那么行格式 (opens new window)中至少会用 1 字节空间存储 NULL 值列表，</p></li></ul></li><li><p>防止索引失效；</p><p> 发生索引失效的情况：</p><ul><li><pre><code>当我们使用**左或者左右模糊匹配**的时候，也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效；</code></pre></li><li><pre><code>当我们在查询条件中**对索引列做了计算、函数、类型转换操作**，这些情况下都会造成索引失效；</code></pre></li><li><pre><code>**联合索引要能正确使用需要遵循最左匹配原则**，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。</code></pre></li><li><pre><code>在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。</code></pre></li></ul></li></ol><h2 id="4-InnoDB-是如何存储数据的？"><a href="#4-InnoDB-是如何存储数据的？" class="headerlink" title="4.InnoDB 是如何存储数据的？"></a>4.InnoDB 是如何存储数据的？</h2><p>InnoDB 的数据是按「数据页」为单位来读写的（数据库的 I&#x2F;O 操作的最小单位是页，InnoDB 数据页的默认大小是 16KB），每个数据页之间通过<strong>双向链表</strong>的形式组织起来，物理上不连续，但是逻辑上连续；</p><p>数据页内包含用户记录，每个记录之间用<strong>单向链表</strong>的方式组织起来，为了加快在数据页内高效查询记录，设计了一个<strong>页目录</strong>，页目录存储各个槽（分组），且主键值是有序的，于是可以通过二分查找法的方式进行检索从而提高效率。</p><blockquote><p><strong>页目录就是由多个槽组成的，槽相当于分组记录的索引</strong>。然后，因为记录是按照「主键值」从小到大排序的，所以我们通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录，无需从最小记录开始遍历整个页中的记录链表。</p></blockquote><h2 id="5-B-树是如何进行查询的？"><a href="#5-B-树是如何进行查询的？" class="headerlink" title="5.B+ 树是如何进行查询的？"></a>5.B+ 树是如何进行查询的？</h2><ul><li>只有叶子节点（最底层的节点）才存放了数据，非叶子节点（其他上层节）仅用来存放目录项作为索引。</li><li>非叶子节点分为不同层次，通过分层来降低每一层的搜索量；</li><li>所有节点按照索引键大小排序，构成一个双向链表，便于范围查询；</li></ul><p>如果叶子节点存储的是实际数据的就是聚簇索引，一个表只能有一个聚簇索引；如果叶子节点存储的不是实际数据，而是主键值则就是二级索引，一个表中可以有多个二级索引。</p><p>在使用二级索引进行查找数据时，如果查询的数据能在二级索引找到，那么就是「索引覆盖」操作，如果查询的数据不在二级索引里，就需要先在二级索引找到主键值，需要去聚簇索引中获得数据行，这个过程就叫作「回表」。</p><h2 id="6-为什么-MySQL-默认的存储引擎-InnoDB-采用的是-B-作为索引的数据结构？"><a href="#6-为什么-MySQL-默认的存储引擎-InnoDB-采用的是-B-作为索引的数据结构？" class="headerlink" title="6.为什么 MySQL 默认的存储引擎 InnoDB 采用的是 B+ 作为索引的数据结构？"></a>6.为什么 MySQL 默认的存储引擎 InnoDB 采用的是 B+ 作为索引的数据结构？</h2><p><font color="#F100">数据库的索引是保存到磁盘上的，因此当我们通过索引查找某行数据的时候，就需要先从磁盘读取索引到内存，再通过索引从磁盘中找到某行数据，然后读入到内存，也就是说查询过程中会发生多次磁盘 I&#x2F;O，而磁盘 I&#x2F;O 次数越多，所消耗的时间也就越大。</font></p><blockquote><p>磁盘读写的最小单位是扇区，扇区的大小只有 512B 大小，操作系统一次会读写多个扇区，所以操作系统的最小读写单位是<strong>块（Block）</strong>。Linux 中的块大小为 4KB，也就是一次磁盘 I&#x2F;O 操作会直接读写 8 个扇区。</p></blockquote><p>B 树，不再限制一个节点就只能有 2 个子节点，而是允许 M 个子节点 (M&gt;2)，从而降低树的高度。<strong>当树的节点越多的时候，并且树的分叉数 M 越大的时候，M 叉树的高度会远小于二叉树的高度。</strong></p><ul><li>B 树的每个节点都包含数据（索引+记录），而用户的记录数据的大小很有可能远远超过了索引数据，这就需要花费更多的磁盘 I&#x2F;O 操作次数来读到「有用的索引数据」。</li><li>而且，在我们查询位于底层的某个节点（比如 A 记录）过程中，「<strong>非 A 记录节点」里的记录数据会从磁盘加载到内存</strong>，但是这些记录数据是没用的，我们只是想读取这些节点的索引数据来做比较查询，而「非 A 记录节点」里的记录数据对我们是没用的，这样不仅增多磁盘 I&#x2F;O 操作次数，也占用内存资源。</li></ul><p>B+ 树：</p><ol><li>叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引；</li><li>所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表；</li><li>非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。</li><li>非叶子节点中有多少个子节点，就有多少个索引；</li></ol><p><strong>B+ 和 B 树的性能区别：</strong></p><ul><li><strong>单点查询</strong>：B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I&#x2F;O次数会更少；</li><li><strong>插入和删除效率</strong>：B+ 树有大量的冗余节点，B + 树的插入和删除不需要变形，效率更高；</li><li><strong>范围查询</strong>： B+ 树所有叶子节点间还有一个链表进行连接，这种设计对范围查找非常有帮助；</li></ul><p>MySQL 中的 B+ 树特点：</p><ul><li>B+ 树的叶子节点之间是用「双向链表」进行连接，这样的好处是既能向右遍历，也能向左遍历。</li><li>B+ 树点节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB。</li></ul><p>总结：</p><ol><li>B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I&#x2F;O次数会更少。</li><li>B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；</li><li>B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I&#x2F;O 操作，范围查询效率不如 B+ 树。</li></ol><h2 id="7-为什么树的深度越深，IO次数越多？"><a href="#7-为什么树的深度越深，IO次数越多？" class="headerlink" title="7.为什么树的深度越深，IO次数越多？"></a>7.为什么树的深度越深，IO次数越多？</h2><p>树往往是用来存储数据的，树的一个节点往往对应着一个磁盘块，节点中可以存放数据，也可以存放指针（指针的指向就是节点对应的数据在磁盘中的位置），往往遍历获取树中数据的时候，我们就要与磁盘进行IO(读写操作)，而树的深度越深，那对应的节点不就越多，遍历时进行的IO操作也就越多。</p><h2 id="8-页的数据结构？"><a href="#8-页的数据结构？" class="headerlink" title="8.页的数据结构？"></a>8.页的数据结构？</h2><p><img src="https://github.com/Feidashen1/Feidashen1.github.io/blob/hexo/source/img/%E9%A1%B5%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%841.jpg" alt="页的数据结构"><br><img src="https://github.com/Feidashen1/Feidashen1.github.io/blob/hexo/source/img/%E9%A1%B5%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%842.jpg" alt="页的数据结构"></p><p>在 File Header 中有两个指针，分别指向上一个数据页和下一个数据页，连接起来的页相当于一个双向的链表，采用链表的结构是让数据页之间不需要是物理上的连续的，而是逻辑上的连续。</p><p>数据页中的记录按照「主键」顺序组成单向链表，单向链表的特点就是插入、删除非常方便，但是检索效率不高，最差的情况下需要遍历链表上的所有节点才能完成检索。</p><p>因此，数据页中有一个页目录，起到记录的索引作用。</p><p>页目录创建的过程如下：</p><ol><li>将所有的记录划分成几个组，这些记录包括最小记录和最大记录，但不包括标记为“已删除”的记录；</li><li>每个记录组的最后一条记录就是组内最大的那条记录，并且最后一条记录的头信息中会存储该组一共有多少条记录，作为 n_owned 字段；</li><li>页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），<strong>每个槽相当于指针指向了不同组的最后一个记录</strong>。</li></ol><h2 id="9-索引失效有哪些？"><a href="#9-索引失效有哪些？" class="headerlink" title="9.索引失效有哪些？"></a>9.索引失效有哪些？</h2><ul><li>当我们使用左或者左右模糊匹配的时候，也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效；</li><li>当我们在查询条件中对索引列使用函数，就会导致索引失效（因为索引保存的是索引字段的原始值，而不是经过函数计算后的值）。</li><li>当我们在查询条件中对索引列进行表达式计算，也是无法走索引的（索引保存的是索引字段的原始值，而不是 id + 1 表达式计算后的值）。</li><li>MySQL 在遇到字符串和数字比较的时候，会<strong>自动把字符串转为数字</strong>，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。</li><li>联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效（数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序）。</li><li>在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效（ OR 的含义就是两个只要满足一个即可，因此只有一个条件列是索引列是没有意义的）。</li></ul><blockquote><p><strong>索引下推功能</strong>：可以在存储引擎层进行索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，再返还给 Server 层，从而减少回表次数。</p><p><strong>索引下推</strong>的大概原理是：截断的字段不会在 Server 层进行条件判断，而是会被下推到「存储引擎层」进行条件判断（因为 c 字段的值是在 (a, b, c) 联合索引里的），然后过滤出符合条件的数据后再返回给 Server 层。由于在引擎层就过滤掉大量的数据，无需再回表读取数据来进行判断，减少回表次数，从而提升了性能。</p></blockquote><h2 id="10-MySQL-使用-like-“-x“，索引一定会失效吗？"><a href="#10-MySQL-使用-like-“-x“，索引一定会失效吗？" class="headerlink" title="10.MySQL 使用 like “%x“，索引一定会失效吗？"></a>10.MySQL 使用 like “%x“，索引一定会失效吗？</h2><p>不一定，使用左模糊匹配（like “%xx”）并不一定会走全表扫描，关键还是看数据表中的字段。</p><p>如果数据库表中的字段只有主键+二级索引，那么即使使用了左模糊匹配，也不会走全表扫描（type&#x3D;all），而是走全扫描二级索引树(type&#x3D;index)。</p><p>这张表的字段没有「非索引」字段，所以 select * 相当于 select id,name，然后这个查询的数据都在二级索引的 B+ 树，因为二级索引的 B+ 树的叶子节点包含「索引值+主键值」，所以查二级索引的 B+ 树就能查到全部结果了，这个就是覆盖索引。</p><h2 id="11-count-和-count-1-有什么区别？哪个性能最好？"><a href="#11-count-和-count-1-有什么区别？哪个性能最好？" class="headerlink" title="11.count(*) 和 count(1) 有什么区别？哪个性能最好？"></a>11.count(*) 和 count(1) 有什么区别？哪个性能最好？</h2><p><code>count() </code>是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是<strong>统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个</strong>。</p><ul><li>count（1）:常见计数方式，统计目标表的记录行数。括号里表示一个固定值，可以是任何固定的数字字符，是个常量。</li><li>count（*）:常见计数方式，统计目标表的记录行数，与count（1）执行结果相同，但是执行会根据目标表的不同进行优化。</li><li>count（列名）:常见计数方式，统计目标表某一列的非空记录数。它会统计指定列中不为NULL的行数，忽略NULL值。</li><li>count(distinct(列名)) ：其实是 count(列名) + distinct 的结果集，指定列不为NULL，并且在字段值重复的情况下只统计一次</li></ul><blockquote><p>count(1)其实是在统计表中有多少个记录。</p></blockquote><blockquote><p><code>count(*) </code>其实等于 count(0)，也就是说，当你使用 count(*) 时，MySQL 会将 * 参数转化为参数 0 来处理</p></blockquote><p><font color = "#F100">COUNT(*) &#x3D; COUNT(1) &gt; COUNT(字段)（存在二级索引）&gt; COUNT(主键字段)（仅存在主键索引）&gt;COUNT（非主键字段）（不存在二级索引）</font></p><blockquote><p>同数量的二级索引记录可以比聚簇索引记录占用更少的存储空间，所以二级索引树比聚簇索引树小，这样遍历二级索引的 I&#x2F;O 成本比遍历聚簇索引的 I&#x2F;O 成本小，因此「优化器」优先选择的是二级索引。</p></blockquote><p><code>count（*）</code>和<code>count（1）</code>执行机制存在差异，count（）函数在传入<code>*，1，2，&#39;abc&#39;</code>等值都会返回相同的结果；区别在于<code>count（*）</code>在传入<code>*</code>时，MySQL优化器会找到最小的那棵索引树进行遍历.</p><p>对于 count(1) 和 <code>count(*)</code> ，效率相当，建议尽量使用 <code>count(*)</code>，因为 MySQL 优化器会选择最小的索引树进行统计，针对此操作进行优化。</p><h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><h2 id="1-事务有哪些特性？"><a href="#1-事务有哪些特性？" class="headerlink" title="1.事务有哪些特性？"></a>1.事务有哪些特性？</h2><ul><li><strong>原子性（Atomicity）</strong>：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态;</li><li><strong>一致性（Consistency）</strong>：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。</li><li><strong>隔离性（Isolation）</strong>：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。</li><li><strong>持久性（Durability）</strong>：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</li></ul><blockquote><p>InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？</p></blockquote><blockquote><ul><li>持久性是通过 redo log （重做日志）来保证的；</li></ul></blockquote><ul><li>原子性是通过 undo log（回滚日志） 来保证的；</li><li>隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；</li><li>一致性则是通过持久性+原子性+隔离性来保证；</li></ul><h2 id="2-并行事务会引发什么问题？"><a href="#2-并行事务会引发什么问题？" class="headerlink" title="2.并行事务会引发什么问题？"></a>2.并行事务会引发什么问题？</h2><ul><li><strong>脏读</strong>：一个事务「读到」了另一个「未提交事务修改过的数据」；</li><li><strong>不可重复读</strong>：在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况；</li><li><strong>幻读</strong>：在一个事务内多次查询某个符合查询条件的「记录数量」，前后两次查询到的记录数量不一样。</li></ul><p><font color="#F100">严重性排序：脏读 &gt; 不可重复读 &gt; 幻读</font></p><p>SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低:</p><ol><li><strong>读未提交（read uncommitted）</strong>：指一个事务还没提交时，它做的变更就能被其他事务看到；</li><li><strong>读提交（read committed）</strong>：指一个事务提交之后，它做的变更才能被其他事务看到；</li><li><strong>可重复读（repeatable read）</strong>：指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别；</li><li><strong>串行化（serializable ）</strong>：会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；</li></ol><p><font color="#F100">按隔离水平高低排序如下：串行化 &gt; 可重复读 &gt; 读已提交 &gt; 读未提交</font></p><ul><li>在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象；</li><li>在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象；</li><li>在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象；</li><li>在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。</li></ul><h2 id="3-隔离级别具体是如何实现的？"><a href="#3-隔离级别具体是如何实现的？" class="headerlink" title="3.隔离级别具体是如何实现的？"></a>3.隔离级别具体是如何实现的？</h2><ol><li>对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以<strong>直接读取最新的数据</strong>就好了；</li><li>对于「串行化」隔离级别的事务来说，通过加<strong>读写锁</strong>的方式来避免并行访问；</li><li>对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在「<strong>每个语句执行前</strong>」都会重新生成一个 Read View，而「可重复读」隔离级别是「<strong>启动事务时</strong>」生成一个 Read View，然后整个事务期间都在用这个 Read View。</li></ol><h2 id="4-Read-View-在-MVCC-里如何工作的？"><a href="#4-Read-View-在-MVCC-里如何工作的？" class="headerlink" title="4.Read View 在 MVCC 里如何工作的？"></a>4.Read View 在 MVCC 里如何工作的？</h2><p><img src="https://raw.githubusercontent.com/Feidashen1/Feidashen1.github.io/hexo/source/img/ReadView%E5%9B%9B%E4%B8%AA%E5%AD%97%E6%AE%B5.jpg" alt="页的数据结构"></p><p>Read View 有四个重要的字段：</p><ol><li>m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表，注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务。</li><li>min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务，也就是 m_ids 的最小值。</li><li>max_trx_id ：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1；</li><li>creator_trx_id ：指的是创建该 Read View 的事务的事务 id。</li></ol><p>对于使用 InnoDB 存储引擎的数据库表，它的聚簇索引记录中都包含下面两个隐藏列：</p><ul><li>trx_id，当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里；</li><li>roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录；</li></ul><p>一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：</p><ol><li>如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在<strong>创建 Read View 前</strong>已经提交的事务生成的，所以该版本的记录对当前事务<strong>可见</strong>。</li><li>如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在<strong>创建 Read View 后</strong>才启动的事务生成的，所以该版本的记录对当前事务<strong>不可见</strong>。</li><li>如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中：<ol><li>如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。</li><li>如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。</li></ol></li></ol><p>这种<strong>通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC</strong>（多版本并发控制）。</p><h2 id="5-MySQL-可重复读隔离级别，完全解决幻读了吗？"><a href="#5-MySQL-可重复读隔离级别，完全解决幻读了吗？" class="headerlink" title="5.MySQL 可重复读隔离级别，完全解决幻读了吗？"></a>5.MySQL 可重复读隔离级别，完全解决幻读了吗？</h2><p>MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了），解决的方案有两种：</p><ul><li>针对<strong>快照读</strong>（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。</li><li>针对<strong>当前读</strong>（select … for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。</li></ul><blockquote><p>对于快照读， MVCC 并不能完全避免幻读现象。因为当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读。</p></blockquote><blockquote><p>对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。</p></blockquote><p><strong>MySQL 可重复读隔离级别并没有彻底解决幻读，只是很大程度上避免了幻读现象的发生。</strong></p><p><font color="#F100">要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select … for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。</font></p><hr><h1 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h1><p>##1.MySQL 有哪些锁？</p><p><strong>1.全局锁</strong></p><p>执行后，整个数据库就处于只读状态了，这时其他线程执行以下操作，都会被阻塞；</p><pre><code>flush tables with read lockunlock tables</code></pre><p>全局锁主要应用于做全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。</p><p><strong>2.表级锁</strong></p><ul><li><strong>表锁</strong>：表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作（表锁的颗粒度太大，会影响并发性能）；</li><li><strong>元数据锁（MDL）</strong>：保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更（对数据库表进行操作时，会自动给这个表加上 MDL，事务执行期间，MDL 是一直持有的）;<ul><li>申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁</li></ul></li><li><strong>意向锁</strong>：意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables … read）和独占表锁（lock tables … write）发生冲突（意向锁的目的是为了快速判断表里是否有记录被加锁）；<ul><li>   如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢 ；在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。</li></ul></li><li><strong>AUTO-INC 锁</strong>：特殊的表锁机制，锁不是在一个事务提交后才释放，而是在执行完插入语句后就会立即释放；<ul><li>在插入数据时，会加一个表级别的 AUTO-INC 锁，然后为被 AUTO_INCREMENT 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉；</li></ul></li></ul><p><strong>3.行级锁</strong></p><p>nnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁</p><ul><li><strong>Record Lock</strong>，记录锁，也就是仅仅把一条记录锁上；</li><li><strong>Gap Lock</strong>，间隙锁，锁定一个范围，但是不包含记录本身（只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象）；</li><li><strong>Next-Key Lock</strong>：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。</li><li><strong>插入意向锁</strong>：一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。<br>如果有的话，插入操作就会发生阻塞，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新记录，但是现在处于等待状态。(插入意向锁名字虽然有意向锁，但是它并不是意向锁，它是一种<strong>特殊的间隙锁</strong>，属于行级别锁。)</li></ul><p><font color="#F100">MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁</font></p><p>如果说间隙锁锁住的是一个区间，那么<strong>「插入意向锁」锁住的就是一个点</strong>。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。</p><p>插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却<strong>不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁</strong>（当然，插入意向锁如果不在间隙锁区间内则是可以的）</p><h2 id="2-MySQL是怎么加锁的？"><a href="#2-MySQL是怎么加锁的？" class="headerlink" title="2.MySQL是怎么加锁的？"></a>2.MySQL是怎么加锁的？</h2><p>1.唯一索引等值查询：</p><ul><li>当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会退化成「记录锁」。</li><li>当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会退化成「间隙锁」</li></ul><p>2.非唯一索引等值查询：</p><ul><li>当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁。</li><li>当查询的记录「不存在」时，扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁。</li></ul><p><strong>非唯一索引和主键索引的范围查询的加锁规则不同之处在于：</strong></p><ul><li>唯一索引在满足一些条件的时候，索引的 next-key lock 退化为间隙锁或者记录锁。</li><li>非唯一索引范围查询，索引的 next-key lock 不会退化为间隙锁和记录锁。</li></ul><p>3.没有加索引的查询</p><p>执行 update、delete、select … for update 等具有加锁性质的语句，没有使用索引列作为查询条件，或者没有走索引，导致扫描是<strong>全表扫描</strong>。那么，每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞。</p><h2 id="3-update-没加索引会锁全表？"><a href="#3-update-没加索引会锁全表？" class="headerlink" title="3.update 没加索引会锁全表？"></a>3.update 没加索引会锁全表？</h2><p>当我们要执行 update 语句的时候，确保 where 条件中带上了索引列，并且在测试机确认该语句是否走的是索引扫描，防止因为扫描全表，而对表中的所有记录加上锁。</p><p>我们可以打开 MySQL <code>sql_safe_updates</code> 参数，这样可以预防 update 操作时 where 条件没有带上索引列。</p><p>如果发现即使在 where 条件中带上了列索引列，优化器走的还是全标扫描，这时我们就要使用 force index([index_name]) 可以告诉优化器使用哪个索引。</p><h2 id="4-MySQL-记录锁-间隙锁可以防止删除操作而导致的幻读吗？"><a href="#4-MySQL-记录锁-间隙锁可以防止删除操作而导致的幻读吗？" class="headerlink" title="4.MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗？"></a>4.MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗？</h2><p>在 MySQL 的可重复读隔离级别下，针对当前读的语句会对索引加记录锁+间隙锁，这样可以避免其他事务执行增、删、改时导致幻读的问题。</p><p>有一点要注意的是，在执行 update、delete、select … for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了，这是挺严重的问题。</p><h2 id="5-MySQL-死锁了，怎么办？"><a href="#5-MySQL-死锁了，怎么办？" class="headerlink" title="5.MySQL 死锁了，怎么办？"></a>5.MySQL 死锁了，怎么办？</h2><p>行锁的释放时机是在事务提交（commit）后，锁就会被释放，并不是一条语句执行完就释放行锁。</p><p><strong>MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁。</strong></p><p>死锁的四个必要条件：<strong>互斥、占有且等待、不可强占用、循环等待</strong>。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。</p><p>在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态：</p><ul><li><strong>设置事务等待锁的超时时间</strong>。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 <code>innodb_lock_wait_timeout</code> 是用来设置超时时间的，默认值时 50 秒。</li><li><strong>开启主动死锁检测</strong>。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 <code>innodb_deadlock_detect</code> 设置为 on，表示开启这个逻辑，默认就开启。</li></ul><p>两个事务即使生成的间隙锁的范围是一样的，也不会发生冲突，因为间隙锁目的是为了防止其他事务插入数据，因此间隙锁与间隙锁之间是相互兼容的。</p><blockquote><p>next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。</p></blockquote><p>在执行插入语句时，如果插入的记录在其他事务持有间隙锁范围内，插入语句就会被阻塞，因为插入语句在碰到间隙锁时，会生成一个插入意向锁，然后<strong>插入意向锁和间隙锁之间是互斥的关系</strong>。</p><p><font color="#F00">如果两个事务分别向对方持有的间隙锁范围内插入一条记录，而插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，满足了死锁的四个条件：互斥、占有且等待、不可强占用、循环等待，因此发生了死锁。</font></p><h1 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h1><h2 id="1-执行一条-update-语句，期间发生了什么？"><a href="#1-执行一条-update-语句，期间发生了什么？" class="headerlink" title="1.执行一条 update 语句，期间发生了什么？"></a>1.执行一条 update 语句，期间发生了什么？</h2><pre><code>UPDATE t_user SET name = &#39;xiaolin&#39; WHERE id = 1;</code></pre><ol><li>客户端先通过连接器建立连接，连接器自会判断用户身份；</li><li>因为这是一条 update 语句，所以不需要经过查询缓存，但是表上有更新语句，是会把整个表的查询缓存清空的，所以说查询缓存很鸡肋，在 MySQL 8.0 就被移除这个功能了；</li><li>解析器会通过词法分析识别出关键字 update，表名等等，构建出语法树，接着还会做语法分析，判断输入的语句是否符合 MySQL 语法；</li><li>预处理器会判断表和字段是否存在；</li><li>优化器确定执行计划，因为 where 条件中的 id 是主键索引，所以决定要使用 id 这个索引；</li><li>执行器负责具体执行，找到这一行，然后更新。</li></ol><blockquote><p>更新语句的流程会涉及到 undo log（回滚日志）、redo log（重做日志） 、binlog （归档日志）这三种日志：</p><ul><li>undo log（回滚日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC。</li><li>redo log（重做日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复；</li><li>binlog （归档日志）：是 Server 层生成的日志，主要用于数据备份和主从复制；</li></ul></blockquote><h2 id="2-为什么需要-undo-log？"><a href="#2-为什么需要-undo-log？" class="headerlink" title="2.为什么需要 undo log？"></a>2.为什么需要 undo log？</h2><ul><li><strong>实现事务回滚，保障事务的原子性</strong>。事务处理过程中，如果出现了错误或者用户执行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。</li><li><strong>实现 MVCC（多版本并发控制）关键因素之一</strong>。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。</li></ul><blockquote><p>Undo 页是记录什么？</p></blockquote><blockquote><p>开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。</p></blockquote><h2 id="3-为什么需要-Buffer-Pool？"><a href="#3-为什么需要-Buffer-Pool？" class="headerlink" title="3.为什么需要 Buffer Pool？"></a>3.为什么需要 Buffer Pool？</h2><p>Innodb 存储引擎设计了一个缓冲池（Buffer Pool），来<strong>提高数据库的读写性能</strong>。</p><ul><li>当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取；</li><li>当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I&#x2F;O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘；</li></ul><p>在 MySQL 启动的时候，<strong>InnoDB 会为 Buffer Pool 申请一片连续的内存空间</strong>，然后按照默认的 <code>16KB</code> 的大小划分出一个个的页， Buffer Pool 中的页就叫做<strong>缓存页</strong>。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。</p><p>当我们查询一条记录时，InnoDB 是会把<strong>整个页</strong>的数据加载到 Buffer Pool 中，将页加载到 Buffer Pool 后，再通过页里的「<strong>页目录</strong>」去定位到某条具体的记录。</p><h2 id="4-为什么需要-redo-log-？"><a href="#4-为什么需要-redo-log-？" class="headerlink" title="4.为什么需要 redo log ？"></a>4.为什么需要 redo log ？</h2><p>为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先<strong>更新内存</strong>（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，这个时候更新就算完成了。</p><p>后续，InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 WAL （Write-Ahead Logging）技术。</p><blockquote><p><font color="#F100">WAL 技术指的是， <strong>MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上</strong>。 </font></p></blockquote><p>redo log 是<strong>物理日志</strong>，记录了某个数据页做了什么修改，比如<strong>对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新</strong>，每当执行一个事务就会产生这样的一条或者多条物理日志。</p><p>1.<strong>实现事务的持久性，让 MySQL 有 crash-safe 的能力</strong>，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失:</p><ul><li>在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。</li><li>当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。</li></ul><p>2.<strong>将写操作从「随机写」变成了「顺序写」</strong>，提升 MySQL 写入磁盘的性能：</p><ul><li>写入 redo log 的方式使用了追加操作， 所以磁盘操作是顺序写，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是随机写。磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。</li></ul><blockquote><p>实际上， 执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I&#x2F;O 操作，而且磁盘的运行速度远慢于内存。</p><p>所以，redo log 也有自己的缓存—— redo log buffer（默认大小 16 MB），每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘</p></blockquote><h2 id="5-redo-log-和-undo-log-区别在哪？"><a href="#5-redo-log-和-undo-log-区别在哪？" class="headerlink" title="5.redo log 和 undo log 区别在哪？"></a>5.redo log 和 undo log 区别在哪？</h2><p>这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于：</p><ul><li>redo log 记录了此次事务「<strong>完成后</strong>」的数据状态，记录的是更新<strong>之后</strong>的值；</li><li>undo log 记录了此次事务「<strong>开始前</strong>」的数据状态，记录的是更新<strong>之前</strong>的值；</li></ul><p>事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务.</p><h2 id="6-redo-log-什么时候刷盘？"><a href="#6-redo-log-什么时候刷盘？" class="headerlink" title="6.redo log 什么时候刷盘？"></a>6.redo log 什么时候刷盘？</h2><ul><li>MySQL 正常关闭时；</li><li>当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；</li><li>InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。</li><li>每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘。</li></ul><p>数据安全性和写入性能是熊掌不可得兼的，要不追求数据安全性，牺牲性能；要不追求性能，牺牲数据安全性。</p><h2 id="7-redo-log-文件写满了怎么办？"><a href="#7-redo-log-文件写满了怎么办？" class="headerlink" title="7.redo log 文件写满了怎么办？"></a>7.redo log 文件写满了怎么办？</h2><p>默认情况下， InnoDB 存储引擎有 1 个重做日志文件组( redo log Group），「重做日志文件组」由有 2 个 redo log 文件组成，这两个 redo 日志的文件名叫 ：<code>ib_logfile0</code> 和 <code>ib_logfile1</code>。</p><p>在重做日志组中，每个 redo log File 的大小是固定且一致的；</p><p>重做日志文件组是以循环写的方式工作的，从头开始写，写到末尾就又回到开头，相当于一个环形。</p><p>InnoDB 存储引擎会先写 <code>ib_logfile0</code> 文件，当 <code>ib_logfile0</code> 文件被写满的时候，会切换至 <code>ib_logfile1</code> 文件，当 <code>ib_logfile1</code> 文件也被写满时，会切换回 <code>ib_logfile0</code> 文件。</p><p>redo log 是循环写的方式，相当于一个环形，InnoDB 用 write pos 表示 redo log 当前记录写到的位置，用 check point 表示当前要擦除的位置，</p><p>如果 write pos 追上了 check point，就意味着 <strong>redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞</strong>（因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要），此时会停<strong>下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针）</strong>，然后 MySQL 恢复正常运行，继续执行新的更新操作。</p><h2 id="8-为什么需要-binlog-？"><a href="#8-为什么需要-binlog-？" class="headerlink" title="8.为什么需要 binlog ？"></a>8.为什么需要 binlog ？</h2><p>undo log 和 redo log 这两个日志都是 Innodb 存储引擎生成的。</p><p>MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。</p><p>binlog 文件是记录了<strong>所有数据库表结构变更和表数据修改的日志</strong>，不会记录查询类的操作，比如 SELECT 和 SHOW 操作。</p><p><strong>redo log 和 binlog 有什么区别？</strong></p><ol><li><p><strong>适用对象不同：</strong></p><ul><li>binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；</li><li>redo log 是 Innodb 存储引擎实现的日志；</li></ul></li><li><p><strong>文件格式不同：</strong></p><ul><li>binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）【每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志）），主从复制中 slave 端再根据 SQL 语句重现】、ROW【记录行数据最终被修改成什么样了】、 MIXED【包含了 STATEMENT 和 ROW 模式】</li><li>redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；</li></ul></li><li><p><strong>写入方式不同：</strong></p><ul><li>binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。</li><li>redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。</li></ul></li><li><p><strong>用途不同：</strong></p><ul><li>binlog 用于备份恢复、主从复制；</li><li>redo log 用于掉电等故障恢复。</li></ul></li></ol><h2 id="9-主从复制是怎么实现？"><a href="#9-主从复制是怎么实现？" class="headerlink" title="9.主从复制是怎么实现？"></a>9.主从复制是怎么实现？</h2><p>MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。</p><p>这个过程一般是异步的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。</p><p>MySQL 集群的主从复制过程梳理成 3 个阶段：</p><ul><li><strong>写入 Binlog</strong>：主库写 binlog 日志，提交事务，并更新本地存储数据。</li><li><strong>同步 Binlog</strong>：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。</li><li><strong>回放 Binlog</strong>：回放 binlog，并更新存储引擎中的数据。</li></ul><p>具体过程：</p><ol><li>MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。</li><li>从库会创建一个专门的 I&#x2F;O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。</li><li>从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。</li></ol><h2 id="10-事务提交为什么需要两阶段提交？"><a href="#10-事务提交为什么需要两阶段提交？" class="headerlink" title="10.事务提交为什么需要两阶段提交？"></a>10.事务提交为什么需要两阶段提交？</h2><p>避免出现两份日志之间的逻辑不一致的问题</p><p>在持久化 redo log 和 binlog 这两份日志的时候，如果出现<strong>半成功</strong>的状态，就会造成主从环境的数据不一致性。这是因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。</p><p>两阶段提交其实是<strong>分布式事务一致性协议</strong>，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态。</p><p>两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。</p><blockquote><p>在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog 日志与 InnoDB 的 redo log，为了保证这两个日志的一致性，MySQL 使用了<strong>内部 XA 事务</strong>，<strong>内部 XA 事务由 binlog 作为协调者，存储引擎是参与者</strong>。</p></blockquote><p>事务的提交过程有两个阶段，就是将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog，具体如下：</p><ul><li><strong>prepare 阶段</strong>：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit &#x3D; 1 的作用）；</li><li><strong>commit 阶段</strong>：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog &#x3D; 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；</li></ul><p><font color="#F100">两阶段提交是以 binlog 写成功为事务提交成功的标识，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID</font></p><h2 id="11-两阶段提交有什么问题？"><a href="#11-两阶段提交有什么问题？" class="headerlink" title="11.两阶段提交有什么问题？"></a>11.两阶段提交有什么问题？</h2><p>两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差，主要有两个方面的影响：</p><ul><li><strong>磁盘 I&#x2F;O 次数高</strong>：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。</li><li><strong>锁竞争激烈</strong>：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。</li></ul><p><strong>MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I&#x2F;O 的次数</strong></p><p>引入了组提交机制后，prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程：</p><ul><li>flush 阶段：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）【用于支撑 redo log 的组提交】；</li><li>sync 阶段：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）【组合更多事务的 binlog，然后再一起刷盘】；</li><li>commit 阶段：各个事务按顺序做 InnoDB commit 操作；</li></ul><p>上面的每个阶段都有一个队列，每个阶段有锁进行保护，因此保证了事务写入的顺序，第一个进入队列的事务会成为 leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。</p><p>对每个阶段引入了队列后，锁就只针对每个队列进行保护，不再锁住提交事务的整</p><h2 id="12-具体更新一条记录-UPDATE-t-user-SET-name-xiaolin-WHERE-id-1-的流程"><a href="#12-具体更新一条记录-UPDATE-t-user-SET-name-xiaolin-WHERE-id-1-的流程" class="headerlink" title="12.具体更新一条记录 UPDATE t_user SET name = &#39;xiaolin&#39; WHERE id = 1; 的流程"></a>12.具体更新一条记录 <code>UPDATE t_user SET name = &#39;xiaolin&#39; WHERE id = 1;</code> 的流程</h2><ol><li>执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id &#x3D; 1 这一行记录：<ol><li>如果 id&#x3D;1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；</li><li>如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。</li></ol></li><li>执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：<ol><li>如果一样的话就不进行后续更新流程；</li><li>如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；</li></ol></li><li>开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。</li><li>InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I&#x2F;O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 WAL 技术，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。</li><li>至此，一条记录更新完了。</li><li>在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。</li><li>事务提交（为了方便说明，这里不说组提交的过程，只说两阶段提交）：<ol><li>prepare 阶段：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；</li><li>commit 阶段：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；</li></ol></li><li>至此，一条更新语句执行完成。</li></ol><h1 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h1><h2 id="1-为什么要有-Buffer-Pool？"><a href="#1-为什么要有-Buffer-Pool？" class="headerlink" title="1.为什么要有 Buffer Pool？"></a>1.为什么要有 Buffer Pool？</h2><ul><li>当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。</li><li>当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。</li></ul><blockquote><p>Buffer Pool 是在 MySQL 启动的时候，向操作系统申请的一片连<strong>续的内存空间</strong>，默认配置下 Buffer Pool 只有 128MB 。</p><p>可以通过调整 innodb_buffer_pool_size 参数来设置 Buffer Pool 的大小，一般建议设置成可用物理内存的 60%~80%</p></blockquote><p>InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，<strong>一个页的默认大小为 16KB</strong>。因此，<strong>Buffer Pool 同样需要按「页」来划分</strong>。Buffer Pool 中的页就叫做缓存页。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。</p><ul><li>Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等。</li><li>InnoDB 为每一个缓存页都创建了一个控制块，控制块信息包括「缓存页的表空间、页号、缓存页地址、链表节点」等等。控制块也是占有内存空间的，它是放在 Buffer Pool 的最前面，接着才是缓存页。</li></ul><p><strong>查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，因为，通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。</strong>将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。</p><h2 id="2-如何管理-Buffer-Pool？"><a href="#2-如何管理-Buffer-Pool？" class="headerlink" title="2.如何管理 Buffer Pool？"></a>2.如何管理 Buffer Pool？</h2><p><strong>1.空闲页</strong></p><p>使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为** Free 链表**（空闲链表）。</p><ul><li>Free 链表上除了有控制块，还有一个头节点，该头节点包含链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息。</li><li>每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。</li></ul><p><strong>2.脏页</strong></p><p><strong>Flush 链表</strong>，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。</p><p>有了 Flush 链表后，后台线程就可以遍历 Flush 链表，将脏页写入到磁盘。</p><p><strong>3.提高缓存命中率</strong></p><p>将 LRU 划分了 2 个区域：old 区域 和 young 区域，young 区域在 LRU 链表的前半部分，old 区域则是在后半部分；</p><ul><li>划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。（<strong>预读失效</strong>）</li><li>进入到 young 区域条件增加了一个停留在 old 区域的时间判断（<strong>Buffer Pool 污染</strong>）：<ul><li>如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该缓存页就不会被从 old 区域移动到 young 区域的头部；</li><li>如果后续的访问时间与第一次访问的时间不在某个时间间隔内，那么该缓存页移动到 young 区域的头部；</li></ul></li></ul><p><font color="#F100">每次访问都把预读的数据作为热点数据，排挤了原有的热点，导致预读失效，因此提高成为热点的门槛（二次访问才变热点）。可是全表扫描的的二次访问导致不需要的数据又挤走了热点，导致buff污染，因此继续提高变热门槛（二次访问间隔够长才能变热）</font></p><h2 id="3-会触发脏页刷新的几种情况"><a href="#3-会触发脏页刷新的几种情况" class="headerlink" title="3.会触发脏页刷新的几种情况"></a>3.会触发脏页刷新的几种情况</h2><ul><li>当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘；</li><li>Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘；</li><li>MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘；</li><li>MySQL 正常关闭之前，会把所有的脏页刷入到磁盘；</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基础&quot;&gt;&lt;a href=&quot;#基础&quot; class=&quot;headerlink&quot; title=&quot;基础&quot;&gt;&lt;/a&gt;基础&lt;/h1&gt;&lt;h2 id=&quot;1-MySQL-执行流程是怎样的？&quot;&gt;&lt;a href=&quot;#1-MySQL-执行流程是怎样的？&quot; class=&quot;headerlink</summary>
      
    
    
    
    
    <category term="Offer" scheme="http://example.com/tags/Offer/"/>
    
  </entry>
  
  <entry>
    <title>敏捷开发</title>
    <link href="http://example.com/2024/04/27/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/"/>
    <id>http://example.com/2024/04/27/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/</id>
    <published>2024-04-27T12:18:22.000Z</published>
    <updated>2024-04-27T12:49:28.577Z</updated>
    
    <content type="html"><![CDATA[<h1 id="敏捷或敏捷方法或敏捷过程定义"><a href="#敏捷或敏捷方法或敏捷过程定义" class="headerlink" title="敏捷或敏捷方法或敏捷过程定义"></a>敏捷或敏捷方法或敏捷过程定义</h1><p>顾名思义，敏捷方法论是一组方法和实践，其中软件开发和项目管理发生在称为冲刺的短开发周期中交付以客户为中心的产品。这是一种迭代方法，每次迭代都经过专门设计，体积小且易于管理，以便可以在特定的给定时间段内交付。敏捷方法对随时间变化的需求持开放态度，并鼓励最终用户不断反馈。这是最受欢迎的方法，因为在此过程中，客户也参与其中，以便他们可以获得有关其产品的更新，并确保他们是否满足其要求。</p><h1 id="基本敏捷面试问题"><a href="#基本敏捷面试问题" class="headerlink" title="基本敏捷面试问题"></a>基本敏捷面试问题</h1><h2 id="1-敏捷方法有哪些不同类型？"><a href="#1-敏捷方法有哪些不同类型？" class="headerlink" title="1. 敏捷方法有哪些不同类型？"></a>1. 敏捷方法有哪些不同类型？</h2><p><strong>Scrum（敏捷）</strong>：它用于建立假设，测试它们，反思经验，并进行调整。它在很大程度上取决于反馈、自我管理、小团队和分解为冲刺的工作。它依赖于增量开发。</p><p><strong>FDD（功能驱动开发）</strong>：它通常涉及每两周创建一次软件模型，并且还需要为每个模型功能进行开发和设计。它基本上是一个轻量级的迭代和增量软件开发过程，其主要目的是按时交付稳定且有效的软件。</p><p><strong>Lean Software Development（精益软件开发）</strong>：它基本上是一种最大限度地减少浪费和最大化价值的方法。它更注重流程效率，以实现客户价值的最佳结果。它完全基于两个指导原则，即尊重人和持续改进。</p><p><strong>XP（极限编程）</strong>：其主要目的是为开发团队生产更高质量的软件和更高质量的生活。它被认为是低风险，灵活的，是一种开发软件并确保客户获得所需内容的方法。在这种方法中，软件从第一天起就进行测试，收集反馈以改进开发过程。</p><p><strong>DSDM（动态软件开发方法）</strong>：它通常侧重于整个项目生命周期，主要目的是确保良好的治理作为项目管理的基础。它是用户驱动的，并相信对项目的修改总是在意料之中的。它还提供了在预算范围内按时交付产品的完整路线图。</p><p><strong>ASD（自适应系统开发）</strong>：它代表了项目应该始终处于持续适应状态的想法，并且具有三个重复序列的循环，即推测，协作和学习。</p><p><strong>Crystal Methodology（晶体方法）</strong>：它主要关注个人及其互动，而不是过程。它被认为是开发软件的最轻量级和最灵活的方法之一。它是一系列敏捷方法，包括不同的变体，如晶莹剔透、晶黄、晶橙和晶红。</p><p><strong>Kanban（看板）</strong>：看板项目通常通过看板或表（看板）进行管理。这个看板是一个工具，可以帮助团队成员密切关注工作流程以衡量其进度，并包括每个阶段需要对产品完成的所有信息及其完成路径。其主要目的是任务管理的灵活性、持续改进和增强的工作流程。</p><h2 id="2-敏捷过程的优缺点是什么？"><a href="#2-敏捷过程的优缺点是什么？" class="headerlink" title="2.敏捷过程的优缺点是什么？"></a>2.敏捷过程的优缺点是什么？</h2><p>使用敏捷过程有几个优点：</p><ul><li>很好地适应不断变化的需求</li><li>与团队成员和客户面对面对话</li><li>专注于卓越的技术和良好的设计</li><li>快速和持续的开发</li><li>实现客户和项目团队之间的协作和互动</li><li>确保和促进客户满意度</li><li>更快地从客户或最终用户获得反馈</li><li>快速识别并消除代码中发现的错误</li><li>将敏捷项目划分为冲刺或迭代，即通常长达 1-4 周的短且可重复的阶段</li><li>快速交付产品</li><li>易于管理，更灵活</li><li>最终目标可能是未知的：敏捷对于未定义目标的项目是有益的，随着项目的进展，目标变得更加明显。</li></ul><p>使用敏捷过程有几个缺点：</p><ul><li>缺乏正式的文档和设计</li><li>难以估计资源需求和工作量</li><li>不适合小型开发项目</li><li>与其他开发方法相比成本高昂</li><li>需要每个人投入更多的时间和精力</li><li>项目永恒的风险</li><li>难以扩展大型项目</li><li>测试和测试施工困难。</li></ul><h2 id="3-解释敏捷测试？敏捷测试的原则是什么？"><a href="#3-解释敏捷测试？敏捷测试的原则是什么？" class="headerlink" title="3.解释敏捷测试？敏捷测试的原则是什么？"></a>3.解释敏捷测试？敏捷测试的原则是什么？</h2><p>顾名思义，敏捷测试是一个软件测试过程，其中软件针对任何缺陷、错误或其他问题进行测试。它被认为是开发过程的核心部分，因为它使测试人员和开发人员能够作为一个团队一起工作，从而提高整体性能。它还有助于确保成功交付高质量的产品。通常执行测试，以便测试人员可以在开发过程的每个阶段及早识别和解决问题。</p><p>敏捷测试主要原则，如下所示：</p><ol><li>连续测试：测试应由敏捷团队持续进行，以确保持续的开发进度。</li><li>持续反馈：此过程通常鼓励从客户那里获得反馈，以确保产品满足客户或客户的要求。</li><li>团队合作或集体工作：不仅是测试人员，开发人员，业务分析师也可以执行软件测试或应用程序测试。</li><li>清洁代码：当团队测试软件以确保代码干净、简单和紧凑时，将保持软件质量。在测试阶段发现的所有错误和缺陷都会由敏捷团队在同一迭代中快速修复。</li><li>更少的文档：此过程通常涉及使用可重用的清单，而不是冗长的文档。</li><li>测试驱动：在其他传统方法中，测试仅在实现后执行，但在敏捷测试中，测试是在实现期间完成的，以便可以及时删除错误或任何问题。</li><li>客户满意度：在敏捷测试过程中，向客户或客户显示开发进度，以便他们可以调整和更新其需求。这样做是为了确保客户满意度。</li></ol><h2 id="4-敏捷测试人员应该具备哪些优秀品质？"><a href="#4-敏捷测试人员应该具备哪些优秀品质？" class="headerlink" title="4.敏捷测试人员应该具备哪些优秀品质？"></a>4.敏捷测试人员应该具备哪些优秀品质？</h2><ul><li>积极的态度和解决方案导向</li><li>专注于目标</li><li>优秀的沟通技巧</li><li>了解并满足客户需求</li><li>有关敏捷过程及其原则的基本知识</li><li>批判性和创造性思维</li><li>有效分享想法</li><li>根据需求计划和确定工作的优先级</li><li>应对变化</li></ul><h2 id="5-重构是什么意思？"><a href="#5-重构是什么意思？" class="headerlink" title="5.重构是什么意思？"></a>5.重构是什么意思？</h2><p>重构基本上是一种涉及改变或修改软件内部结构的活动，而不对其外部行为或功能进行任何更改。在这种情况下，开发人员进行一些更改或修改代码以增强和改进软件的内部结构。敏捷软件开发过程中最流行和广泛使用的重构技术之一是红绿。重构过程使代码更具可读性、可理解性和更简洁。重构的持续习惯有助于更轻松地扩展和维护代码。</p><h2 id="6-冲刺积压和产品积压有什么区别？"><a href="#6-冲刺积压和产品积压有什么区别？" class="headerlink" title="6.冲刺积压和产品积压有什么区别？"></a>6.冲刺积压和产品积压有什么区别？</h2><p><strong>冲刺积压工作</strong>：它通常由开发团队拥有。它仅包含与特定冲刺 （sprint） 相关的功能和要求。它被视为产品积压工作的子集。它由完成特定冲刺必须完成的所有操作一起编译而成。它仅包括在每个敏捷冲刺 （sprint） 期间可以完成的项目。它仅在特定冲刺中特定于冲刺目标。</p><p><strong>产品待办列表</strong>：它通常由项目所有者拥有和维护。它通常包含产品的每个功能以及产品的要求。它被编译为完成整个过程所必须完成的所有操作。它只是将每个项目分解为一系列步骤。它更具体地针对产品的最终目标。</p><h2 id="7-什么是敏捷中的冲刺和零冲刺？"><a href="#7-什么是敏捷中的冲刺和零冲刺？" class="headerlink" title="7.什么是敏捷中的冲刺和零冲刺？"></a>7.什么是敏捷中的冲刺和零冲刺？</h2><p><strong>冲刺</strong>：它通常是指软件开发中太大且复杂的用户故事，在开发团队运行限时调查之前无法估计。这些故事可用于各种活动，如研究、设计、探索、原型制作等。创建冲刺通常是为了解决项目中的一些技术问题和设计问题。</p><p><strong>零冲刺</strong>：它通常是指在第一个冲刺之前的第一步或预准备步骤。它包括所有活动，例如设置开发环境，准备积压工作等。</p><h2 id="8-敏捷方法和传统软件开发方法有什么区别？"><a href="#8-敏捷方法和传统软件开发方法有什么区别？" class="headerlink" title="8.敏捷方法和传统软件开发方法有什么区别？"></a>8.敏捷方法和传统软件开发方法有什么区别？</h2><p><strong>敏捷软件开发</strong>：它是一种迭代方法，用于设计复杂的软件。在这种方法中，项目团队可以更加灵活，并确保最终满足客户的要求。它开发以客户为中心的产品，并在更短的冲刺中交付。</p><p><strong>传统软件开发</strong>：它是一种线性方法，用于设计简单的软件。在这种方法中，过程的所有阶段通常按顺序发生。它更适合在范围内更改的可能性可以忽略不计的项目。</p><h2 id="9-敏捷中的“速度”一词是什么意思？"><a href="#9-敏捷中的“速度”一词是什么意思？" class="headerlink" title="9.敏捷中的“速度”一词是什么意思？"></a>9.敏捷中的“速度”一词是什么意思？</h2><p>速度基本上是一个度量单位，用于测量或计算敏捷开发团队在单个冲刺中可以成功完成多少工作以及完成项目需要多少时间。它被广泛用作校准工具，帮助开发团队创建准确有效的时间表。它还用于识别问题并衡量随时间推移而发生的改进。</p><h2 id="10-每日站立会议是什么意思？"><a href="#10-每日站立会议是什么意思？" class="headerlink" title="10.每日站立会议是什么意思？"></a>10.每日站立会议是什么意思？</h2><p>每日站立会议是敏捷团队所有成员之间的日常会议。它的主要目的是了解每个从事Scrum任务的团队成员的当前进度和表现。会议主要在上午举行，通常涉及产品所有者、开发人员和 Scrum 主管。</p><p>这些会议通常出于以下原因举行：</p><ul><li>要知道昨天做了什么，今天的计划是什么。</li><li>为了更好地理解目标。</li><li>确保每个团队成员都在朝着同一个目标努力。</li><li>将团队成员的问题集中起来，以便快速解决问题。</li><li>让每个人都了解最新信息并帮助团队保持井井有条。</li></ul><h2 id="11-什么是增量和迭代开发？"><a href="#11-什么是增量和迭代开发？" class="headerlink" title="11.什么是增量和迭代开发？"></a>11.什么是增量和迭代开发？</h2><p><strong>迭代开发</strong>：它基本上是一个软件开发过程，其中软件开发周期（冲刺和发布）重复，直到获得最终产品。根据客户或用户的反馈，再次以周期或发布和冲刺的方式开发产品，即以重复的方式添加新功能。</p><p><strong>增量开发</strong>：它基本上是一个软件开发过程，其中开发工作被切成增量或部分或部分。在这种情况下，软件是分段或增量开发和交付的，每个部分都有一套完整的功能。增量可以很小，也可以很大，每个增量都经过全面编码和测试。在测试每个增量之后，它们都被集成在一起，以便它们作为一个整体工作。</p><h2 id="12-什么是产品路线图？"><a href="#12-什么是产品路线图？" class="headerlink" title="12.什么是产品路线图？"></a>12.什么是产品路线图？</h2><p>顾名思义，产品路线图是一个强大的工具，可以描述产品如何随着时间的推移而增长。它是创建产品愿景的产品功能的整体视图。它还指示正在构建的开发内容，新产品将实现的业务目标，产品将解决的问题等。产品路线图归产品经理所有。它还鼓励开发团队共同努力，以实现成功交付产品的预期目标。</p><h2 id="13-敏捷中最常用的项目管理工具有哪些？"><a href="#13-敏捷中最常用的项目管理工具有哪些？" class="headerlink" title="13.敏捷中最常用的项目管理工具有哪些？"></a>13.敏捷中最常用的项目管理工具有哪些？</h2><ul><li>Icescrum </li><li>Rally Software </li><li>Agilent </li><li>Version One </li><li>Agilo </li><li>X-planner</li></ul><h2 id="14-敏捷和Scrum有什么区别？"><a href="#14-敏捷和Scrum有什么区别？" class="headerlink" title="14.敏捷和Scrum有什么区别？"></a>14.敏捷和Scrum有什么区别？</h2><p><strong>敏捷</strong>： 它是一种主要用于软件开发的方法。在这种方法中，复杂的项目被分解为可以在特定时间范围内实现的较小单元。它始终让客户参与开发过程。</p><p><strong>Scrum</strong>：有不同的敏捷方法，Scrum就是其中之一。它促进类似于敏捷的问责制、功能和团队合作。简而言之，它是敏捷方法的一种改进方式，并具有与敏捷相同的原则和价值观，并添加了一些自己独特的功能。</p><h2 id="15-结对编程是什么意思？写下它的优点。"><a href="#15-结对编程是什么意思？写下它的优点。" class="headerlink" title="15.结对编程是什么意思？写下它的优点。"></a>15.结对编程是什么意思？写下它的优点。</h2><p>结对编程，顾名思义，是一种编程类型，其中两个人一起编写代码并在一台机器或计算机上并排工作。它基本上是一种主要用于敏捷软件开发的技术。在这种类型的编程中，一个人编写代码，另一个人检查和审查每一行代码。他们俩在工作时也会转换角色。</p><p>结对编程的优势：</p><ul><li>开发更高质量的代码</li><li>降低出错风险</li><li>分享知识的有效方式</li><li>提高生产力</li><li>改善团队协作</li></ul><h2 id="16-什么是敏捷宣言？它的价值观和原则是什么？"><a href="#16-什么是敏捷宣言？它的价值观和原则是什么？" class="headerlink" title="16.什么是敏捷宣言？它的价值观和原则是什么？"></a>16.什么是敏捷宣言？它的价值观和原则是什么？</h2><p>敏捷宣言基本上是一个由敏捷中表达的价值观和原则组成的文档。它创建于2001年初。它仅由 4 个价值观和 12 个关键原则组成。该宣言有助于开发团队更有效地工作，并提供清晰且可衡量的结构，以促进团队协作、迭代开发等。它是专门为改进开发方法而设计的。</p><p><strong>4个敏捷价值观：</strong></p><ol><li>流程和工具上的个人和交互：它侧重于给予与客户沟通更多的关注和重视。</li><li>工作软件超过全面的文档：它侧重于项目的完成，并确保项目正在完成最终的可交付成果。</li><li>通过合同谈判进行客户协作：它侧重于让客户参与项目的所有阶段，以便最终产品不会缺少客户所需的任何要求。这样做是为了确保100%的客户满意度。</li><li>响应变化而不是遵循计划：它专注于变化，并激励团队快速采用变化，以便交付更高质量的产品。因此，敏捷在短冲刺中工作，以便可以很好地利用更改。</li></ol><p><strong>12项敏捷原则：</strong></p><ol><li>客户满意度：首要任务是满足客户需求，确保100%的客户满意度。</li><li>欢迎更改：更改对于改进很重要，因此即使在开发过程的后期，也可以在整个开发期间引入和解决更改。</li><li>经常交付：产品必须尽快交付，因此专注于更短的时间。</li><li>共事：业务利益干系人和团队成员在整个开发过程中协同工作，以实现更好的协作。</li><li>积极进取的团队：为了提供高质量的产品，团队成员受到激励和鼓励。团队成员将获得有效执行所需的环境和支持。</li><li>面对面：敏捷强调面对面的沟通，这是传达信息的最有效和最有效的方式。它可以帮助团队以有效的方式传达简单和复杂的信息。</li><li>工作软件：向客户提供工作软件是敏捷的主要关注点。工作软件或产品是衡量最终产品进展的主要指标。</li><li>恒定的步伐：敏捷促进可持续发展。参与敏捷过程的所有团队、发起人、开发人员和用户都应保持恒定的速度，以便在短时间内交付工作软件。</li><li>好的设计：专注于良好的设计和技术细节，以提高质量和敏捷性（快速而优雅）。</li><li>单纯：团队专注于必不可少的任务和功能，并减少在复杂功能和非必需任务上花费的工作量和时间。这样做是为了保持简单。</li><li>自组织：敏捷团队应该是跨职能和自组织的。它不应该依靠经理来分配工作，而应该找到自己的工作并管理职责和时间表。这样的团队不仅有助于交付高质量的软件，而且还提供最佳的设计、要求和架构。</li><li>反映和调整：为了提高团队的效率，团队反思如何变得更有效率，并定期评估他们的工作方式。这样做是为了人们可以从他们的错误中吸取教训，并采取一些步骤来提高他们在下一次迭代中的性能。</li></ol><h2 id="17-敏捷中的燃尽图是什么？"><a href="#17-敏捷中的燃尽图是什么？" class="headerlink" title="17.敏捷中的燃尽图是什么？"></a>17.敏捷中的燃尽图是什么？</h2><p><strong>燃尽图</strong>：它是一种图表类型，用于显示或表示已完成的工作量以及冲刺或迭代的总工作量。</p><h2 id="18-燃尽图有哪些不同类型？"><a href="#18-燃尽图有哪些不同类型？" class="headerlink" title="18.燃尽图有哪些不同类型？"></a>18.燃尽图有哪些不同类型？</h2><p><strong>产品燃尽图</strong>：它是一种图表，用于显示每个已完成冲刺 （sprint） 的故事点，以便描述需求随时间推移的完成情况。它主要显示团队正在实现多少产品目标以及还剩下多少工作。</p><p><strong>冲刺燃尽图</strong>：它是一种图表，用于显示特定冲刺的Scrum团队的剩余工作。它使团队的工作可见，并显示完成工作的速率以及剩余的完成量。</p><p><strong>发布燃尽图</strong>：它是一种图表，用于显示团队如何针对发布工作取得进展。此图表由 Scrum 团队在每个冲刺 （sprint） 结束时更新。查看每个冲刺期间正在执行的过程非常重要。</p><p><strong>缺陷燃尽图</strong>：它是一种图表，用于显示正在识别和修复或删除的缺陷总数。</p><h2 id="19-列出除Scrum之外的三个主要敏捷框架，用于产品开发。"><a href="#19-列出除Scrum之外的三个主要敏捷框架，用于产品开发。" class="headerlink" title="19.列出除Scrum之外的三个主要敏捷框架，用于产品开发。"></a>19.列出除Scrum之外的三个主要敏捷框架，用于产品开发。</h2><p>除了Scrum之外，三个主要的敏捷框架是：</p><ol><li>看板(KanBan)</li><li>测试驱动开发 （TDD）</li><li>功能驱动开发 （FDD）</li></ol><h2 id="20-什么是“Planning-Poker”技术？"><a href="#20-什么是“Planning-Poker”技术？" class="headerlink" title="20.什么是“Planning Poker”技术？"></a>20.什么是“Planning Poker”技术？</h2><p>Planning Poker，也称为Scrum Poker，是一种基于共识的技术，不仅可以帮助敏捷团队估计完成产品待办事项的每个计划所需的时间和精力，还可以在时间和用户故事过程中识别问题。它使会议更简短、更有成效，并在整个团队的参与下创建估算。它主要用于避免其他参与者的影响，并迫使每个人独立思考并发表意见。</p><h2 id="21-什么是冲刺计划会议、冲刺评审会议和冲刺回顾会议？"><a href="#21-什么是冲刺计划会议、冲刺评审会议和冲刺回顾会议？" class="headerlink" title="21.什么是冲刺计划会议、冲刺评审会议和冲刺回顾会议？"></a>21.什么是冲刺计划会议、冲刺评审会议和冲刺回顾会议？</h2><p><strong>冲刺计划会议</strong>：在此会议中，将讨论对团队很重要的功能和产品积压工作项（用户情景）。此会议通常由产品负责人、Scrum Master 和 Scrum 团队参加。这是每周一次的会议，通常持续约一个小时。</p><p><strong>冲刺评审会议</strong>： 在这次会议上，Scrum团队对产品进行了演示。在此之后，产品所有者确定哪些项目已完成，哪些项目未完成。他还根据客户或利益相关者的反馈向产品待办事项添加了一些其他项目。其主要目的是检查冲刺中创建的产品，并在需要时对其进行修改。</p><p><strong>冲刺回顾会议</strong>：此会议在 Sprint 计划会议之后举行。在这次会议上，Scrum团队再次开会检查自己，讨论过去的错误，潜在的问题和解决这些问题的方法。这次会议的主要目的是改进开发过程。这次会议持续约2-3小时。</p><h2 id="22-“增量”一词是什么意思？"><a href="#22-“增量”一词是什么意思？" class="headerlink" title="22.“增量”一词是什么意思？"></a>22.“增量”一词是什么意思？</h2><p>增量只是冲刺期间完成的所有产品积压工作项的总和或总计，以及所有先前冲刺 （sprint） 的增量值。它是在当前和以前的冲刺 （sprint） 中完成的总工时。</p><h2 id="23-敏捷的标准或通用指标是什么？解释。"><a href="#23-敏捷的标准或通用指标是什么？解释。" class="headerlink" title="23.敏捷的标准或通用指标是什么？解释。"></a>23.敏捷的标准或通用指标是什么？解释。</h2><p>敏捷指标基本上是用于衡量团队工作的标准指标。这些指标用于确定工作质量、生产力、进度、团队健康状况等。它的主要重点是交付给客户的价值以及最终用户受到的影响程度。<br>敏捷项目的标准指标</p><ul><li>速度：它衡量开发团队在冲刺期间完成的工作量。它提供了有关进度、能力等的想法。</li><li>累积流程图：它是用于衡量团队正在进行的工作的当前状态的流程图。它仅用于跟踪敏捷团队的进度并管理流程稳定性。</li><li>缺陷去除意识：它用于衡量开发团队在发布之前消除缺陷的能力。它有助于通过工作团队保持产品质量。</li><li>工作类别分配：它用于衡量我们在哪里花费或投入时间，以便我们可以调整我们的优先事项。</li><li>冲刺燃尽指标：它用于衡量与估计的Scrum任务相比完成的冲刺或任务的总数。它通常跟踪冲刺期间任务的进度。</li><li>缺陷解决时间：它用于衡量团队识别和修复软件中的缺陷或错误所花费的时间。修复错误涉及几个过程。</li><li>时间覆盖率或代码覆盖率：它用于测量在测试期间为代码提供的时间。它有助于人们了解测试了多少代码，也有助于评估测试性能。</li><li>提供的业务价值：它用于衡量工作团队的效率。</li></ul><h2 id="24-什么是Scrum？写下它的优点。"><a href="#24-什么是Scrum？写下它的优点。" class="headerlink" title="24.什么是Scrum？写下它的优点。"></a>24.什么是Scrum？写下它的优点。</h2><p>Scrum是一个轻量级的流程框架，可帮助Scrum团队协同工作并管理产品开发，从而在最短的时间内交付产品。Scrum团队在最短的时间内提供的产品被称为打印。其主要目的是在基于团队的开发环境中管理任务。它特别用于管理软件产品的项目开发，也可用于与业务相关的上下文。<br>Scrum的优势：</p><ul><li>向用户和客户快速发布产品</li><li>确保有效利用时间和金钱，从而节省成本</li><li>最适合快速发展的开发项目</li><li>能够在更改发生时合并更改</li><li>强调创造力和创新，提高商业价值</li><li>大型和复杂的项目分为小而易于管理的冲刺</li></ul><h2 id="25-Scrum中有哪些不同的角色？"><a href="#25-Scrum中有哪些不同的角色？" class="headerlink" title="25.Scrum中有哪些不同的角色？"></a>25.Scrum中有哪些不同的角色？</h2><p>Scrum中基本上有三种不同的角色，如下所示：</p><ul><li>Scrum Master：Scrum Master基本上是一个团队的领导者或主管，负责确保Scrum团队正确执行提交的任务。</li><li>Product Owner：产品负责人基本上是项目的利益相关者，负责管理产品积压工作。他还负责定义为团队构建的愿景。</li><li>Development Team：它涉及一个人，每个人都负责集体工作以完成特定项目。该团队负责开发实际的产品增量并实现冲刺目标。</li></ul><h2 id="26-Scrum-Master是什么意思？Scrum-Master的职责是什么？"><a href="#26-Scrum-Master是什么意思？Scrum-Master的职责是什么？" class="headerlink" title="26.Scrum Master是什么意思？Scrum Master的职责是什么？"></a>26.Scrum Master是什么意思？Scrum Master的职责是什么？</h2><p>Scrum Master是Scrum的领导者，即负责管理和促进敏捷开发团队并确保遵循Scrum框架的人。Scrum Master也被称为团队的教练，帮助团队成员尽可能做到最好。</p><p>Scrum Master 的职责 ：</p><ul><li>保护团队免受干扰</li><li>激励和指导团队实现冲刺目标</li><li>建立一个自组织和积极进取的团队</li><li>提高团队的效率和生产力</li><li>确保团队在冲刺期间提供预期价值</li><li>确保团队遵循Scrum的价值观，实践和原则</li><li>消除外部障碍并管理内部障碍</li><li>主持会议并解决任何类型的问题</li></ul><h2 id="27-Scrum框架的主要工件是什么？"><a href="#27-Scrum框架的主要工件是什么？" class="headerlink" title="27.Scrum框架的主要工件是什么？"></a>27.Scrum框架的主要工件是什么？</h2><p>Scrum框架有三个主要工件：</p><ul><li>产品待办列表：它是产品中需要的客户或利益相关者的所有需求的列表，应在项目结束之前完成。</li><li>冲刺积压工作：它是所有最终用户故事、错误修复、工作项等的列表，这些内容由 Scrum 完成并选择在当前冲刺期间完成。</li><li>产品增量：它是从每个Sprint的完成派生的最终产品版本。</li></ul><h2 id="28-解释术语-Scrum-中的用户故事、史诗和任务？"><a href="#28-解释术语-Scrum-中的用户故事、史诗和任务？" class="headerlink" title="28.解释术语 Scrum 中的用户故事、史诗和任务？"></a>28.解释术语 Scrum 中的用户故事、史诗和任务？</h2><p>Scrum活动中通常使用许多技术术语。其中一些给出如下：</p><ul><li>史诗：它基本上是一个大故事，无法在单个冲刺中完成。因此，史诗在处理之前被细分为多个较小的用户故事。</li><li>用户故事： 这些是可以在一个冲刺中安装和完成的最小单元。用户情景进一步细分为不同的任务。</li><li>任务：这些是将用户故事转换为可行组件所必需的详细工作。</li></ul><h2 id="29-Scrum项目中最常用的重要工具是什么？"><a href="#29-Scrum项目中最常用的重要工具是什么？" class="headerlink" title="29.Scrum项目中最常用的重要工具是什么？"></a>29.Scrum项目中最常用的重要工具是什么？</h2><p>Scrum项目中最常用的工具有：</p><ul><li>Version One </li><li>Sprintster </li><li>Atlassian JIRA </li><li>RTC Jazz, etc.</li></ul><h2 id="30-在-Scrum-中解释时间盒。"><a href="#30-在-Scrum-中解释时间盒。" class="headerlink" title="30.在 Scrum 中解释时间盒。"></a>30.在 Scrum 中解释时间盒。</h2><p>时间盒是一种重要的时间管理技术或工具，用于限制完成任务所花费的时间量。它只是为每个任务允许一个固定的时间单位，这个单位被称为时间盒。时间框的最大长度为 15 分钟。它不仅有助于提高注意力，还可以提高生产力。Scrum中有一些事件，所有这些事件都是有时间限制的，这意味着所有这些事件都被分配了任务的最大和固定的时间单位。下面列出了有时间限制的事件：</p><ul><li>Sprint 冲刺</li><li>Sprint Planning 冲刺计划</li><li>Daily Scrum  每日Scrum  </li><li>Sprint Review  冲刺审查</li><li>Sprint retrospective  冲刺回顾</li></ul><h2 id="31-解释-Scrum-中的“障碍”一词。"><a href="#31-解释-Scrum-中的“障碍”一词。" class="headerlink" title="31.解释 Scrum 中的“障碍”一词。"></a>31.解释 Scrum 中的“障碍”一词。</h2><p>障碍是阻碍或阻止团队合作进展的东西。它导致团队无法以更好的方式按时执行任务，从而减慢速度。Scrum主管有责任消除或解决障碍。障碍可以是下面列出的任何内容：</p><ul><li>缺少资源</li><li>严格的老板或团队成员</li><li>技术或操作问题</li><li>停电</li><li>缺乏对敏捷或Scrum的理解</li><li>战争、天气等外部问题。</li><li>业务问题</li></ul><h2 id="32-Sashimi在-Scrum-中的主要角色是什么？"><a href="#32-Sashimi在-Scrum-中的主要角色是什么？" class="headerlink" title="32.Sashimi在 Scrum 中的主要角色是什么？"></a>32.Sashimi在 Scrum 中的主要角色是什么？</h2><p>Sashimi基本上是一个日语单词，其含义是刺穿身体。在Scrum中，Sashimi是一种技术，仅用于在产品显示后检查所有功能（软件开发周期的每个阶段）是否完成。功能包括需求分析、规划、设计、开发、测试和文档编制。</p><h2 id="33-解释-Scrum-中的“故事点”一词。"><a href="#33-解释-Scrum-中的“故事点”一词。" class="headerlink" title="33.解释 Scrum 中的“故事点”一词。"></a>33.解释 Scrum 中的“故事点”一词。</h2><p>故事点基本上是一个单位，用于估计完成或执行特定任务或用户情景所需的总工作量。它提供了更准确的度量，减少了计划时间，更准确地预测了发布日期。</p><h2 id="34-crums中的Scrum是什么意思？-Scrum-of-Scrums-SoS"><a href="#34-crums中的Scrum是什么意思？-Scrum-of-Scrums-SoS" class="headerlink" title="34.crums中的Scrum是什么意思？-Scrum of Scrums (SoS)"></a>34.crums中的Scrum是什么意思？-Scrum of Scrums (SoS)</h2><p>SOS，顾名思义是一种敏捷技术，涉及与多个Scrum团队会面，并整合从事同一项目的每个团队的工作。简而言之，它协调需要协同工作以提供复杂解决方案的多个团队的工作。在此会议中，各个团队的成员或代表分享有关各自团队工作的高级更新。其主要目的是通过消除障碍（如果存在）来确保协调和整合多个团队的产出。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;敏捷或敏捷方法或敏捷过程定义&quot;&gt;&lt;a href=&quot;#敏捷或敏捷方法或敏捷过程定义&quot; class=&quot;headerlink&quot; title=&quot;敏捷或敏捷方法或敏捷过程定义&quot;&gt;&lt;/a&gt;敏捷或敏捷方法或敏捷过程定义&lt;/h1&gt;&lt;p&gt;顾名思义，敏捷方法论是一组方法和实践，其中软</summary>
      
    
    
    
    <category term="开发方法" scheme="http://example.com/categories/%E5%BC%80%E5%8F%91%E6%96%B9%E6%B3%95/"/>
    
    
    <category term="scrum" scheme="http://example.com/tags/scrum/"/>
    
  </entry>
  
</feed>
